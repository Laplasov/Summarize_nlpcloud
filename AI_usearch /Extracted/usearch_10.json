[
  {
    "body": "satellites.\nNASA and ESA\nNASA has a massive amount of data and it receives more every day. While some of the data is processed immediately, much of the data is archived to be processed later, sometimes years later. This situation needs to change if researchers are to utilize the data to investigate critical issues with dynamically changing characteristics like global climate change. To increase its ability to process and use this data in a timely manner, NASAs Marshall Space Flight Center announced a joint development program with IBM Research to process the NASA data using IBMs foundation AI technology.\nTo put this task into perspective, the GPT-3 data set, which led to the development of ChatGPT AI platform that recently passed a Wharton MBA exam, represents about 45TB (terabytes) of data. By comparison, NASA estimates that its data set could be upwards of 250PB (petabytes). With 1PB equal to 1,000TB, the NASA data set is over 5,000 times larger than the GPT-3 data set, making this a monumental task, but the benefits could be ground-breaking.\nPreviously, IBM estimated that 90% of data collected is never used, and in their press invitation, IBM and NASA noted that Currently, half of all scientific findings come from archived data, which makes it challenging for researchers to study ever-evolving threats such as climate change. Efficiently mining the enormous amount of archival data needs the power of AI. IBM Researchs massive cloud resources, the collective experiences of the companys AI experts, and its AI foundation model technology will help NASA filter and analyze earth-science data in days or months rather than years or even decades.\nThe first foundation model will be trained on over 300,000 earth science publications, where contextual information will be extracted. This stage will enhance search and investigation of existing data. A second model will be trained on USGS (US Geological Survey) and NASAs Harmonized Landset-Sentinel2 (HLS2) satellite dataset. HLS2 takes data from the joint NASA/USGS Landsat 8 and Landsat 9 and the ESA (European Space Agency) Sentinel-2A and Sentinel-2B satellites to generate harmonized, analysis-ready, surface reflectance data every two to three days.\nAccording to the NASA web page, the harmonization of the Landsat 8 and Landsat 9 data collection (with 30-meter spatial resolution and a 16-day repeat period) with the ESA Sentinel-2A/B collection (with 10- to 20-meter spatial resolution and a five-day repeat period) will allow these data sets to be used as if they were a single collection. Using this harmonized data set, land-surface observations can be created that offer a 30-meter spatial resolution every two to three days.\nMORE FOR YOU\nHow Pacific Sands Beach Resort Makes Tofino A Wellness Destination Year-Round\nThe HLS data is refreshed frequently, which allows for time series observations of land surfaces down to the field/plot scale. Applications for this harmonized data set include everything from detecting natural hazards to tracking changes in vegetation, infestations, and wildlife habitats.\nIBM and NASA are still in the early phases of this project. The IBM foundation models are presently trained on massive Nvidia A100 GPU installations in the IBM Cloud. However, the data center strategy will depend upon the data gravity (is NASAs data portable enough to send to the cloud or will the compute have to be located closer the data) and compute resources to be applied to the workload.\nNASA hopes to use the fundament models to feed the generation of transformer models (AI models customized to particular applications) in areas such as weather prediction, climate analysis, and geological analysis. The training data set and the foundation models will be open sourced and available for other researchers to use. Theoretically, the NASA data could be combined with data from other US and international government agencies, such as NOAA (the National Oceanic and Atmospheric Administration) and the Department of Agriculture, to further improve the training data sets and expand the scope of the foundation models to cover almost every aspect of the earth.\nThe result of this collaboration may have wide-reaching impacts. Researchers will have an improved ability to monitor and analyze earth data. IBM itself could use the data for its Weather.com subsidiary, to better model weather patterns and the impact of weather on the earth. The resulting models could also be critical for commercial operations in agriculture, fishing, oil and gas exploration, mining, and many other industries.\nIf a large data set like GPT-3 can lead to intelligent communication platforms in just months, an earth super data set and AI foundation models based on it may be able to help humanity better understand and monitor our planet and lead to a better future.\nFollow me on"
  },
  {
    "body": "Junior Bernadin, Dean of Students and Director of Information Techonology for The Ron Clark Academy\nBy Junior Bernadin, Dean of Students and Director of Information Techonology for The Ron Clark Academy\nAs technology advances and artificial intelligence (AI) becomes more prevalent in our daily lives, it is crucial that the creators and developers of these technologies accurately represent and include all diverse groups.\nFor example, on January 3, I generated a series of about one hundred images using the word beautiful in conjunction with the words kids, baby, and girl on the Dall-E. This tool generates images using AI based on written descriptions.\nUnfortunately, as seen in my recent experiment with Dall-E, hardly any Black babies, kids, or girls were represented in the art generated when using the term beautiful baby, beautiful kids, or beautiful girls.\nThe word beautiful is often used to describe art and photographs, and it can be especially significant when it is used to describe images of Black people. There are a few reasons why this is the case.\nHistorically, Black people have often been marginalized and excluded from mainstream definitions of beauty. This has contributed to harmful stereotypes and biases about Black peoples appearance.\nWhen Black youth are rarely represented in a positive light in mainstream media and art, it can be difficult for them to feel confident and valued in society.\nThis lack of representation is not only harmful and offensive, but it also negatively impacts the development and accuracy of AI systems.\nIt is my belief that if there isnt enough representation present in the data sets and those involved in the machine learning process like developers and stakeholders, bias occurs in the AI.\nIn other words, if the people creating and inputting data into these systems are not diverse and representative of different cultures and communities, the resulting AI will also be biased and exclude certain groups.\nThis is especially concerning regarding facial recognition technology, which has been shown to have significant biases against people of color.\nFor example, in a study conducted by the National Institute of Standards and Technology (NIST), it was found that most facial recognition algorithms were more accurate for lighter-skinned males than darker-skinned females (NIST, 2019).\nThe technology is more likely to recognize and identify white men accurately while consistently misidentifying and excluding Black women.\nThese biases and exclusions have real-life consequences, as seen in the case of biometric border control systems. In 2018, the Electronic Frontier Foundation (EFF) reported that customs officers have been using facial recognition to screen travelers at border crossings, including US citizens, for several years (EFF, 2018).\nHowever, the technology has been shown to have higher error rates for people of color, leading to false positives and wrongful detentions.\nThe lack of diversity in the development and creation of AI also perpetuates harmful stereotypes and reinforces systemic racism.\nFor example, the lack of beautiful Black babies, kids, and girls in the Dall-E-generated images reinforces the harmful stereotype that beauty only exists in certain races and further perpetuates the exclusion of Black women and children from societal beauty standards.\nDiverse developers and scientists must be included in creating and developing AI systems to ensure that the technology accurately represents and consists of all groups."
  },
  {
    "body": "ChatGPT is an AI language model, that is not perfect and may sometimes produce incorrect answers or nonsensical outputs. Hence, it's crucial to review, edit or process the model's results and always consider the context.\r\n\r\nTo optimize ChatGPT's performance, it's essential to ask clear questions, fine-tune it for a specific purpose, and utilize it in conjunction with other techniques. With proper usage and post-processing, ChatGPT can be an effective tool in any NLP task.\r\n\r\nHighlighted below are some tips on how to get better answers with ChatGPT.\r\n\r\nProvide context:Providing ChatGPT with additional context in your requests leads to more concise answers. ChatGPT is efficient and delivers the most accurate response when you pose a clear question. By giving some background information, ChatGPT adapts its response to match what you're looking for. The more context and details you offer, the better the model will comprehend and respond accordingly.\r\n\r\nFor example, instead of simply asking What is the weather like today?. You could ask What is the current temperature and forecast for Los Angeles, California?.\r\n\r\nMake your request precise:When posing a question to ChatGPT, try to be as direct and precise as you can while also providing background information. Your query should contain as many details as are required. ChatGPT will take into account each signal you send and each clarification you offer to come up with a response that is exactly what you asked for.\r\n\r\nAsk it to elaborate:Sometimes ChatGPT doesn't produce specific responses. If you want to continue the conversation, don't be afraid to ask the chatbot to expand on or complete its initial response. Then ChatGPT will continue by enhancing its initial response with new information.\r\n\r\nAsk ChatGPT to reformulate responses:If you are not satisfied with ChatGPT's initial response, you can request that it be reformulated. This can be done without altering your original request. Additionally, you only need to request that he respond using straightforward language, refrain from using formulations that you find to be overly complicated, or even respond as if you were a child. The chatbot will resume speaking as per your instructions and revise its previous speech to make it clearer.\r\n\r\nAsk it to format replies in a specific manner:In addition to being an almost infinite source of knowledge, ChatGPT can alter its speech by adopting a specific language style. For example, you could ask for it to mimic the writing style of a famous person or author. Chabot can also change the responses by producing things like tables and bulleted lists."
  },
  {
    "body": "15:52, 1 FEB 2023\nBookmark\nJit and Sophie Jagatia swapped out their kids' pocket money for mobile data back in 2021\n(Image: Jit Jagatia/EE)\nA dad-of-two who swapped his kids' pocket money for phone data says 'we've never seen them so motivated to unstack the dishwasher'.\nJit and Sophie Jagatia from Cheshire said they began giving their son Jay and daughter Ananya phone data instead of pocket money in 2021.\nApparently the move has been a fantastic motivator for the kids, who have never done so many chores or performed so well at school.\nREAD NEXT:\nJit, an IT consultant, said: \"The kids are often on their phones when they're out and about, and we realised data top ups were more important to them than pocket money.\"\nJit and Sophie allocate data to their kids' phones using EE's family plan app\n(Image: Getty Images)\nAI clone under fire over fake Emma Watson reading Hitler and Attenborough rant\nJit and Sophie, who works for the NHS, give their kids around 3GB of data per week if they complete all of their chores, and additional data if they do well at school.\nJit said: \"Jay recently came first in his year at maths, and Ananya was appointed to the school council. We were really proud so we gave them each a whole 30GB of data for the month - a massive amount - and they were delighted with it.\nJit and Sophie use their family EE account to allocate data to different members of the family and keep track of usage.\nJit and Sophie's kids are apparently excelling at school since the change\n(Image: Jit Jagatia/EE)\nAI can now make its own music - and it could put Ed Sheeran out of a job\nJit added: \"They mostly use their data to watch YouTube videos, stay in touch with their friends and check social media. They wouldn't get through all that data, but it gives them a bigger sense of achievement.\"\nAccording to research by EE, one in four parents use data as a reward for their children. Apparently, washing the car is considered the most valuable 'chore for data' and can net kids 173mb of data, which amounts to about 10 minutes of TikTok videos.\nSharon Meadows, Director of Broadband and Mobile at EE, said: \"Parents know how much children love their data - and how they hate to run out. Our research confirms that pocket money is no longer king, with more than a quarter of parents already sharing data as a reward for chores.\"\nREAD MORE:\nEvil Putin pledges to deploy terrifying Satan nuke that could hit UK within 6 minutes\nApple fans surprised at 'inspiring' real meaning behind the 'i' in iPhone\nJapanese scientists' 'insect death ray' can zap cockroaches with powerful laser beams\n'Superhuman AI could kill everyone' and is as dangerous as nukes, MPs warned\nRussia shows off autonomous 'killer robot' designed to eliminate 'Western enemies'\nRead More"
  },
  {
    "body": "February 01, 2023, 15:37 GMT\nShare This Article\nSAN FRANCISCO, Feb.  01, 2023  (GLOBE NEWSWIRE) --\nArchipelago\n, an AI-driven technology platform that connects, validates and analyzes property risk data for large commercial property owners, today announced the successful completion of their SOC 2 Type I attestation. This certification confirms the company meets all of the necessary criteria for providing secure and reliable services to its customers. The SOC 2 Type I attestation is a widely accepted independent evaluation that ensures a service provider's secure systems, processes, and organization are compliant with industry standards. The completion of this assessment validates Archipelago as a trusted and secure technology for our customers and their data.\n\"At our core, the Archipelago solutions adds efficiencies to risk managers, brokers and underwriters across the value chain through the curation, enrichment, secure storage and sharing of property risk data critical to the commercial property insurance and risk management ecosystem. Rather than sharing sensitive data in emails and spreadsheets, Archipelago enables a secure end-to-end experience for all involved,\" said Hemant Shah, CEO and Co-Founder of Archipelago. \"Having secured our SOC 2 assessment signals our commitment to the proper processing and protection of the data of our clients, providing them the confidence that sensitive, proprietary information is protected at the highest industry standard possible.\"\nSOC 2 is an independent audit conducted to review a company's effective implementation of employee controls and training, IT systems and risk management control, product discipline, and vendor selection. SOC 2 Type I consists of a thorough examination, by a third party firm, of control policies and practices set forth by the AICPA. A SOC 2 attestation is most often required when doing business with customers from the healthcare, finance and education sectors.\n\"With 1.3 million properties represented on Archipelago, totaling over $9.5 trillion in total insured value, a SOC 2 assures our clients, vendors and partners they can rest easy with the knowledge that our data and security measures meet the highest bar. SOC2 is particularly valuable to those in healthcare, finance and education, and we're thrilled to meet this mark for our clients who operate in and around these sectors,\" said Shah.\nAbout Archipelago\nArchipelago is an AI technology and data analytics company transforming how commercial property risks are understood and managed by owners, operators, and risk managers. The high-quality data generated through Archipelago's platform can be shared securely with stakeholders to deliver innovative services and solutions to their customers. Learn more at"
  },
  {
    "body": "GOOGL\n)) represented 70% of that.\nSaaS applications represented ~35% ($167bn). The use cases for SaaS are very broad (from CRM systems to design software). Within SaaS, there are several new entrants that sit on top of the cloud infrastructure platforms and provide ways of using the platforms more efficiently and securely, e.g., separating storage from compute, sharing data without having to store it twice, etc.\nThere are several different types of business models within cloud. In general, the infrastructure services are project-/decision-based and many of the application that sit on top of the infrastructure platforms are consumption-based.\nConsumption-based businesses models were the first ones to go into the downturn, and the companies noted deteriorating demand since 1H22 (e.g., Snowflake (\nDDOG\n) noted weakness in their logs business). As we went through the year, the consumption side stabilized at lower levels, but the headwinds broadened to the project side, where recession fears started influencing investment decisions (e.g., hyperscalers just started experiencing demand softening in the second half of 2022).\nWe believe that while the hyperscalers may be facing 1-2 more quarters of weaker demand, the consumption-based models will start facing easier comps.\nInterestingly, this cyclical downturn in IT spend is coming at a time when Artificial Intelligence (AI) adoption is reaching an inflection point, creating a meaningful medium-/long-term tailwind for many of these companies.\nStrong medium-term outlook driven by AI inflection\nAI is undergoing a significant breakthrough driven by several successful applications of a new foundational model (Transformer) in large language model training. The Transformer model is a neural network that learns context and can therefore be used for \"generative\" rather than \"predictive\" applications.\nWe believe that this will be transformational for many industries and has already generated a fair amount of hype. But investors are not appreciating the amount of data and compute power that these applications will require, which will likely provide a meaningful tailwind for cloud spending.\nAccording to an ETR report surveying companies and their budgets, the cloud spending CAGR (for PaaS and IaaS) may be as high as 67%. Among all respondents, the median annual spend on IaaS/PaaS is currently $375,000 and is expected to increase to $1,750,000 in 3 years. Looking at large organizations, spend is currently $750,000 today but is expected to increase to $3,750,000 over that same time period.\nThese spend projections tie to commentary that we are hearing from companies, such as Snowflake. Once their costumers see what they can do with their data, the spend grows exponentially. While we are using a more conservative ~40% growth estimate, we believe that there is room for upside.\nAnother interesting observation from the same survey is that respondents expect that while AWS and Azure will remain the top platforms, there will be an opportunity for new entrants and smaller players to gain market share.\nIn summary, while recession expectations are impacting cloud spending, several quarters of below-trend spend could create pent-up demand as we go into what we expect to be a meaningful AI-driven investment cycle.\nDisclosures\nViews expressed here are for informational purposes only and are not investment recommendations. SPEAR may, but does not necessarily have investments in the companies mentioned. For a list of holdings click\nhere.\nAll content is original and has been researched and produced by SPEAR unless otherwise stated. No part of SPEARs original content may be reproduced in any form, without the permission and attribution to SPEAR. The content is for informational and educational purposes only and should not be construed as investment advice or an offer or solicitation in respect to any products or services for any persons who are prohibited from receiving such information under the laws applicable to their place of citizenship, domicile or residence. Certain of the statements contained on this website may be statements of future expectations and other forward-looking statements that are based on SPEAR's current views and assumptions, and involve known and unknown risks and uncertainties that could cause actual results, performance or events to differ materially from those expressed or implied in such statements. All content is subject to change without notice.\nAll statements made regarding companies or securities or other financial information on this site or any sites relating to SPEAR are strictly beliefs and points of view held by SPEAR or the third party making such statement and are not endorsements by SPEAR of any company or security or recommendations by SPEAR to buy, sell or hold any security. The content presented does not constitute investment advice, should not be used as the basis for any investment decision, and does not purport to provide any legal, tax or accounting advice. Please remember that there are inherent risks involved with investing in the markets, and your investments may be worth more or less than your initial investment upon redemption. There is no guarantee that SPEAR's objectives will be achieved.\nFurther, there is no assurance that any strategies, methods, sectors, or any investment programs herein were or will prove to be profitable, or that any investment recommendations or decisions we make in the future will be profitable for any investor or client. Professional money management is not suitable for all investors."
  },
  {
    "body": "AI (Artificial Intelligence) can now generate a sermon that mimics the writing of a human preacher.  How will we know who is truly writing the pastors sermon?\nPhoto by Possessed Photography on Unsplash. https://unsplash.com/photos/YKW0JjP7rlU\nA paradigm shift for preachers\nThe first time a preaching colleague showed me AI (Artificial Intelligence) generating a sermon on her phone, I was sitting next to her on a bus in early December 2022 as we were riding back to our hotel at the annual meeting of the Academy of Homiletics.  (AOH is the professional guild of those who teach preaching.) In seconds, the program had produced a sermon  something that takes a preacher hours and days to produce.  Suddenly, it felt like the bus had taken a sharp turn and was about to tip over.\nBut no, that was just my world veering and teetering into a paradigm shift.\nMy colleagues name is Rev. Lisa Cressman, Founding Steward of Backstory Preaching, an online preaching community made up of nearly 2,000 ordained and lay preachers.  And the app she showed me is called Craft, a writing program that uses Artificial Intelligence to create content that mimics human writing. (See the end of this article for other AI apps.)\nWhat is AI-generated content?\nLets let Craft tell us about AI.  Heres what I got when I asked it to write an article about AI-generated content:\nAI-generated content is created by machines that utilize artificial intelligence. It is content created by algorithms which are programmed to produce output that is similar to content created by humans. AI-generated content is becoming increasingly popular as it can take a huge amount of effort and time away from the content creator and provide better and faster results.\nWhat can a program like Craft do?\nIn that short bus ride, Lisa showed me how she can input the text from a book and ask Craft to summarize it, create an outline, offer pros and cons, and even continue writing the next paragraph based on what has already been entered into the program.  This was stunning enough.  But what she showed me next sent a crack down through the foundation of my preaching world.\nAI, write me a sermon\nLisa entered in a biblical passage and entered the command write a sermon.  It churned out 300-word mini-sermon in seconds.  We read it together.  It wasnt the best sermon wed ever read.  But it wasnt the worst.  And as teachers of preaching, I can tell you, weve seen our share of bad sermons.\nThen she hit the refresh button, and it generated a whole new sermon.  I couldnt believe that a computer was outputting something that takes me hours of exegesis, prayer, contemplation, and writing rough drafts to get something I consider decent enough to preach.\nEven though I was sitting down, I felt a wave of dizziness on this bus ride into a future that was coming way too fast for me to process.\nA Pandoras Box of AI ethical conundrums\nGasping in what suddenly felt like very thin air, I asked, Whats to stop a preacher from letting AI write their sermons for them?  Whats to stop students from having AI write the book review I assign in class?  And aside from my own moral and ethical fortitude, why wouldnt I use AI to create content for a blog post, a chapter in a book, or a lecture for a class?\nI know! Lisa whispered. Just think of the possibilities! And the very real ethical issues this raises! We hovered over the glowing screen as if we had just discovered Pandoras Box right in the palm of her hand.\nPhoto by Andrea De Santis on Unsplash. https://unsplash.com/photos/zwd435-ewb4\nAI cant always be detected . . .\nAt first, it may seem difficult to detect whether or not a preacher used AI.  For example, consider this first paragraph from a sermon that I asked Craft to write about Genesis 1:1:\nTake a moment and read this powerful scripture: In the beginning God created the heavens and the earth. God is the creator of all. He is the mastermind behind everything in our world. He is the architect of the universe, the creator of every living thing, and the author of the divine plan. This powerful God is the one who made man in His image. He gave us life and the power to be creative and to build. He endowed us with the unique ability and potential to be more than just He created us to be. It is Gods intention that we live lives of purpose and meaning. He created us with special talents and abilities so that we can use them to bless others and bring glory to His name.\nFor some, this would be perfectly acceptable.  There are several clear theological claims about who God is and what God does. And the sermon tells us what Genesis 1:1 has to do with us as human beings (It is Gods intention that we live lives of purpose and meaning. He created us with special talents and abilities so that we can use them to bless others and bring glory to His name.)\n. . . but there are clues\nHowever, my students know that I would never accept a sermon that refers to God and humanity exclusively using male pronouns.  There is also some awkward grammar in this sentence:  He endowed us with the unique ability and potential to be more than just He created us to be. Certainly, some humans do write like this (which is why AI is mimicking this syntax). But as a professor of homiletics, this would tip me off that perhaps my student didnt actually write these words.\nThe next paragraph sounds like it came straight out of a Prosperity Gospel pulpit.\nToday I want to challenge you to recognize Gods sovereignty and to submit to His will and His plan in your life. You see, when we live according to His plan, we find true joy and satisfaction. When we live according to His design, there is nothing that can stand in our way.\nReally? This pull-yourself-up-your-bootstraps theology is incredibly problematic.  And its just plain wrong.  Lots of things can stand in our way of finding true joy and satisfaction even when we live according to His design.  Not to mention the fact that there is absolutely no evidence of any kind of exegesis about the biblical text.  Its just platitudes and aphorisms without any real substance.\nThe end of this mini-sermon is chock-full of lettuce.\nLet us put our faith in Him and trust that He will direct our paths. Today, let us remember His words from the beginning of Genesis. He is the one who created the heavens and the earth, who gave us life and gave us purpose. Let us trust in His plan for our lives and live according to His will.\nThree times this AI-preacher uses the words let us. This lofty-sounding phrase is meant to convey an exalted-yet-benevolent tone imploring the congregation to respond in some way. But this jussive command is so overused in sermons, it has about as much impact as a head of iceberg lettuce.  The fact that the AI used it so many times indicates how often it is spoken by the preachers whose sermons the technology mined for this sermon!\nSo, if a student turned in a sermon like this, I would ask whether or not they had used AI to help generate their content.  But a"
  },
  {
    "body": "In 2016, Studio Ghibli co-founder and director Hayao Miyazaki, responsible for beloved anime classics like Princess Mononoke and Kikis Delivery Service, made headlines around the world for his reaction to an AI animation program. I would never wish to incorporate this technology into my work at all, Miyazaki told the software engineers who came to show their creation to him. I strongly feel that this is an insult to life itself. A half-decade later, artificial intelligence and the potential role it could play in anime productions is once again in the spotlight.\nThis week, Netflix shared Dog and Boy, an animated short the streaming giant described as an experimental effort to address the anime industrys ongoing labor shortage. We used image generation technology for the background images of all three-minute video cuts, said Netflix Japan of the project on Twitter, according to a machine translation. The short is touching but was immediately controversial. As Motherboard points out, many Twitter users accused Netflix of using AI to avoid paying human artists.\nNetflix rinnaWIT STUDIO3 pic.twitter.com/GYuWONSqlJ Netflix Japan |  (@NetflixJP) January 31, 2023\n \n\nOthers took issue with how Netflix and Wit Studio, the company that produced the short, credited those who worked on Dog and Boy. As you can see at the end of the video, human animators were not only involved in the creation of the shorts backgrounds, but they also revised the AIs work. However, the background designer is listed as AI (+Human). The credits go on to list Rinna Inc, an AI artwork company, and a handful of AI researchers.\nMany artists worry about the potential for AI to devalue their work, but that concern is particularly acute among anime creators. The labor shortages Netflix points to are the result of unsustainable labor practices that see the majority of Japans animation studios depend on essentially unpaid freelancers to complete much of the work that makes anime possible.\nAccording to data from the Japanese Animation Creators Association published in 2018, in-between animators, the workers who draw the frames that make a scene look fluid, earn about 200 (or less than $2) per drawing. With many frames taking more than an hour to produce, the average in-between animator can expect to make about 1.1 million (or $10,000) per year. For context, in 2019, Japans poverty line was at 2.2 million."
  },
  {
    "body": "NurPhoto/Getty Images\n\nChatGPT has been making headlines worldwide, but not all are impressed. Yann LeCun, Meta's chief artificial intelligence (AI) scientist, had some harsh words for the program in an hour-and-a-half talk hosted by the Collective[i] Forecast. This online, interactive discussion series is organized by Collective[i].\nWhat exactly did he have to say? ZDNET attended the session and reported on it.\nSee Also\n\"In terms of underlying techniques, ChatGPT is not particularly innovative,\" said LeCun on Zoom last week.\n\"It's nothing revolutionary, although that's the way it's perceived in the public,\" said LeCun. \"It's just that, you know, it's well put together, it's nicely done.\"\nIs ChatGPT overrated?\nHe noted that such systems had been built before by other companies; they simply hadnt gained the popularity of ChatGPT.\n\"OpenAI is not particularly an advance compared to the other labs, at all,\" explained LeCun.\n\"It's not only just Google and Meta, but there are half a dozen startups that basically have very similar technology to it,\" said LeCun. \"I don't want to say it's not rocket science, but it's really shared, there's no secret behind it if you will.\"\nIn many ways, ChatGPT was a group effort as it brought together multiple pieces of technology developed over many years by many parties.\n\"You have to realize, ChatGPT uses Transformer architectures that are pre-trained in this self-supervised manner,\" said LeCun. \"Self-supervised learning is something I've been advocating for a long time, even before OpenAI existed.\n @Sama (CEO of"
  },
  {
    "body": "Email\nGetty Images\nArtificial intelligence is, suddenly, all around. You may have tested ChatGPT, the AI-powered chatbot that headlined tech conversations at this years World Economic Forum, seen AI-generated portraits on Instagram, or followed the wave of recent enthusiastic media coverage. But this technology hasnt just appeared from nowhere. Artificial intelligence has powered internet search, voice assistants, and more for years  but has rapidly entered our public awareness and conscious engagement in the past few months.\n2023 will be a defining year in shaping the future of AI. Here are ten important AI domains to watch:\n1. AI and bots will change your job, no matter your profession\nDelivery drivers, cleaners, grocery clerks, and hospitality staff all face the unsettling possibility of being replaced by bots. Even legal and medical professionals are beginning to envision working alongside AI to conduct research, prepare briefs or develop diagnoses. Throughout 2023, debate over employment and industrial protection will shape our national discourse. To ensure genuine preparedness, we need empathetic, human-centered, and community-driven efforts to prepare for labor disruption at scale, ensuring workers have access to new upskilling and opportunities.\n2. AI will enter classrooms and exam halls\nAI has rapidly progressed from providing simple scripted answers to writing entire essays with logical arguments and inferences. Provocative headlines like \n illustrate rising concerns about how AI might affect traditional pedagogical methods. Educational institutions need to grapple with AIs effects on learning and evaluation and design new curricula to prepare students for the AI future.\n3. For children, AI will create new opportunities  and challenges\nParents already contend with the behavioral risks of cell phone and social media addictions, cyberbullying, and online harassment. Children will have access to advanced AI tools and chatbots with the capacity to introduce new interpersonal challenges. Together, parents, teachers, and community leaders will need to strike a balance between encouraging healthy, offline connection and responsible use of social AI tools.\n4. Digital portrait generators will change our understanding of privacy\nTodays phones and social media accounts give technology companies access to vast stores of information about users, including our images. Applications like Lensa AIs Magic Avatars function, which uses real photos to generate glamorous, aggrandized, or even quirky self-portraits, are the latest advances under this umbrella of scrutiny. What happens when AI  or its developer  knows every facial feature and can pick us out from a crowd? Throughout 2023, we will see increased focus on security and data protection debates.\n5. Defining what constitutes art will become increasingly difficult\nWith AI making its art world debut, traditional artists and art critics are simultaneously questioning its validity as a form of creative expression and highlighting the risks to artistic and intellectual ownership. Apps like DALL-E pull from troves of publicly accessible images created by other artists to create new works without compensating the original artists. Some critics have deemed these actions artistic theft. In 2023, we need public debate on the ethical implications  and economic fairness  of AI-generated art.\n6. Algorithmic justice will become a critical, cross-sectoral inquiry\nAlgorithmic justice dilemmas abound in hiring, law enforcement, health care, and beyond. As long as data sets reflect real-world discrimination and bias, the AI tools trained on that data will continue to perpetuate inequity. Both technologists and policymakers need a new toolkit to audit new algorithms and hold their users accountable.\n7. Killer robots will have to obey the law\nIn November 2022, San Franciscos board of advisors voted affirmatively  and then swiftly overturned  an authorization for local police to deploy autonomous robots capable of executing deadly force. The U.S. Army use of \n during drone strikes in Afghanistan and Iraq is well-documented. 2023 will prove to be an important year for regulating the use of lethal AI systems and determining the appropriate level of human oversight and machine autonomy.\n8. Expect more and bigger technology commitments from civil society\nPhilanthropy will play an increasingly large role in directing the development of new technologies to focus on human and long-term planetary challenges. Expect to see civil society underwriting new AI public goods  supporting data gathering efforts and the creation of new predictive tools for climate adaptation, health delivery and more.\n9. The AI divide is the new digital divide\nAI has the ability to make many aspects of our lives easier  from enhancing our productivity at work to helping us avoid traffic on our commute. But with a recent World Economic Forum reporting almost 3 billion people across the globe remain offline, the widening gap between those with access to AI and those without presents clear challenges to equitable development and global progress. In 2023, we need to see substantial, rapid action from global leaders  public, private and philanthropic  towards improving digital access and digital and AI literacy.\n10. AI will play a new role in government  our public service leaders need to be prepared\nSocial Security can be fixed. Heres how.\nGovernments have frequently been slow to adopt and adapt to technological advances. AI provides an extraordinary opportunity to utilize real-time data analysis, predict future needs, and deliver high-quality services. To achieve this, government will need more diverse technical talent than ever before, as well as programs that allow technologists to move relatively seamlessly between private sector careers and public service.\nThe speed of AI innovation is accelerating, and individuals and communities are taking note: AI is here to stay. To ensure AI serves us all, we must become co-designers of our common, AI-driven future in 2023."
  },
  {
    "body": "Getting accurate speech-to-text has always been a pain in the ass. A decade ago, it would cost you a $199 app purchaseand the result would still require a lot of editing to make it accurate. But this is where we start to see tangible benefits of the AI revolution, where the learning models can do things incredibly quickly, and without using a ton of resources. While OpenAIs Whisper technology is shockingly good at turning speech into text, you need to be a developer or a technician to actually make the most of it. But now, a developer has done the heavy lifting of turning this technology into a delightful little Mac app: MacWhisper.\n\nYou can use MacWhisper to directly record audio to be transcribed into text (with time stamps). However, things become a lot more interesting when you import an audio file or a video filethe app can quickly generate accurate transcription, time-stamped down to the millisecond. \n\nOnce the text is generated, you can go through and edit it. The Reader feature can show you all the text together in a document preview; you can then copy the transcript. Click the Share button, and youll be able to download the entire transcript as an SRT file (this is where those timestamps really come in handy).\n\nYou can download the MacWhisper app for free via Gumroadput a 0 (thats a zero, not the letter o) in the payment field to get it for free. Currently, the app requires macOS Monterey or Ventura, and its recommended to use an Apple Silicon Mac for fastest results. The free version will be enough for most people, but if you plan to use this in a professional setting, we suggest you spring for the 9 Pro version. This gives you access to the 3GB large data model, which improves the accuracy."
  },
  {
    "body": "Feb. 1, 2023\nImage: Getty Images\nChatGPT maker OpenAI has released a \"classifier\" tool that can detect AI-written text, but notes it shouldn't be relied on. \nThe breadth of prompts ChatGPT can create answers for has alarmed educators as some students begin handing in AI-generated essays and homework as their own work.\nAlso:\nWhat is ChatGPT and why does it matter? Here's everything you need to know\nEducation is one field that could benefit from OpenAI's new classifier by automating the detection of AI-generated essays and homework. It might allow a different response than say, restricting its use as New York Schools did recently. School departments across Australia have banned ChatGPT too. \nThe classifier could also help companies like developer Q&A site, Stack Overflow, which banned ChatGPT answers after its moderators were flooded with sometimes-correct solutions.\nWhile the classifier can eliminate some detection work, OpenAI says it's impossible to reliably detect all AI-written text and there are a number of limitations that impact its effectiveness.\nThe classifier correctly identifies 26% of AI-written text as \"likely AI-written\"  its true positive rate. It incorrectly identifies human-written text as AI-written 9% of the time  its false positive. In other words, there is a reasonably high chance it will fail to detect text submitted by a human who doesn't disclose it was written by AI and some chance it will mislabel text both ways. But it claims the classifier is \"significantly more reliable on text from more recent AI systems\" than its"
  },
  {
    "body": "Education Budget 2023: National Digital Libraries, 157 Nursing College, Integrated Online Training Programme - Key Takeaways\nThe finance minister made the announcement in her budget speech in Lok Sabha, and announced the biggest ever budgetary allocation of Rs 1,12,899 crore in the education sector. Re-envisioning teacher training through innovative pedagogy, curriculum transaction, continuous professional development, dipstick surveys, ICT implementation and a research and development grant for indigenous production of Lab Grown Diamond (LGD) seeds and machines to one of the IITs for five years were among other major announcements for the education sector.\nThe education budget for 2023-24 is an increase of Rs 13,018 crore from the current fiscal, with Rs 38,953 being the budget estimate for the core National Education Mission. However, estimated expenditure on education by the Centre would be 2.5 pc of total allocations, down from 2.6 pc in 2021-22.\nIn the budget allocation for school education, there has been an overall increase of Rs 9752.07 crore (16.51 pc) and for higher education, an amount of Rs 44,094.62 crore has been made as compared to Rs 40,828.35 crore in RE 2022-23, an increase of 8 per cent. For realising the vision of Make AI in India and Make AI work for India, three centres of excellence for Artificial Intelligence will be set-up in top educational institutions.\nLeading industry players will partner in conducting interdisciplinary research, develop cutting-edge applications and scalable problem solutions in the areas of agriculture, health, and sustainable cities. This will galvanize an effective AI ecosystem and nurture quality human resources in the field, she said.\nSitharaman said a total of 100 labs will be set up in engineering institutions in collaboration with various authorities, regulators, banks and other business for developing applications using 5G services. One hundred labs for developing applications using 5G services will be set up in engineering institutions to realise a new range of opportunities, business models, and employment potential. The labs will cover, among others, applications such as smart classrooms, precision farming, intelligent transport systems, and health care applications, she added.\nTo address learning loss incurred during the pandemic years, a national digital library for children and adolescents will be set up for facilitating availability of quality books across geographies, languages and genres, the finance minister announced. A National Digital Library for children and adolescents will be set-up for facilitating availability of quality books across geographies, languages, genres and levels, and device agnostic accessibility.\nStates will be encouraged to set up physical libraries for them at panchayat and ward levels and provide infrastructure for accessing the National Digital Library resources, she said. To build a culture of reading, and to make up for pandemic-time learning loss, the National Book Trust, Childrens Book Trust and other sources will be encouraged to provide and replenish non-curricular titles in regional languages and English to these physical libraries, Sitharaman announced.\nCollaboration with NGOs that work in literacy will also be a part of this initiative. To inculcate financial literacy, financial sector regulators and organisations will be encouraged to provide age-appropriate reading material to these libraries, she said. As many as 38,000 teachers and support staff will be recruited in the next three years for 740 Eklavya Model Residential Schools serving 3.5 lakh tribal students, she said.\nSitharaman also announced that teachers training will be re-envisioned through innovative pedagogy, curriculum transaction, continuous professional development dipstick survey and ICT implementation. Teachers training will be re-envisioned through innovative pedagogy, curriculum transaction, continuous professional development, dipstick surveys, and ICT implementation. The District Institutes of Education and Training will be developed as vibrant institutes of excellence for this purpose, she said.\nNoting that Lab Grown diamonds (LGD) is a technology and innovation and energy driven sector with high employment potential, Sitharaman said to encourage indigenous production of such diamonds, a research grant will be provided to one of the IITs for five years.\nAccording to the Ministry of Education, in order to implement the New Education Policy (NEP), 2020 in true spirit, the best institutions and universities of the country under the central government have been given an additional Rs 4,235.74 crores, which is an increase of 12.8 per cent over their allocation last budget.\nThe grant for University Grants Commission (UGC) has been increased by Rs 459 crores (9.37 pc). Grants to Central Universities have been increased by 17.66 per cent, Deemed University by 27 per cent, support to IITs have been increased by 14 per cent, and to NITs by 10.5 per cent as compared to BE 2022-23.\nFor breaking news and live news updates, like us on Facebook or follow us on Twitter and Instagram. Read more on Latest                        Exams & Results News on India.com.\nTopics"
  },
  {
    "body": "Comments\nExploring the Impact of Artificial Intelligence on the Future of Education: The Good, The Bad and The Ugly\nAs an educator, Ive always been captivated by the intersection of technology and education. I am constantly on the lookout for new and exciting ways to engage my students and enhance their learning experience. And let me tell you, the future is looking bright! With the rise of digital learning and the incorporation of Artificial Intelligence (AI) in education, the possibilities are endless.\nBut before we dive into the nitty-gritty of how AI is revolutionizing education, let me tell you a little bit about how I came to be so fascinated with this topic. It all started with a LinkedIn post I came across, discussing the impact of digital learning on the future of education. This got me thinking about the future of education and the role of technology in it. I couldnt help but wonder, what does digital learning look like? If I were designing a curriculum for the future, what aspects of digital (and non-digital) learning would I incorporate? And how can we use technology to make learning more engaging and interactive? In this blog, I want to explore these questions and share my thoughts on how we can use technology, specifically AI, to enhance the educational journey of students.\nThe Evolution of Education\nWeve come a long way from the days of chalkboards and textbooks. The world is changing rapidly, and education needs to keep up. With the rise of technology, the way we learn has also changed. The incorporation of digital learning in the classroom has brought about a whole new level of engagement and interactivity for students. But, its not just about incorporating technology for the sake of it. Its about finding the right balance between digital and non-digital learning to enhance the educational journey of students.\nExamples of Digital Learning in the Classroom\nOne example of digital learning in the classroom is the use of online quizzes and assessments. These tools allow teachers to quickly and easily assess student understanding and provide personalized feedback. For example, using a platform like Kahoot, teachers can create interactive quizzes that students can take on their own devices and receive instant feedback.\nEffective communication is 20% what you know and 80% how you feel about what you know.\nStephen Covey\nAnother example is the use of digital textbooks and interactive e-books. These resources provide students with multimedia-rich learning experiences, including videos, animations, and interactive activities that can help to engage and motivate students. Digital learning also allows for blended learning, where students can learn at their own pace and get tailored instruction, with the use of adaptive learning software. This software adapts to the students learning style and adjusts the instruction accordingly, such as ALEKS, Knewton, and Carnegie Learning.\nThe Good, The Bad, and The Ugly\nLets start with the good. Digital learning has the potential to make education more accessible and personalized for students. With the use of technology, students can access a wealth of information at their fingertips, allowing them to learn at their own pace and level. And lets be real, who doesnt love a good interactive game or virtual field trip?But, as with any new technology, there are also challenges. One major concern is the potential for digital distractions, such as social media and online games, to take away from the learning experience. And lets not forget the dreaded tech overload where students (and teachers!) can become overwhelmed with the constant bombardment of information and notifications.Now, the ugly. Despite the challenges, digital learning is here to stay and is only going to continue to grow in popularity. As educators, its our job to find ways to leverage the power of technology to enhance the learning experience, while also addressing the potential downsides.\nDesigning a Curriculum for the Future\nWhen designing a curriculum for the future, its important to consider the different aspects of digital learning that can be incorporated. From virtual reality to online resources, the possibilities are endless.For example, virtual reality can be used to transport students to different parts of the world or even different time periods, making history come alive in a whole new way. Online resources like videos, simulations and quizzes can be used to supplement traditional instruction and cater to different learning styles.But, its not just virtual reality thats making waves in the world of education. Artificial Intelligence (AI) is also playing a big role in shaping the future of education.\nThe Future is Here: How AI is Transforming Education\nWe are currently educating people out of jobs that dont yet exist, using technologies that havent been invented, in order to solve problems, we dont even know are problems yet.\nSir Ken Robinson\nThis statement highlights the importance of preparing our students for the future and equipping them with the skills they need to succeed in an increasingly digital world.\nOne way we can do this is by incorporating AI into our curriculum. AI has the potential to revolutionize education by providing personalized learning experiences, automating administrative tasks, and even grading assignments.\nAnother example of AI in education is through the use of AI-powered personal tutors. These tutors can analyse a students learning style and adjust the teaching methods accordingly. They can also provide real-time feedback, helping students to better understand and retain the material.\nAI can also be used to grade essays and assignments. This not only saves teachers time but also provides students with more timely feedback. With the help of AI, we can now make the learning experience more efficient and effective, which can lead to better outcomes for the students.\nAnother example is the integration of AI-powered chatbots. These can be used to assist students with homework and answer their queries, and to provide instant feedback on their work.\n\nExamples of AI in the Classroom\nPersonalized Learning:One of the biggest benefits of AI in education is its ability to personalize learning. By using data and machine learning algorithms, AI can adapt to the needs of each individual student and provide customized learning experiences.\nFor example, Knewton, an AI-powered learning platform, uses data on student performance to create personalized lesson plans for each student.\nAutomating Administrative Tasks:Another way AI can be used in education is by automating administrative tasks such as grading assignments, providing feedback, and even generating lesson plans. For example, Gradescope, an AI-powered grading tool, uses machine learning algorithms to grade assignments, providing teachers with more time to focus on teaching.\nCreating Interactive Learning Experiences:AI can also be used to create interactive and engaging learning experiences. For exam"
  },
  {
    "body": "A new Twitch livestream tries to answer the question: What if AI made never-ending Seinfeld? Nothing, Forever is an experiment using OpenAIs GPT-3 natural language model to produce (occasionally coherent) dialog between pixelated counterparts of Jerry, George, Elaine and Kramer. Although its closer to surreal performance art than the beloved 90s sitcom, it conjures images of a strange, dystopian future where we entertain ourselves with endless content generated by robots.\nNothing, Forever immediately hits you with well-known aesthetics. Scene transitions show the exterior of a line of New York City brownstones over the sound of a quirky jazz bassline. It frequently cuts to Larry (the Jerry equivalent) performing what AI passes as standup comedy. Scenes inside Larrys apartment show him chatting with George, Elaine and Kramer's counterparts about appropriately mundane topics. Their conversations, while mostly unintelligible and lacking structure or narrative, make their inspiration clear.\nOn the other hand, the stiff and rudimentary character models look like they walked out of a 1980s Sierra adventure game. Their voices are robotic too, and Jerry and George sound less like their real-world counterparts and more like Mr. Van Driessen, the hippie social studies teacher from Beavis & Butthead. Finally, its a stretch to say the generated dialog is coherent  much less funny. (If not for its laugh track, you wouldnt notice the laugh lines.) Generative AIs current limits are as much on display as the shows influence.\nTwitch\nAside from the artwork and the laugh track youll hear, one of the shows creators posted to Reddit, everything else is generative, including: dialogue, speech, direction (camera cuts, character focus, shot length, scene length, etc), character movement, and music. The stream has little human involvement and changes based on viewer feedback from the Twitch stream. The show can effectively change, and the narrative actually evolves based on the audience, said Hartle in an interview with Vice. One of the major factors that were thinking about is how do we get people involved in crafting the narrative so it becomes their own.\nThat goal may be far away, as any narrative  much less a personalized one  seems beyond its current capabilities. Still, with a sizable budget and several years of technological advancement, its easy to imagine someone producing more watchable generative programming, an endless stream of personalized, assembly-line digital media. Our grounding principle was, can we create a show that can generate entertaining content forever? Because thats truly where we see the future emerging towards. Our goal with the next iterations or next shows that we release is to actually trade a show that is like Netflix-level quality."
  },
  {
    "body": ";RAD\nhas raised over $2.5 million from retail investors, and some of the biggest companies in the world use its platform. The company is backed by Fidelity Investments and Expert Dojo, meaning institutional investors and venture capitalists are just as excited about this startup as retail investors.\nTo stay updated with top startup investments,\nsign up for Benzingas Startup Investing & Equity Crowdfunding Newsletter\nThe platform claims to increase return on investment (ROI) by as much as 300% for certain campaigns and averages a 100% increase for campaigns adopting RAD AI.\nIt seems many of the top companies in the world have taken notice of the platform, indicating there could be something to these claims. Noted customers include professional services firm Accenture, UBS, Crush Soda,\nThe platform takes in data, audits everything from blog articles to videos, then develops a plan to target the audience the team is trying to reach. When it determines that, it generates an optimized language message that can be shown to your target audience.\nThe process reduces the time required to launch a marketing campaign and significantly increases its ROI.\nRAD is in its early stages, but that hasnt stopped it from making big waves. As advancements in the space continue, AI will continue to grow in prominence and interesting startups will continue to surface.\nSee more on startup investing from Benzinga."
  },
  {
    "body": "Reddit\nSuneeta Reddy, Managing Director, Apollo Hospitals| Photo Credit:KARUNAKARAN M\nThe highest form of human intelligence is the acceptance and willingness to volve and learn. The Budget today has yet again showcased the governments forward looking approach to global trends and making India a strong destination for intelligence, R&D and talent.\nTechnology and knowledge focussed, the Budget this year has laid out a strong roadmap for Make AI in India and make AI work for India. The use of technology in healthcare is becoming increasingly important and the proposals to set up centres of excellence in AI will help foster interdisciplinary research and the development of scalable applications and solutions to many health problems.\nIt is hoped that this spurs public-private partnership in developing an effective AI ecosystem in healthcare with digital solutions that improve patient access to healthcare in remote and underserved areas. Digital health solutions such as telemedicine, electronic health records, and remote monitoring will benefit from these CoEs in AI and help improve patient outcomes.\nNot leaving it to the machines alone, there is high impetus in the Budget for focus on healthcase skiling and R&D. Efforts to establish 100s of nursing colleges, opening up ICMR lab infrastructure and resources for R&D while encouraging three-way partnership between public-private and academia and very bold moves on a roadmap to setup India as a global healthcare destination.\nThese skilling efforts can further dovetail into the Global Workforce Development vision which has the aim of developing 1 million trained and accredited healthcare resources by 2030 for the country, who can be used to serve India, and the greying world. This will create a vital momentum to encourage skilled healthcare manpower and raise the bar in terms of competencies that we offer the world.\nThere is a clear commitment to improving the overall health ecosystem and well-being of the Indian population and have a significant impact on making India a global health destination.\n(The author is the Managing Director of Apollo Hospitals)"
  },
  {
    "body": ",\nFeb. 1, 2023\n/PRNewswire/ -- WorkLLama, technology provider of an AI-driven, talent marketing, relationship management, and direct sourcing suite, today announced several game-changing features to its platform, highlighting its commitment to investment in its technology. These benefits center around WorkLLama's unparalleled ability to help organizations access highly skilled talent at scale and on demand.\nWorkLLama's continued investment in its shift management suite means full functionality is now available via its mobile app. Hiring managers and recruiters can leverage on-the-fly capabilities to quickly post and fill last-minute shifts. Users can chat with candidates in real-time, see who's checked in for a shift, know which shifts are unfilled or underfilled, and respond quickly to find additional talent. This functionality drives greater retention, productivity, and timely engagement with top talent.\n\"Shift work is a critical component for many industries including healthcare, manufacturing, retail, and more. The ability to find workers where they're at means they can easily apply for critical shifts,\" said\nSaleem Khaja\n, COO, WorkLLama. \"Our customers have seen a 42% increase in monthly engagement, a 23% increase in profitability, and an 81% decrease in absenteeism.\"\nAdditionally, WorkLLama's full content management system (CMS) provides customers with search engine optimized, branded career sitesa destination that offers next-gen talent marketing opportunities. The platform delivers massive impact for employers, including:\nEffortless branding to top talent\nSimple multimedia content management\nPersonalized job searches and performance insights\nNow, WorkLLama delivers consumer-grade talent experiences with career sites that highlight an employer's brand, keeping them ahead of the competition for talent.\n\"Our CMS makes it simple to attract, engage, and nurture talent like never before,\" said Sugandan Dinakaran, Head of Product for WorkLLama. \"Companies can market directly to top talent with personalized messaging, content, and job opportunities at scale, making talent attraction, retention, and redeployment easy.\"\nFinally, customers leveraging Sofi, WorkLLama's AI-driven conversational chatbot, can now have two-way conversations with candidates via WhatsApp. This functionality provides extended global reach and a seamless connection with talent.\nAbout WorkLLama\nWorkLLama is a total talent management and engagement suite. We create communities of highly engaged talent with a single, modern, AI-driven talent marketing, relationship management, and direct sourcing platform. Visit us at www.workllama.com. Follow us on LinkedIn.\nLogo -\nfrom 8 AM - 5:30 PM GMT"
  },
  {
    "body": "Posted on\nFebruary 1, 2023\nDocket Alarm, owned by Fastcase, has introduced a new tool using the artificial intelligence of GPT-3 that allows legal professionals to view summaries of litigation filings without having to open and read the underlying PDF document. The tool is a simple yet practical application of GPT-3, taking advantage of its ability to create summaries rather than generate content from scratch.\nTo use the tool, legal professionals simply mouse over the link to any document while browsing a court docket sheet. A pop-up appears with the option Create GPT Summary; within seconds, bullet points are displayed with a summary of the document. The feature is available to all Docket Alarm subscribers at no additional cost and works on any court or agency that Docket Alarm covers.\nThe summaries generated by the tool are not of the entire document but rather roughly the first 3,000 words, which Docket Alarm automatically captures as text and sends to GPTs Davinci model. The tool saves time for legal professionals, as they can quickly triage which documents they need to read in full and which they can skip over without having to download and view each attachment.\n\nWhere\nSearch Jobs\nDocket Alarm founder Michael Sander cautions legal professionals to rely on something other than AI-generated summaries, as they are experimental and not always perfect. He emphasizes that the tool is merely using AI to solve a small problem in the legal workflow and is not meant to replace lawyers. The summaries generated by the tool should be used as a preview tool but not for legal work or representing clients, as accuracy is only sometimes guaranteed.\nEd Walters, CEO of Fastcase, compares the tool to headnotes for legal cases. It manages the unstructured information in Docket Alarms PDFs, often in hundreds or thousands per case. He notes that the tool is not a magical robot lawyer but rather a method for text summarization to automate the tedious and time-consuming parts of the legal process.\nIn conclusion, Docket Alarms new tool is a step forward in using AI to improve the legal workflow and save time for legal professionals. It is not meant to replace human judgment but rather to assist legal professionals in managing vast information. The summaries generated by the tool should be used with caution and verified, as accuracy is not always guaranteed.\nGet JD Journal in Your Mail\nSubscribe to our FREE daily news alerts and get the latest updates on the most happening events in the legal, business, and celebrity world. You also get your daily dose of humor and entertainment!!\nSubscribe\nREFERENCES:\nDocket Alarm Now Uses GPT-3 To Show You Summaries Of PDF Litigation Filings As You Review Docket Sheets\nRelated Items:"
  },
  {
    "body": "Joshua Browder\n, appears to have found himself in.\nAs Techdirt explains, Browder's series of unfortunate events started roughly a week ago, when a paralegal named Kathryn Tewsen called Browder out on Twitter for what appeared to be pretty glaring errors in his company's tech. Online prompts designed to help users were questionable at best, and Tewsen, someone well-versed in legal jargon and proceedings, very easily poked a lot of holes in the AI tech's understandings of law. (Not a great look for a \"robot lawyer.\")\nTewsen noted these findings in a very detailed January 24 Twitter thread, which quickly picked up some viral steam. Shortly thereafter, Browder announced that his AI lawyer's first live court case, which was allegedly to take place in February, had been postponed  because, he claimed, he'd been threatened with jail time. For now, he said, DoNotPay would bring its focus back to\ndistracting\n\" cases like divorce proceedings.\nThe DoNotPay website, meanwhile, no longer allowed users to \"test documents,\" a feature that Tewsen had discovered significant flaws in. Suspect timing for, well, all of this, to say the absolute least.\nTewsen, per Techdirt, now convinced that the whole thing was more or less a publicity stunt to begin with, decided to investigate another pretty major Browder claim: that he according to a November 2022 Twitter post would buy and forgive $10 of medical debt for every \"[retweet] + follow\" earned by that tweet  and post receipts.\nReceipts were never posted, so Tewsen decided to inquire (on Twitter, of course.) Browder responded pretty saltily.\n\"Yes, I did donate,\" he wrote back, an image of a payment receipt to the nonprofit organization RIP Medical Debt in tow. \"Not sure why you are criticizing a donation.\"\nThat receipt, importantly, was marked as being paid on December 2, 2022, a few weeks after Browder's initial medical debt hype tweet. And as it turns out, the tech CEO did make a donation. He just didn't make it when he said he did.\n\"I have no reason to believe that Josh faked his donation to the debt-relieving nonprofit RIP Medical Debt,\" the paralegal tweeted, upon the realization that the image looked very, very photoshopped.\n\"But based on this?\" she continued, \"I don't think he did it on December 2, 2022.\"\nAnd sure enough: in an email reviewed by Techdirt, RIP Medical Debt confirmed to Tewsen that Browder had indeed made a $500 donation, but he'd made that donation on January 29  just four minutes after Tewsen had called him out for failing to follow through with his cash-forward publicity stunt. Browder's shoddy photoshop work was tweeted just 17 minutes after that.\nBrowder has unsurprisingly deleted the tweet promising to pay medical bills. And at the end of the day, this is, again, all astonishingly ridiculous  but also a little infuriating, given that this guy has raised many millions in funding cash from top-dollar VCs, including Marc Andreessen and the folks at Founders Fund. Not exactly genius moves on Browder's behalf, and we should probably all expect more from the people raking in this kind of investor interest.\nMaybe, just maybe, we should be a little more skeptical of genius wunderkinds who just say whatever on Twitter.\nREAD MORE: DoNotPay's CEO Appears To Modify Donation Receipt After Being Called Out On Unfulfilled Promise [Techdirt]\nMore on DoNotPay's \"court case\":"
  },
  {
    "body": "Click to print (Opens in new window)\nA ChatGPT prompt is shown on a device near a public school in Brooklyn, New York, Thursday, Jan. 5, 2023. New York City school officials started blocking this week the impressive but controversial writing tool that can generate paragraphs of human-like text. (AP Photo/Peter Morgan)\nBy Doug McIntyre | Doug@DougMcIntyre.com | Daily News\nPUBLISHED:\nFebruary 1, 2023 at 7:00 a.m.\n| UPDATED:\nFebruary 1, 2023 at 9:25 a.m.\nArtificial intelligence (AI) has the potential to revolutionize the way we live and work, but it also poses significant risks to society. As we continue to develop and deploy AI systems, it is crucial that we understand and address the dangers they pose.\nOne of the major concerns about AI is its potential to displace human workers. As machines become more capable and efficient, they are likely to take over jobs currently done by humans, leading to widespread unemployment and economic inequality. Additionally, AI systems can perpetuate and amplify biases in the data they are trained on, leading to discriminatory outcomes.\nAnother concern is the potential for AI to be used in ways that are harmful to society. Autonomous weapons, for example, could be used to conduct warfare without human oversight, leading to unpredictable and potentially catastrophic consequences. AI-powered surveillance systems could be used to monitor and control populations, violating privacy and civil liberties.\nThere is also the risk that AI systems could become uncontrollable and pose a threat to humanity. As AI systems become more advanced, they may be able to outsmart their human creators and make decisions that are not in our best interests.\nNow, heres the really scary part  everything you have read up until now was written by something called ChatGPT, a new AI software program that threatens to upend life as we have known it.\nChatGPT (an acronym for Generative Pre-trained Transformer) is capable of rapidly processing large amounts of text in natural language, including highly personal and stylistic writing.\nHeres how I wrote todays column. I opened a free account at chat.openai.com. I typed in, Write an 800-word essay on the dangers of AI in the style of Doug McIntyre. In less than 60 seconds, the program wrote the opening seven paragraphs of todays column. Pretty amazing, huh?\nOf course, this is still the early stages of development. Think Google in 1998. That didnt stop Microsoft from investing $10 billion last month. ChatGPT is going to get bigger, faster and more sophisticated and very quickly. Still, my first dip into the AI pool failed in several key respects. First off, instead of 800 words, it gave me only 450, and I specifically requested in the style of Doug McIntyre. Instead, I got an essay with crisp, clean, grammatically correct sentences, no dumb attempts at humor or cheap shots at local elected officials and zero spelling errors. So, not my style at all.\nStill, wow!\nCan you imagine a school teacher or college professor who not only has to worry about the woke police coming for him/her/they, or getting shot by a lunatic, but now has ChatGPT to contend with? The days of plagiarizing a book report from Cliff Notes are over. I asked ChatGPT for a summary of John Steinbecks, The Grapes of Wrath. Thirty seconds later I had this:\nRelated Articles"
  },
  {
    "body": "Share to Linkedin\nCEO of\nQlik, driving the mission to create a data-literate world where organizations tackle their most complex challenges with data.\ngetty\nBusiness intelligence and analytics are a powerful force in driving decision-making and giving companies a central engine for data on business KPIs. With adoption of self-service options and integration of data from a growing number of sources over the past few years, weve closed the gap on delivering timely and relevant insights to all levels of the enterprise.\nAn evolution is now underway in analytics that will bring about a new era in enterprise decision-making. A flow of real-time data, when combined with artificial intelligence (AI), is expanding the ability of everyone in the business to both make decisions with more certainty and leverage data to plan for whatever might come next.\nA significant shift has taken place over the past few years in the way enterprises are deploying AI. AI and machine learning arent just limited to data scientistsalthough organizations will certainly still rely on those experts for the most complex and hardest problems. Instead, AI is being embedded into a wide range of daily processes throughout the organization.\nThis change is bringing more clarity and effectiveness through real-time information to staff at every level. Recent research from Boston Consulting Group in collaboration with MIT Sloan Management Review does a great job\n: New research shows that employees derive individual value from AI when using the technology improves their sense of competency, autonomy and relatedness.\nMORE FOR YOU\nTourism Numbers Trending High Post Pandemic\nThe democratization of AI is happening across every industry. Through technologies like automated machine learning (AutoML), people who arent trained in data science now have the ability to see suggested courses of action and alternate paths based on data directly related to their roles.\nThat last part is the most important change thats happening. AI models arent being blindly applied to everything in the organization. Rather, they are being tailored by data teams and delivered in a \"data as a product\" model, which is making it much easier for staff to comfortably use AI and see how it helpsnot hinders or replacestheir ability to make decisions.\nAI-fueled analytics, when combined with more relevant data now available through the cloud, is the way decisions should be made in a world of constant market shifts. It helps everyone in the organization align on initiatives to drive lower risk, create better processes, increase customer satisfaction and deliver better environmental impacts.\nAI Helps Create Certainty In A Changing World\nThe last few years are full of examples where the tailored use of AI could have helped organizations pivot more quickly to proactively address unfolding world events. For example, a shipping company could have examined the pros and cons of going through the Suez Canal during the blockage, determining whether it made more sense to consider going around Cape Horn. A retail store manager could have evaluated inventory levels, store traffic patterns, existing pricing plans and discounts to maximize their holiday shopping revenue opportunities as we exited the worst of the Covid-19 pandemic.\nAI is at the center of predictive analytics that help identify patterns that managers or other employees might miss. That same shipping company could determine the best ports at which to unload its containers as strike threats spread through the industry. Staffing executives can be warned if theyre about to schedule someone into overtime when other employees are available.\nIn all of these cases, the AI is not making the decision. Instead, it is increasing decision-maker confidence since choices can be made based on current data and by picking the best of multiple possible scenarios.\nThe Path Forward With AI\nThe good news is that AI is already making its way into many systems in the workplace. Last year, 56% of the respondents to McKinseys State of AI Report said they used it in at least one business function. Thats a 6% jump over 2020. Nearly two-thirds of the companies surveyed said they planned to increase their investments in AI technology through 2025.\nWhats important to keep in mind is that AI can only go so far. Yes, it can help automate some processes and alleviate manual data work, but it cant and shouldnt be the ultimate decision-maker. Humans still need to layer a real-world perspective on what AI and the data are showing them in order to make the best decisions.\nLeadership will play a crucial role in allaying fears and helping employees understand that AI actually enhances their value to the organization and isnt a replacement strategy. In fact, it's actually expected to create more positions than it replaces\nas many as 12 million more\n, according to the World Economic Forum. The BCG research shows us a strong path forward. When individuals are a) required to use AI, b) given proper training through data literacy, c) provided a clear understanding of how it can assist in their roles and d) are aware of the value they create for the organization, AI adoption and comfort soar alongside the bottom-line benefits.\nThe wider use of AI, data and analytics are helping professionals at every level make smarter decisions, create new opportunities and apply modern technology to advance their skills and careers. Leaders who design effective AI strategies will help their staff understand how it drives performance and will set their organizations up for competitive advantages today and moving forward."
  },
  {
    "body": "Published on\nFeb. 1, 2023\nAs technology has developed, its felt as though the line between PC and console gaming, once vast, has significantly thinned. We now have consoles that have online, graphics settings, and even keyboard and mouse support. Many things previously thought impossible on consoles are now simple. But a few types of game remain largely the purview of PC players  most notably, the real-time strategy genre.\nThere have been a number of attempts over the years, of course. I have fond memories of those slightly-crap console ports of the earliest Command & Conquer games, and then C&C actually managed some pretty damn good controller-based releases of C&C3 and Red Alert 3. Id argue those games have a direct lineage in control scheme to Halo Wars. Halo Wars was a decent bit of fun  and now another Microsoft strategy stalwart is entering Game Pass on console. Age of Empires has hit Xbox, with a raft of improvements and tweaks to make it more accessible and easily playable on console, regardless of what control method you choose.\nThe Xbox launch trailer shows how impressive a feat Age of Empires II on console really is.\nFirst up is Age of Empires 2: Definitive Edition, a strong re-release with a beautiful 4K visual overhaul and a smattering of new content that was first released on PC in 2019. This release truly is definitive, featuring everything from the original game, plus a smattering of new additions, and even the option to choose between the original 1999 enemy AI and more advanced versions.\nThe complete package now makes its way over to Xbox, acting both as an exciting release in its own right and as a sort of prelude to the much more contemporary Age of Empires 4, which is coming to Xbox later this year.\nThis wasnt a simple matter of a port, however  because this is a genre that cant just be dumped onto console. Compromises and adjustments have to be made, and this definitely appears to be a title that has placed a considerable emphasis on finding a truly elegant control input solution rather than simply muddling out some good enough offering.\nPlaying this on console... that was once a pipe dream.\nOur team conducted a significant amount of research and prototyping during development, Alex Liu, design director at AOE developer Worlds Edge reveals. We discovered quickly that simply porting our deeply PC-centric game to Xbox was not going to provide the right gameplay experience.\nTo truly deliver a gold standard console strategy game, we needed to rethink and rebuild everything from the ground up, and do what was right for console. This meant new controls, new UI, new features, new tutorials, everything.\nAll console RTS ports have gone through some degree of iteration to even work, and even then not all avoid being headache-inducingly fiddly. But through experimentation, the Age of Empires team happened upon a single solution that could significantly lessen many of the genres controller-based ills  and its all about artificial intelligence.\nAI automation and site-based commands were our biggest game-changers during development, Liu says of the console versions most significant addition.\nBoth features are brand-new to the Age franchise, and resolved many of our outstanding design challenges, and at the same time, will significantly lower the barrier of entry for new players.\nWhich faction will you play as?\nEarly prototypes of the console version didnt have this feature, but Liu notes that the team quickly noticed that the intense and repetitive aspects of managing your villagers and other base units was proving to be taxing on players  both in terms of mentally staying on top of everything and physically executing it. Hopping around the map and performing micro is a hell a lot easier on keyboard and mouse - but on controller, things are more sluggish, upping the stress level.\nThe solution? An AI automaton that steps in and helps players take care of more of that stuff automatically, which allows players to shift their focus onto the larger-scale strategic decisions that will actually shape the flow of a match. The AI can be cycled between preset approaches with the right stick. And if you feel you can do better without it, you can turn the AI automation off. Leave it on, however, and itll really hammer through that classic RTS busywork on your behalf.\nOnce active, a player can direct Villagers to gather each resource based on selected ratio. We have created presets designed for many common economic needs, and experienced players are welcome to manually adjust the ratios after enabling the Advanced Interface profile. The automation will affect all Villagers, including idle and newly created ones. They will gather appropriate nearby resources and can even auto-build farms.\nDuring the AI development, we took great care to ensure that it does not take away players initiative for strategic thinking. All strategically meaningful actions, such as training Villagers, building Houses, building resource drop-off structures, herding sheep, hunting boar, or scouting for more resources, remain firmly in the hands of the players.\nThe AI system is inactive at the beginning of each game and can be manually turned on or off at anytime. The auto-Farm function can also be enabled or disabled.\nIt's a wonder what technology can do.\nNaturally, this leaves a little bit of concern for balance. As does the inclusion of cross-platform play to allow controller players face off against PC warlords and even keyboard and mouse support on Xbox, meaning theres no guarantee that all console players are on controller. Im old enough to remember the hand-wringing and endless debates about the Xbox 360 Shadowrun reboot having cross-play, and how the KBM players would smoke the pad players every time.\nTheres potential for that again here, but Worlds Edge has strongly considered every aspect of Age of Empires 2 on console to avoid it. For a start, cross-play with PC is optional for controller players  but if you plug a keyboard and mouse into your Xbox, youll be thrown in at the deep end with all the PC vets. That seems fair.\nAge is ultimately a game of strategy. We hope that, for all players except ones at the highest competitive level, the deciding factor for victory should be strategic decision-making, not actions per minute, Liu explains.\nFor what its worth, its bloody good. Ive had a bit of a toy around, and the controls are intuitive and effective, and are actually probably a good bit superior to those 360-era Command & Conquer control schemes that I also found more than acceptable. A lot of it is down to the shortcuts, like how the game alerts you if theres idle villagers and lets you instantly skip to them with a single button so you can un-idle them. Theres also a lovely button  I have to give Halo Wars credit for this one  that just selects all military units, ready to roll them towards the enemy.\nCommand all this, intuitively.\nThe thing about Age of Empires is that compared to a lo"
  },
  {
    "body": "Email\nPhoto by Lionel BONAVENTURE / AFP) (Photo by LIONEL BONAVENTURE/AFP via Getty Images\nThis picture taken on Jan. 23, 2023, in Toulouse, southwestern France, shows screens displaying the logos of OpenAI and ChatGPT, a conversational artificial intelligence software application developed by OpenAI.\nOpenAI, the company that launched ChatGPT, announced on Tuesday it has created a tool that can tell the difference between text generated by artificial intelligence (AI) and text written by a human.\nThe classifier the company created, by its own admission, is not always 100 percent accurate in distinguishing between the text.\nWhile it is impossible to reliably detect all AI-written text, we believe good classifiers can inform mitigations for false claims that AI-generated text was written by a human: for example, running automated misinformation campaigns, using AI tools for academic dishonesty, and positioning an AI chatbot as a human, the company said in a blog post.\nThe announcement comes after ChatGPT rose quickly in popularity, especially among students, for its ability to give human-like responses to questions and turning the responses into things such as essays or emails.\nThe program also brought a wave of controversy in education as ChatGPT gives different answers to the same questions, making it impossible to tell if a student used ChatGPT to write their essay or assignment.\nAs a result, New York City and Seattle Public Schools banned the chatbot from their servers, citing concerns of cheating and a lack of critical thinking skills needed with the program.\nThe company responded by saying it was working with schools to ease their concerns.\nThe classifier made in response is very unreliable for catching AI-generated text for writing under 1,000 characters, but gets more reliable the longer the text is, according to the company.\nIn our evaluations on a challenge set of English texts, our classifier correctly identifies 26% of AI-written text (true positives) as likely AI-written, while incorrectly labeling human-written text as AI-written 9% of the time (false positives), the company said.\nThe company added that it is launching the imperfect tool to get feedback and will continue to work on ways to detect AI text."
  },
  {
    "body": "In what is being perceived as the new frontier for cooperation with an eye on China, India and the US have decided to deepen cooperation on defence, artificial intelligence, quantum technologies, high-performance computing, co-production of jet engines, semiconductor supply chains, human spaceflight, commercial space launches, telecom technologies including 6G. These are the major takeaways from the meeting held between National Security Advisor Ajit Doval and US NSA Jake Sullivan in Washington DC over the past two days. The two NSAs met for the first meeting of the US-India initiative on Critical and Emerging Technology (iCET), which was decided between Prime Minister Narendra Modi and US President Joe Biden in May 2022 on the sidelines of the Quad meeting in Tokyo. The list of new initiatives are the following: A new bilateral Defence Industrial Cooperation Roadmap to accelerate technological cooperation for joint development and production of jet engines, munition related technologies.  The US has received an application from General Electric to jointly produce jet engines that could power jet aircraft operated and produced by India. The US committed to expeditious review of the licence application submitted by M/s General Electric to produce jet engines in India for the indigenously manufactured Light Combat Aircraft, the Indian statement said.  Long-term research and development cooperation, with a focus on identifying maritime security and intelligence surveillance reconnaissance operational use cases. A new Innovation Bridge that will connect US and Indian defence startups. Collaboration on high-performance computing (HPC), including by working with US Congress to lower barriers for US exports to India of HPC technology and source code. A new Implementation Arrangement for a Research Agency Partnership between the National Science Foundation and Indian science agencies to expand international collaboration in a range of areasincluding artificial intelligence, quantum technologies and advanced wireless technology.  Joint Indo-US Quantum Coordination Mechanism with participation from industry, academia and government to facilitate research and industry collaboration. Collaboration on resilient semiconductor supply chains; supporting the development of a semiconductor design, manufacturing and fabrication ecosystem in India. A task force organised by the US Semiconductor Industry Association in partnership with the India Electronics Semiconductor Association with participation from the Government of India Semiconductor Mission to develop a readiness assessment to identify near-term industry opportunities and facilitate longer-term strategic development of complementary semiconductor ecosystems.  Cooperation on human spaceflight, including by establishing exchanges that will include advanced training for an Indian Space Research Organisation (ISRO) or Department of Space Astronauts at NASA Johnson Space Center.  New STEM talent exchanges by expanding the Professional Engineer and Scientist Exchange Program (PESEP) to include space science, earth science and human spaceflight.  Strengthen commercial space partnership, including through a new US Department of Commerce and Indian Department of Space-led initiative under the US-India Civil Space Joint Working Group. This initiative will foster US-India commercial space engagement and enable growth and partnerships between US and Indian commercial space sectors.  Advancing cooperation on research and development in 5G and 6G, facilitating deployment and adoption of Open RAN in India, and fostering global economies of scale within the sector.  Launching a public-private dialogue on telecommunications and regulations.  A new joint task force of the Association of American Universities and leading Indian educational institutions, including Indian Institutes of Technology, which will make recommendations for research and university partnerships. A White House statement said the United States and India affirm that the ways in which technology is designed, developed, governed, and used should be shaped by our shared democratic values and respect for universal human rights. We are committed to fostering an open, accessible, and secure technology ecosystem, based on mutual trust and confidence, that will reinforce our democratic values and democratic institutions. It also said that the two countries looked forward to the next iCET meeting in New Delhi in 2023. The National Security Councils of both countries will coordinate with their respective ministries, departments and agencies to advance cooperation and engage with stakeholders to deliver on ambitious objectives ahead of the next meeting, it said. Apart from his meeting with NSA Sullivan, Doval also met Chairman of the Joint Chiefs of Staff General Mark Milley, Acting Secretary of Defense Kathleen Hicks, key senators and industry leaders. He is scheduled to meet US Secretary of State Antony Blinken later during the visit. During the meetings, the NSA was accompanied by Indian ambassador Taranjit Singh Sandhu; principal scientific advisor Ajay Sood; G Satheesh Reddy, scientific advisor to the defence minister; ISRO chairman S Somanath; telecom secretary K Rajaraman; and officials from NSCS."
  },
  {
    "body": "LISTEN\n Peter Morgan/AP\nFrench university Sciences Po is one the first higher education institutions to ban the use of the artificial intelligence text generator ChatGPT to complete assignments, in order to prevent fraud and plagiarism. The company that created ChatGPT said it has released software that educators can use to detect AI-generated text.\nSciences Po sent a message to all students and faculty announcing a ban on all AI-based tools by students and faculty in the network, based in Paris, with campuses around France, including Lille, Toulouse and Grenoble.\nThe use of ChatGPT, or any other tool using AI, without the transparent referencing is strictly forbidden in the academic space, wrote provost Sergei Guriev.\nThe decision is a first for a French university, and Sciences Po said the penalty for using the tools would be expulsion from the institution\" or even a ban from French higher education as a whole, though it did not specify how the use of the tools would be detected.\nUniversities and schools around the world have been debating the use of ChatGPT, which was released in November and can be used to generate text in response to simple prompts that can be taken for human writing.\nIn an experiment, professors at the University of Minnesota Law School had the chatbot answer questions from final exams in several subjects, including constitutional law and taxation, and when graded alongside student answers, it consistently achieved low, but passing grades.\nAI cannot be ignored\nMany French students have been using ChatGPT to write homework assignments, but Guillaume Leboucher, who created the AI for school foundation, at the Institut de France, is not concerned.\nInstead of banning the use of ChatGPT, he would like educators to see it as a tool  a new generation of search engine that allows users to interact in simple, human text.\nThe interface has the potential to radically change our relationship with AI in our daily lives,\" he told RFI.\nWhile there are ethical issues raised by its use by students, we encourage teachers to have students use ChatGPT, to play with it, while warning them that it will not help them get better grades on their homework if they just cut and paste text generated by a chatbot.\nThe challenges related to the AI-based language generation tools will necessarily and rapidly change teaching and evaluation practices, Sciences Po provost Guriev wrote.\nWe know very well that it will be part of the digital ecosystem, Sciences Po's Directof of Studies, Myriam Dubois-Monkachi, told FranceInfo radio. \"How do we live with it?\nIn order to block students' use of the tools, some schools have announced plans to assign fewer take-home writing projects and have more oral and hand-written exams.\nUnreliable detection tools\nMany are looking for software tools to detect AI-generated text. Some third-party tools, including GPTZeroZ have already been created.\nOpenAI, the creator of ChatGTP, which has received billions of dollars of investment from Microsoft, released its own detection tool on Wednesday.\nIn a blog post, the company said that its AI classifier is a language model trained with pairs of human and AI written text on the same topic.\nWe recognise that identifying AI-written text has been an important point of discussion among educators, and equally important is recognising the limits and impacts of AI generated text classifiers in the classroom.\"\nThe company said the classifier is unreliable, particularly on short texts of fewer than 1,000 characters.\nIt also says the classifier is not as effective on non-English languages, making it of limited use for schools like Sciences Po.\n\"We're making this classifier publicly available to get feedback on whether imperfect tools like this one are useful,\" OpenAI said."
  },
  {
    "body": "FBI searches Biden's Rehoboth home in connection to documents probe\nTom Brady says he's retiring from the NFL \"for good\"\nHow to watch Tyre Nichols' funeral service\nIce storm cancels flights, leaves 250K without power in Texas\nGOP-led states ask judge to end DACA policy for \"Dreamers\"\nCDC tells consumers to stop using Ezricare Artificial Tears\nNew York City finally sees measurable snow after long wait\nNikki Haley to announce 2024 presidential run on Feb. 15\nBeyonc announces Renaissance world tour\nShows"
  },
  {
    "body": "Download MP3\nSubscribe (68)\nTheyre never gonna tell you anything is my guess...This is how it's gonna go folks. It hit me a couple days ago like a ton of bricks. The targeted individual program or \"Non-Compliant Individual\" program IS what this will be. It will be as if everyone is targeted basically. Shadowbanned from everything but the problem isn't that. The problem.is... you'll never know when it's them, when it's the company, ifbits your phone, may e you made a mistake. . Maybe try that again... or yet again... it's maddening and there's no way out unless you're willing to walk away. Drop the device, step away and leave. If you're one foot in and you need the system but you got one foot out so the system ain't working for you, you're gonna lose your mind. I promise you, this is the unspoken piece no one is mentioning. It drives you MAD. It's relentless. It doesn't stop. And after 2 years, (2018 to early 2020)the only thing I ever managed to do was maybe get in the way a little bit? Im not a techy tho...It was VERY thorough and was a warming the Pegasus, Prism and CORPSE programs. These programs are what this is gonna be and I suspect our devices are are already loaded with them. It used to be right in your apple.analytics. thays how i knew about em although, then, there wasnt anything out about em then. That's what  I have done... this is real guys. This world can be lost. Reality can be lost....you can be lost. REMEMBER this video. The time will come when you realize that what you're experiencing is what I was talking about in this video... i hope this helps. Folks, plan on being w out your device. Period. Done. Get a hammy, strip that sucker down... use that if you must. You're up against AI now yall. We ain't in Kansas you guys... Tin man has no brain and is leading the country off a cliff. Scarecrow ain't working anymore. The crows don't care and the Lion took a shit on his courage. Time is arriving fast folks. It's already started.\nKeywords"
  },
  {
    "body": "Whats the World Economic Forum doing about climate change?\nShow more\nDon't miss any update on this topic\nCreate a free account and access your personalized content collection with our latest publications and analyses.\nSign up for free\nLicense and Republishing\nWorld Economic Forum articles may be republished in accordance with the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International Public License, and in accordance with our Terms of Use.\nThe views expressed in this article are those of the author alone and not the World Economic Forum.\nRelated topics:"
  },
  {
    "body": "As one of the largest businesses in the world, Amazon is an instantly recognisable brand name.\nBut the Internet retail giant wasn't always named after the world's largest river.\nAmazon founder Jeff Bezos was actually forced to change the original name of the company after a lawyer misheard it as something a bit morbid.\nREAD NEXT:\nUK Amazon workers strike over 50p pay rise saying 'robots are treated better'\nWhen it began as an online bookshop in 1994, Amazon was actually called Cadabra, Incas in 'abracadabra'.\nBut a few months after Bezos launched the firm from a garage in Washington, a lawyer misheard the company name as 'cadaver', i.e. a corpse.\nBezos said brand names are more important online than offline\n(Image: AFP via Getty Images)\nRead More\nAI clone under fire over fake Emma Watson reading Hitler and Attenborough rant\nBezos decided to ditch the name to avoid any potential confusion, and pick something else out.\nEver a creative mind, he picked up a dictionary and began flicking through it. It didn't take long to get to Amazon, obviously.\nBezos said he thought the name would be 'exotic and different' and that, as the world's largest river, 'Amazon' fit his vision for building the world's biggest online bookshop.\nIt's also early in the alphabet, which means Bezos didn't have to waste time reading all the way through to those pesky 'Qs' and 'Zs'.\nJeff Bezos founded Amazon in a garage back in the 1990s\n(Image: Getty Images)\nAI can now make its own music - and it could put Ed Sheeran out of a job\nIn 1997, Bezos told Inc magazine: \"There's nothing about our model that can't be copied over time. But you know, McDonald's got copied. And it still built a huge, multibillion-dollar company.\n\"A lot of it comes down to the brand name. Brand names are more important online than they are in the physical world.\"\nEarlier this month, Amazon workers went on strike in the UK for the first time, with 300 staff walking out of the company's Coventry warehouse over a 55p pay offer.\nREAD MORE:"
  },
  {
    "body": ",\nFeb. 1, 2023\n/PRNewswire/ -- Digital Diagnostics maker of IDx-DR, the first-ever FDA-cleared, fully autonomous AI system for the diagnosis of diabetic retinopathy  announced today a strategic partnership with Tamer Healthcare  an integrated healthcare and wellness firm with more than 100 years of established business in the\nKingdom of Saudi Arabia\n to further enhance healthcare and innovation in the\nKingdom of Saudi Arabia\n.\nThe strategic partnership initially focuses on the distribution of Digital Diagnostics flagship product, IDx-DR, for the detection of diabetic retinopathy (including macular edema) with plans for future artificial intelligence (AI) technology development and expansion. The Saudi Arabian population represents one of the world's most acute needs for such innovative technology, with over 8 million people at risk of vision loss due to diabetes.\nTamer Healthcare and digital diagnostics will also work together with the goal of developing additional AI healthcare applications in conjunction with the Saudi Localization Plan.\n\"This long-term partnership aims to further enhance healthcare and innovation in the Kingdom as part of Saudi Vision 2030,\" said\nDana Cooney\n, VP of International Sales at Digital Diagnostics. \"Most importantly, this partnership signifies Digital Diagnostics' commitment to foster investment in the Kingdom by developing innovative healthcare solutions rooted in AI that create access to affordable and high-quality care for the people of the\nKingdom of Saudi Arabia\n.\"\n\"We look forward to leveraging this partnership to facilitate the advancement of healthcare innovation for the benefit of the nation,\" said Dr.\nYasser Khattab\n, CEO of Tamer Healthcare. \"Deploying new technology in tandem with a company that has successfully developed and deployed this type of system will help expedite the process in the Kingdom and foster continued local innovation and technology solutions.\"\nAbout Digital Diagnostics Inc.\nDigital Diagnostics Inc. is a pioneering AI diagnostics company on a mission to transform the quality, accessibility, equity, and affordability of global healthcare through the application of technology in the medical diagnosis and treatment process. The company, originally founded by\nMichael Abramoff\n, MD, PhD, a neuroscientist, practicing fellowship-trained retina specialist, and computer engineer, is led in partnership with co-founders\nJohn Bertrand\nSeth Rainford\n.\nDigital Diagnostics is paving the way for autonomous and assistive AI diagnosis to become a new standard of care, contributing to democratizing healthcare and closing care gaps. The company works closely with patient advocacy groups, federal regulators, and other quality of care and ethics-focused stakeholders to enable the adoption of autonomous AI. Digital Diagnostics IDx-DR system does not replace a full - comprehensive seven-point - eye exam. For more information and the latest news follow:"
  },
  {
    "body": "SETI: Alien hunters get a boost as AI helps identify promising signals from space\nby Michael Garrett,   The Conversation\nThe new study analysed data gathered at the Green Bank Observatory in West Virginia. Credit: Shutterstock\nAn international team of researchers looking for signs of intelligent life in space have used artificial intelligence (AI) to reveal eight promising radio signals in data collected at a U.S. observatory.\nThe results of their research, published in\nNature Astronomy\nare remarkable. The team hasn't yet carried out an exhaustive analysis, but the paper suggests the signals have many of the characteristics we would expect if they were artificially generated. In other words, they are the kinds of signals we might pick up from an extraterrestrial civilisation broadcasting into space.\nA cursory review of the new paper suggest these are indeed promising signals. They're much more compelling than what is perhaps the most famous SETI candidate, the \"Wow!\" signal, radio emission bearing the hallmarks of an extraterrestrial origin that was collected by an Ohio telescope in 1977.\nRealistically, it's most likely that these eight new signals were generated by human technology. But the real story here is the effectiveness of AI and the techniques used by the team to dig out rare and interesting signals previously buried in the noise of human-generated radio frequency interference, such as mobile phones and GPS.\nAstronomers working in the field of SETI (the search for extraterrestrial intelligence) must filter out interference produced by radio communications here on Earth.\nIn this case, Peter Ma from the University of Toronto and his colleagues unleashed a set of algorithms on a mountain of data collected by the Green Bank Telescope in West Virginia, US. The data was gathered through a SETI initiative called Breakthrough Listen, established in 2015 by the investor Yuri Milner and his wife Julia.\nHere are the characteristics astronomers look for in signals that could be artificially-generated: firstly they are narrow-band, which means that where the radio transmission is confined to only a few frequency channels. They also disappear as the telescope is moved to another direction in the sky, and they exhibit \"Doppler drifting,\" where the frequency of the signal changes in a predictable way with time. We would expect Doppler drifting because both the transmitteron a distant planet, for exampleand the receiver, on Earth, are moving.\nBuried in the noise\nThe Breakthrough Listen project's first candidate signal, called BLC1, was first announced in 2020. But it was later traced to transmissions associated with cheap electronic devices on this planet. The application of AI techniques to the Breakthrough Listen observing program, however, is a potential game changer for the field. Even seasoned SETI researchers are beginning to think that we might be on the cusp of a momentous scientific breakthrough.\nThis may explain renewed interest by groups around the world that are planning for SETI success. For example, a SETI post-detection hub has been set up at the University of St Andrews in Scotland. This will study how humans should react if we discover we are not alone in the Universe.\nThe International Academy of Astronautics (IAA) SETI permanent committee oversees the SETI post-detection protocols, which outline what steps scientists should take in the event of detecting a genuine signal. The IAA has opted to update the text of the protocols sometime later this year.\nBut the new study highlights a problem with previous signals of interest. When the team took another look at the stars associated with the eight narrow-band transmissions, they could no longer detect the signals.\nIt would not be surprising if many, and perhaps the vast majority of bona-fide SETI signals, were isolated events. After all, what are the chances that we point our telescopes in exactly the right direction, at the right time and with the right frequency on multiple occasions?\nMissing ingredients\nAs I argued here a few years ago, SETI surveys would greatly benefit from employing multiple radio telescopes, operating in a manner that's known as a classical interferometer network.\nThese telescope arrays (groups of several antennas observing together) generate huge amounts of data. With AI onboard, the challenge is perhaps more manageable than previously thought.\nBreakthrough Listen is already using telescope arrays such as MeerKAT in South Africa for SETI searches. In Europe, researchers have been experimenting with arrays that span the globe.\nThis European approach would help us isolate signals from human-made interference, give us multiple independent detections of individual events, and permit us to localize signals to individual stars and possibly orbiting planets.\nAmong the future projects is the Square Kilometer Array, an international project to build the two largest telescope arrays in the world, which will be based in Australia and South Africa. Another upcoming project is the next generation VLA (ngVLA), a series of linked telescope facilities that will be spread across the United States. These radio telescope arrays will be even more sensitive than current instruments.\nIt's my beliefand indeed hopethat somewhere out there intelligent beings are waiting to be discovered. The AI revolution might be the missing ingredient that previous endeavors have lacked. In particular, AI algorithms will eventually evolve into powerful tools that no longer suffer from human biases.\nLord Martin Rees, chairman of the Breakthrough Listen advisory board and the astronomer royal, has proposed that if we do find aliens they are likely to be intelligent machines operating in the depths of space, unconstrained by the biological limitations placed on humans.\nIf we ever do find a bona-fide signal, it could just be that it's mediated by machines on Earth and in space.\nJournal information:"
  },
  {
    "body": "are used in healthcare:\n1. Accurate diagnosis\nMisdiagnosis is a primary concern for both patients and healthcare professionals. Doctors can accurately analyze MRI reports, CT scans, and other types of images using AI development services and digital medical tools like computer vision.\n2. Virtual assistants\nApplications of AI in healthcare help with tasks like reminding patients about impending medical appointments and directing people to the appropriate hospital or doctor to match their medical needs.\nTheir availability around-the-clock is one of their advantages for patients and healthcare facilities. Without a doubt, such software goes beyond the conventional voicemail decision tree to a process that utilizes AI technology in healthcare to make wise selections based on examining patient data and input.\n3. Risk analysis\nTo provide preventative care, you can identify individuals at risk of contracting a particular disease using a pattern recognition algorithm. Healthcare practitioners, on the other hand, can make wise decisions with timely insights by utilizing applications of AI in healthcare.\n4. Radiology\nIn radiology, doctors manually evaluate the patients medical records and photographs to find disease. With AI technology in healthcare on the field, the time needed to do the same activity is multiplied, and the procedure is hassle-free for both the patient and the doctor.\nAI applications in healthcare can considerably enhance patient care since they optimize several workflows, saving time and money that can then be applied to the patients care. On the other hand, applications of AI in healthcare also produce a ton of useful data during the process that wasnt previously available.\n5. Workflow administration\nOne-sixth of doctors working hours are spent on administrative chores that have no influence on patient treatment. Healthcare providers can now focus on the crucial aspects of patient care because AI in healthcare app development has dramatically reduced administrative chores.\nOrdering tests, filling prescriptions, and taking notes on charts can all benefit greatly from speech recognition software that permits voice-to-text transcriptions.\n6. Data management\nElectronic medical records often contain unstructured, challenging-to-read medical reports. Not to mention that in the sea of billions of data points, important data can be lost and impact patient care, diagnosis, and preventative medicine.\nThe healthcare sector has an excellent opportunity to save money and fatalities by using AI-assisted medical data management. Using algorithms to process data can help the pharmaceutical and medical industries save billions of dollars annually.\nAI in healthcare records has user-friendly benefits in addition to boosting data discovery, extraction, and treatment suggestions. Clinical fatigue brought on by manually entering data into electronic medical records can be reduced by using virtual healthcare assistants and AI-based healthcare software development.\n7. Fraud detection\nClaims assessment can be automated using AI development services. The processing, validation, and payment of valid claims are accelerated thanks to machine learning models, which also identify invalid claims before they are paid for.\nHowever, AI in healthcare app development is also capable of detecting other types of fraud. AI is helpful when it comes to charging for services a patient never had, upcoding (billing for a basic procedure as for something more complex), or preventing the theft of patient data.\nIt also helps in the following:\nQuicker processing of insurance.\nCheaper premiums for patients and decreased healthcare expenditures.\nGreater data security for personal healthcare.\nIncreased patient satisfaction."
  },
  {
    "body": "Insilico Medicine Opens Largest AI-Powered Biotechnology Research Center in the Middle East\nFebruary 01, 2023 09:27 ET\n| Source:\nInSilico Medicine\nUNITED STATES\nAbu Dhabi, Feb.  01, 2023  (GLOBE NEWSWIRE) -- Insilico Medicine (\"Insilico\"), a clinical-stage artificial intelligence (AI)-driven drug discovery company, is announcing today the opening of the Insilico Medicine Generative Artificial Intelligence and Quantum Computing Research and Development Center in Abu Dhabi, the regions largest AI-powered biotechnology research center.\nLocated in the International Renewable Energy Agency (IRENA) headquarters in Masdar City, Abu Dhabis flagship sustainable urban development, the research and development (R&D) hub will comprise global talent in artificial intelligence and software development dedicated to expanding the capabilities of Insilicos end-to-end AI-driven drug discovery platform, Pharma.AI, exploring aging research and sustainable chemistry, and supporting the digital transformation of healthcare in the region.\nThe grand opening occurred at the IRENA headquarters atrium in Masdar City, witnessed by nearly 100 ecosystem partners from the government, academia, the investment community, and the AI and biotech industry. The event featured speeches from H.E. Omar Al Olama, the Minister of State for Artificial Intelligence, Digital Economy and Remote Work Applications, Alex Zhavoronkov, Ph.D., Founder and CEO of Insilico, and Alex Aliper, Ph.D., President of Insilico.\nThe prime location, strong and stable economy, developed infrastructure, and highly educated talent make Abu Dhabi an emerging hub that attracts high-tech companies from around the world. We are excited to be a part of this, said Alex Aliper, Ph.D., President of Insilico, who will serve as the regional hubs general manager. We plan to hire locally and work closely with biotech companies and academic partners to license Insilicos proprietary software and collaborate on joint research projects to facilitate the digital transformation of the local healthcare industry.\nThis is exactly the kind of groundbreaking work in artificial intelligence that we aim to support in our free zone and innovation ecosystem, said Ahmed Baghoum, the acting CEO of Masdar City. Were excited about this milestone for Insilico Medicine  particularly given it is taking place during the Year of Sustainability. We look forward to the transformational research that will certainly come out of this incredible new hub, and we thank the Abu Dhabi Investment Office for attracting these kinds of organizations to Masdar City.\nInsilico has made steady inroads into the Middle East. On January 31, 2023, the Company announced that it will receive support from the Abu Dhabi Investment Office (ADIO) to establish its regional HQ in Abu Dhabi focused on R&D for its AI platform. Eng. Abdulla Abdul Aziz AlShamsi, Acting Director General of the Abu Dhabi Investment Office, said: ADIO congratulates Insilico Medicine on the opening of a regional HQ in the UAE capital. Abu Dhabi has made it a priority to advance technological solutions that further economic progress for the region and beyond. Insilico Medicine is a stellar example of the success of that strategy, and proof of the limitless opportunities available for health tech companies in Abu Dhabi.\nIn August 2022, the Company announced a Series D2 investment led by Prosperity7 Ventures, the diversified growth fund of Aramco Ventures, expanding its AI biotechnology expertise into Saudi Arabia. The company also signed a Memorandum of Understanding with the Ministry of Investment of Saudi Arabia, which includes providing Insilicos end-to-end AI drug discovery platform to local biotech companies, partnering with local biotechs on robotic drug discovery, contributing to local clinical trial expertise, and further developing projects extending healthy and productive longevity.\nInsilico founder and CEO Alex Zhavoronkov, Ph.D., was also a featured speaker at the Global AI Summit in Riyadh, Saudi Arabia, in Sept. 2022, an event focused on AI for the good of humanity.\nSince our very inception, our mission has been to extend healthy, productive longevity for everyone on the planet. Over the past decade, we developed a platform for drug discovery and longevity and became one of the dominant companies in this field. Now, we would like to extend our global infrastructure to the Middle East, said Alex Zhavoronkov, Ph.D., founder and CEO of Insilico Medicine. We look forward to expanding our presence and connections in the region by creating a true AI drug discovery hub in Abu Dhabi.\nAbout Insilico Medicine\nInsilico Medicine, a clinical-stage end-to-end artificial intelligence (AI)-driven drug discovery company, connects biology, chemistry, and clinical trials analysis using next-generation AI systems. The company has developed AI platforms that utilize deep generative models, reinforcement learning, transformers, and other modern machine learning techniques to discover novel targets and design novel molecular structures with desired properties. Insilico Medicine delivers breakthrough solutions to discover and develop innovative drugs for cancer, fibrosis, immunity, central nervous system (CNS), and aging-related diseases.\nFor more information, visit\nLaunch of Insilico Medicine's AI and Quantum Computing R&D Center in Abu Dhabi\nLaunch of Insilico Medicine's AI and Quantum Computing R&D Center in Abu Dhabi\nL to R: Dr. Alex Aliper, Co-founder and President of Insilico Medicine; Dr. Eric Xing, President of ..."
  },
  {
    "body": ",\nFeb. 1, 2023\n/PRNewswire/ -- Smart Data Solutions (SDS), a technology leader in healthcare process automation for front, middle and back-office operations, has been named an HFS OneOfficeHot Vendor for Q4 of 2022. HFS, a trusted global analyst organization, has developed Hot Vendors, an exclusive group of emerging players, each with a differentiated value proposition in the market. Smart Data Solutions was chosen for its distinctiveness, ecosystem robustness, client impact, financial position, and impact in HFS' OneOfficeor OneEcosystemframeworks.\nContinue Reading\nSmart Data Solutions was named a Hot Vendor for being a leading organization applying automation and AI to reimagine and streamline healthcare workflows. SDS has been designated this title by HFS for its specialized approach to data capture and AI-driven decision making, combined with their commitment to a DevOps culture, and overall supporting healthcare entities in the market better.\nSDS is a leading organization applying automation and AI to reimagine and streamline healthcare workflows.\nTweet this\n\"The journey from tech enabled workflows to AI-enabled automation to enhance efficiencies for health plan value chains is critical to impacting their financial health and consumer experiences. Smart Data Solutions is helping make that transition real with meaningful outcomes for hundreds of health plans and TPA's.\" said\nRohan Kulkarni\n, Lead Analyst at HFS.\nHot Vendors are chosen and named specifically as good technology providers with offerings that solve today's complex business problems and exploit market opportunities. As a Hot Vendor, Smart Data Solutions will continue to expand its open-source automation and AI capabilities towards the entire healthcare value chain.\n\"We are excited to be named a Hot Vendor by HFS and would really like to share our expertise with the rest of the healthcare market. Our clients tell us we are one of the best kept secrets in healthcare automation,\" stated\nSusan Berndt\n, VP, Head of Marketing at Smart Data Solutions. \"We have big plans for AI and automation enhancements as well as applying this technology to a whole new set of capabilities and workflows - more details to be released soon.\"\nTo read the full report, click here.\nAbout Smart Data Solutions\nAs a technology leader in healthcare process automation and interoperability, Smart Data Solutions (SDS) is a strategic partner in healthcare process automation and interoperability that utilizes data and intelligent automation to digitally transform operations and deliver outcomes for clients which reduces costs, streamlines workflows, and improves overall customer experience. Smart Data Solutions has a specialized approach to data capture, and automation and has focused on creating innovative solutions specifically to meet the needs of the healthcare market. Today, more than 500 clients including multiple Blue Cross Blue Shield state plans, regional health plans, TPAs, and healthcare partners depend on SDS to help streamline complex parts of the front, middle and back-office operations.\nMedia Contact"
  },
  {
    "body": "Print Article\nC3.ai\nstock is soaring Tuesday after the company announced the launch of a set of tools for generative artificial intelligence applications, jumping into the middle of what might be the hottest trend in the technology segment.\nSome generative AI tools, most notably the uber-trendy ChatGPT app from OpenAI, allow the use of conversational language to make queries to large databases. Others, like OpenAIs DALL-E2 application, create images in response to text-based requests.\nSubscribe"
  },
  {
    "body": "The makers of ChatGPT have launched a new tool that can help teachers detect if a student or artificial intelligence wrote that homework (Picture: AP Photo/Richard Drew)\n\n\n\nOpenAI, the creator of the popular chatbot ChatGPT, has released a software tool to identify text generated by artificial intelligence.\n\n\n\nOn Wednesday, the company launched theAI classifier that aims to distinguish text that is written by AI.\n\n\n\nThe language model has been trained on the dataset of pairs of human-written and AI-written text on the same topic.\n\n\n\nIt uses a variety of providers to address issues such as automated misinformation campaigns and academic dishonesty, the company said in a blog post \n\n\n\nChatGPTis a free program that generates text in response to a prompt, including articles, essays, jokes and even poetry, which has gained wide popularity since its debut in November, while raising concerns about copyright and plagiarism.\n\n\n\nCEO of OpenAI Sam Altman (Picture: Reuters/Brendan McDermid/File Photo)\n\n\n\nIn its public beta mode, OpenAI acknowledges the detection tool is very unreliable on texts under 1,000 characters, and AI-written text can be edited to trick the classifier.\n\n\n\nWere making this classifier publicly available to get feedback on whether imperfect tools like this one are useful, said OpenAI.\n\n\n\nWe recognize that identifying AI-written text has been an important point of discussion among educators, and equally important is recognizing the limits and impacts of AI-generated text classifiers in the classroom,\n\n\n\nSince ChatGPT debuted in November, it has gained wide popularity among millions of users.\n\n\n\nPreviously, ChatGPT had succeeded infooling scientists by writing accurate research paper summaries.\n\n\n\n\n\n\n\nChatGPTs conversational speaking style and coherent, spontaneous response style make it nearly identical to human responses, causing concern for educators.\n\n\n\nEarlier this month, New York Citys Department of Educationannounced a banon ChatGPTfrom its schools devices and networks.\n\n\n\nAI chatbots are being used to take the place oflawyers,therapistsor evenyourselfbut their biggest drawback is atendency to give answers out of context.\n\n\n\nPeople have created third-party detection tools likeGPTZeroXto help educators detect AI-generated text.\n\n\n\nOpenAI said it is engaging with educators to discuss ChatGPTs capabilities and limitations, and will continue to work on the detection of AI-generated text.\n\n\n\n\t\n\t\n\tMORE : ChatGPT cracks Wharton MBA exam giving excellent explanations\n\t\n\t\n\n\n\n\t\n\t\n\tMORE : OpenAI paid Kenyan workers less than $2 an hour to make ChatGPT less toxic"
  },
  {
    "body": "Vikram is the co-founder and CEO at\nGalileo, a category leader for ML data quality. Previously, he led product management at Google AI.\ngetty\nFew topics get tossed around as objects of intrigue, excitement and dread as much as artificial intelligence (AI) does. With the advent of generative AI, this topic is now in the zeitgeist more than ever beforewhether its your friend showcasing chatGPT to write eloquent poetry for the umpteenth time or Lensa-generated digital avatars popping up on your Instagram feedAI apps are having a spotlight moment.\nDespite the justified fanfare, excitement and huge potential to upend entire industries, AI is still hard to get right for real-world applications. Although hobbyist tools aim for virality, real-world implementations of AI aim for high-precision implementations.\nWhether it's a bank using AI models to catch fraud, a radiologist using AI to detect cancer or a contact center bot answering an urgent user query, the margin for error is razor-thin. A 90% accurate model might be great for show-and-tell, but providing wrong predictions nine out of 10 times in healthcare, for instance, can be life-threatening. Herein lies the problem.\nGetting highly accurate AI model outputs relies on one thinggood quality data as the input.\nThe Rise Of Foundation Models\nMORE FOR YOU\nFungi-Powered Ingredients Startup Michroma Promising To Remove Petroleum From Food Colorings Raises $6.4 Million In Venture Funding\nIn 2018, AI went through a paradigm shift. The only organizations on Earth with the capital and infrastructure to train models on massive amounts of data and foot the costs for the large amounts of computing power required to do so built \"foundation models.\" For instance, Google researchers open-sourced Bidirectional Encoder Representations from Transformers (BERT), which was trained on 3.3 billion words from Wikipedia and BooksCorpus.\nNow any data scientist could piggyback on foundation models like BERT to fine-tune them for their own data, thereby capturing the nuances of their industry and their users. These foundation models have significantly reduced the capital and time needed to create highly accurate models. And they opened the floodgates for leveraging machine learning (ML) in the enterprise. However, gathering high-quality data to train these models became a bottleneck as well as a business-critical differentiator.\nAlthough used in industry, foundation models, including the much-hyped generative models such as GPT3, can give you model predictions with 70% to 80% accuracy at best. However, gaining the remaining 20% to 30% last-mile accuracy is still a huge grind: It requires leveraging high-quality, unbiased data and an almost artisanal mindset toward painstaking labeling, inspecting and experimenting. Any data scientist will tell you that this careful and grueling \"data detective work\" is 80% of what they do.\nThe Three Main Data Quality Bottlenecks\nThere are three main data quality bottlenecks data scientists face today:\n1. Data Preparation\nData quality challenges can begin at step one. To help avoid them, inspect the raw datawhich may be huge Excel files with text or a large group of imagesto get a better understanding of the data, as well as \"clean\" it. This is critical for two reasons. First, in supervised ML scenarios, this data will be sent for manual labelinga human-intensive and, therefore, a capital- and time-consuming process. Second, investing in high-quality data at this stage sets a good foundation for better model predictions.\n2. Data Debugging During Model Training\nA popular ML evaluation metric is the F1 score. The higher the score, generally, the better the model performance. Building an ML model involves a lot of iterations, and it's rare to get a high F1 score after the first few iterations. This leaves the data scientist to embark upon the data detective work again to figure out the data that's pulling the model performance down, which could be incorrectly labeled data, insufficient data, garbage data, blurry images and a whole lot more. This can take weeks sometimes and is highly manual yet critical work.\n3. Data Quality Monitoring For \"Launched\" Models\nOnce a model is ready for prime time with a high F1 score, it's deployed and real user data starts to hit the model, including radiology reports, customer calls, credit card transaction data and other potentially sensitive information. The model was trained on a specific set of data. If the data it now encounters in the wild is different from what it's seen before, it can perform poorly. This is called data drift, and it needs to be constantly monitored. When drift or other data-quality issues are detected, the model needs to be retrained. Model building and maintenance is, therefore, a continuous loop, with data quality at the core, governing model performance.\nThe Criticality Of ML Data Quality Tooling\nTo constantly deal with this highly manual last-mile ML data quality problem, data scientists need the right tools. Although the MLOps market has exploded with tools focused on models, tools specifically focused on data quality have started to emerge.\nTo effectively overcome the data quality bottlenecks and foster faster, cheaper and better model development, businesses need to first adopt a strong data-centric mindset, followed by the adoption of data quality tools to successfully get past the model accuracy problem. As organizations increasingly adopt AI, with foundation models having become commoditized off-the-shelf entities, an obsession with data quality will make all the difference."
  },
  {
    "body": "Budget 2023: In a fillip to startups, date of incorporation to qualify for tax benefits extended by ...\nSkills in focus will include coding, AI, robotics, mechatronics, 3D, printing, drones, IoT and soft skills.\nThe government's focus on the skill development of India's potential youth talent through initiatives like NEP, PMKVY 4.0 for skilling in niche new-age technologies like 5G, AI, 3D printing, drones, coding, mechatronics, robotics, and IoT draws further impetus to the ongoing efforts. Blue and grey-collar job demand in India grew by up to four-fold in 2022,\" said Arvind Bali, CEO of Telecom Sector Skill Council.\n\"Apart from skill development, the government has focused a lot on training and research by opening a centre for the excellence of AI and labs for 5G. I am certain this will help a lot with entrepreneurship and many youngsters will come with their startups,\" said Dr Hari Shankar Shyam, Professor of Management at Sharda University.\nFollow our live blog for the latest Budget 2023 updates\nNational Digital Library\nThe minister announced that a National Digital Library for children and adolescents will be set up to ensure the availability of quality books across geographies, languages, genres and levels, which would be device agnostic.\n\"States will be encouraged to set up physical libraries at panchayat and ward level and provide infrastructure and accessing the National Digital Library resources,\" the FM said.\nThe National Digital Library for children and adolescents will give a boost to the edtech sector, said Aarul Malviya, Founder, of edtech startup Zamit. \"..it will create a digital ecosystem in the education sector and encourage digital education. It will largely benefit the students who are lagging due to the pandemic,\" Malviya said.\nFocus on new-age skills\nThree Centres of Excellence (CoE) for artificial intelligence (AI) will be set up in top educational institutions. Industry players will partner in conducting interdisciplinary research, and develop cutting-edge applications and scalable problem solutions in the areas of agriculture, health, and sustainable cities.\nThe announcement of opening three AI centres in some of the top educational institutions is very timely, said Vivek Kathpalia, Managing Director & CEO  Singapore, Cyril Amarchand Mangaldas. \"The government needs to urgently supplement and support the work the private sector is doing in the AI space. China is leading us and most of the world in the AI race and we need to catch up fast.\nThe Centre will also recruit 38,800 teachers and support staff for 748 Eklavya Model Residential Schools in the next three years.\nAbhishek Sahu"
  },
  {
    "body": "February 01, 2023\n/ 02:08 PM IST\nMore than 448 million of India's digital population consumes internet on their mobile phones. Rural penetration remains considerably low compared to urban communities. However, the gap seems to be only decreasing as socio-economic conditions of such communities improve.\nWhile giving her Budget speech on February 1, Finance Minister Nirmala Sitharaman said that lakhs of youngsters will be trained in the next three years in subjects such as drones, artificial intelligence, coding and other soft skills under the Pradhan Mantri Kausal Vikas Yojana 4.0.\nSitharaman said, \"Pradhan Mantri Kausal Vikas Yojana 4.0 will be launched to skill lakhs of youth within the next 3 years. On job training, industry partnership and alignment of courses with needs of industry will be emphasised. The scheme will new age courses for industry 4.0 like coding, AI, robotics, mechatronix, 3D printing, internet of things, drones and other soft skills.\"\nPradhan Mantri Kaushal Vikas Yojana (PMKVY) is a scheme of the Ministry of Skill Development & Entrepreneurship (MSDE) implemented by National Skill Development Corporation.\nRead Budget 2023 LIVE Updates"
  },
  {
    "body": ",\nFeb. 1, 2023\n/PRNewswire/ -- NERVTEX's MoDAS (Movement Dysfunction Assessment Software) system, which is a First-in-Class Artificial Intelligence/Machine Learning (AI/ML)- based Software as a Medical Device(SaMD) for the analysis of motor symptoms of Parkinson's disease and other movement disorders, has been approved by the China National Medical Products Administration, making it the first video-based AI-powered medical device for the assessment of movement disorders.\nMoDAS uses consumer-level smart mobile devices to conveniently capture video of the patient's movement status. By adapting AI technologies such as computer vision and deep learning, MoDAS automatically provides doctors with objective and quantitative information for clinical decision support, relieving doctors from time-consuming observation and evaluation, and greatly improving the evaluation and treatment efficiency of movement disorders such as Parkinson's disease. Compared to wearable motion sensors, MoDAS effectively avoids the interference of physical devices with human movement, eliminates the time consumed by wearing and disinfecting sensors, and reduces the difficulty and complexity of deployment in medical institutes and primary healthcare services based entirely on video analysis.\nIn a multi-centre clinical study of Parkinson's disease patients led by Shanghai Changhai Hospital, the output result of MoDAS was highly consistent with clinicians' diagnosis based on existing criteria. No adverse events were observed in patients in this study, demonstrating excellent safety and efficacy. According to the experts involved in the study, MoDAS fits well into the current clinical workflow and its mobile design allows access to graphical data in real time, improving the efficiency and quality of clinical evaluation.\nIn 2021, the AI technology behind MoDAS was selected from hundreds of projects around the world by the Centre for Innovation in Healthcare of the\nNational University\nHealthcare System and the Asian Innovation Research Alliance to be part of the ICP programme for further exploration of clinical application. Recently, MoDAS was also selected for the list of \"Top 100 Most Innovative Medical Technology Products of the Year 2022\" and \"Digital Therapeutics Innovation of the Year\" by the VB-Find Award & VB 100.\nThe diagnosis and classification of movement disorders, such as Parkinson's disease, is still primarily based on clinical observation by the physician in the field and analysis based on the results of a number of standard scales. With the accelerated aging of the population in many major countries around the world, the problems of the traditional approach, including the allocation of limited physician resources and the low efficiency of diagnosis and treatment, have become increasingly apparent. The use of artificial intelligence technology to aid assessment and treatment is the current hotspot of many companies and research institutions around the world, and its theoretical basis and practical use have been fully demonstrated in areas such as pathological analysis and surgical planning. In the field of movement disorders, artificial intelligence technology based on computer vision has obvious advantages and is a hot topic of neurological medicine innovation in neuroscience around the world.\nDr\nZhou Dong\n, NERVTEX's Chief Medical Officer, said: \"Movement disorders are probably one of the earliest neurological diseases to be discovered and studied in humans, yet their symptom assessment methods and tools have made little progress for so many years, which to some extent limits progress in disease assessment and treatment, as well as drug development. My team and I have long aspired to provide neurologists with a convenient tool for objective quantification of motor symptoms, just as X-rays are for surgeons, to help them make more accurate and efficient treatment decisions.\n\"Information technology, after more than 50 years of development, has proven its power and value to all of humanity. Introducing these technologies into the development of the assessment and treatment of movement disorders with MoDAS is a solid and big step for NERVTEX, and also a small step in the big wave of 'Digital | New Medicine'\".\nDong Boya\n, founder and CEO of\nNERVTEX\n, said: \"We are ready to work with physicians around the world on this path to the future and dedicate ourselves to a healthier and better tomorrow.\"\nAbout NERVTEX\nNERVTEX\nis an innovative technology company focused on the research and development of digital therapies for brain disorders. Founded in 2018, the core technology team consists of algorithmic scientists, digital product experts and clinical researchers.\nThe company has extensive experience in the integration of technology and medicine, such as artificial intelligence, virtual reality and gamified neurorehabitation, and is committed to providing innovative digital medical solutions for clinical experts in neurology and psychiatry.\nHeadquartered in\n,\nNERVTEX\nhas two Class II medical device approvals, eight national invention patents pending, and more than 20 products in research and registration for various indications.\nSOURCE NERVTEX"
  },
  {
    "body": "Laxmi Organic Industries\nLaxmi Organic Industries Ltd (LOIL) reported revenue of INR 6,546Mn(-23.9% YoY/+0.4% QoQ) on account of fall in Acetyl Intermediates (AI) prices and lower demand in Specialty Intermediates (SI) compared to last year. However, the prices in AI segmenthas begun to stabilize on a sequentialbasis; whereas SI demand started coming back towards the end of Q3FY23. EBITDA reported at INR 548Mn (-53.8% YoY/+91.4% QoQ). EBITDA margin stood at 8.4% (-543bps YoY/+398bps QoQ); an improvement in margin performance on a sequential basis was mainly on account of correction in input costs and narrowing spread of AI segment. Net Profit decline by 66.8% YoY at INR 273Mn (+216.1% QoQ), Net margin reported at 4.2% (-538bps YoY / +284bpsQoQ). EPS stood at INR 1.03 in Q3FY23 compared to INR 3.07 in Q3FY22 and 0.33 in Q2FY23.\nOutlook\nWe revise our target price at INR 376 by assigning PE multiple of 24.0x to FY25E EPS (Previous TP: INR 380) and rolling over our estimate from FY24E to FY25E while maintain our BUY recommendation (upside 41% ).\nFor all recommendations report,"
  },
  {
    "body": "Roland Hutchinson\nThe new Razer Leviathan V2 Pro soundbar was made official at VES last month and now the device is available to buy direct from Razer.\nThe device comes with an integrated IR camera and it features head-tracking AI, it is available in the USA for $399.99 and in Europe for 489.99.\nCombining beamforming surround sound with head-tracking AI technology, the Leviathan V2 Pro delivers immersive 3D audio thanks to the integrated IR camera that detects the users position. This allows the soundbar to adapt the audio beams to the listeners positioning in real-time, ensuring that they are always in the sweet spot for the best audio experience.\nPowered by THX Spatial Audio for the immersive experience, combined with Audioscenic user adaptive beamforming, the soundbar provides true-to-life 3D audio for all your entertainment needs. 3D audio can be experienced in two modes: THX Spatial Audio Virtual Headset is for any stereo content, providing you with pinpoint positional audio previously only found in headsets, while THX Spatial Audio Virtual Speakers is for any multi-channel content that provides a wide, room-filling soundstage that users would normally experience with a full home theatre system.\nAlong with the included subwoofer, the Leviathan V2 Pro multi-driver PC soundbar delivers crisp, clear treble and deep, punchy bass with support for Razer Chroma RGB, allowing for deeper immersion with 30 lighting zones, 16.8 million colours, and over 200 games integrated into the worlds largest lighting ecosystem for gaming devices.\nYou can find out more information about the new Razer Leviathan V2 Pro soundbar over at the raxer website at the link below.\nSource"
  },
  {
    "body": "MCHX\n), the award-winning AI-powered conversation intelligence company that helps businesses turn strategic insights into the actions that drive their most valued sales outcomes, today announced that it has added more than 300 automotive dealers to its Conversation Intelligence platform during the prior twelve months, driven by a combination of direct dealer sign-ups to its Marchex Engage for Automotive offering and its automotive channel partnerships. Marchex also announced today that it has entered into a long-term, multi-year extension on a partnership with a major original equipment manufacturer (OEM) customer, opening the doors to expand this relationship through a deeper integration with the OEM and additional dealership engagements.\nThe company has built its artificial intelligence-powered solutions to enable automotive sales teams to deliver better buying experiences and improve sales outcomes. As Marchex continues to expand its presence in the automotive industry, the company plans to leverage core capabilities delivered by Marchex Engage for Automotive, including:\nAutomatically scoring and categorizing conversations between consumers and a dealers sales team, using conversation intelligence\nGenerating action lists that enable sellers to efficiently focus follow-up conversations on the highest-value leads\nGenerating deal-saving action alerts so sales team specialists can save lost leads when conversations end unsuccessfully\nEnabling users to share conversations with other team members and the ability to set status to coordinate actions or next steps\nEnabling users to quickly review audio conversations, unlocking opportunities to improve customer experiences\nMarchexs increasing momentum in the automotive vertical comes at a time when consumer sentiment and the car-buying process itself continues to undergo change as new car inventories recover from a supply-constrained environment. A recently released Marchex study found that with inventory shortages, consumers are making clear that it is more important than ever that phone calls focused on understanding actual vehicle availability precede traditional in-person dealership visits. That is, consumers want to call and have conversations with dealers ahead of in-person dealership visits to simply validate what is specifically available and at what price, or to understand how to purchase a vehicle. A previous Marchex study revealed that roughly 80% of consumers prefer to call and speak with a dealership sales representative ahead of visiting the dealership.\n\"We are seeing momentum build in Marchexs automotive vertical, driven by rapid adoption of dealers and expanding relationships with OEM partners, said Ryan Polley, Marchex Chief Operating Officer. There is a significant opportunity in the automotive vertical for Marchex to positively impact these businesses as the industry is going through significant change. Dealerships, OEMs, and other key players in the sector are capitalizing on how understanding consumer-to-business conversations matter more now than ever. We have been deliberate in focusing on sales conversations and have built a flexible platform that empowers OEMs and dealers to have actionable insights that measurably improve their customers experience and their own bottom lines.\nAbout Marchex\nMarchexs\naward-winning conversation intelligence platform, featuring AI-powered sales engagement and marketing solutions, helps businesses turn strategic insights into the actions that drive their most valued sales outcomes. Our multichannel voice and text capabilities enable sales and marketing teams to deliver the buying experiences that todays customers expect. Marchex is the trusted conversation intelligence partner for market-leading companies in critical industries, including many of the worlds most innovative and successful brands.\nPlease visit www.marchex.com, www.marchex.com/blog or @marchex on Twitter (\n), where Marchex discloses material information from time to time about the company and its business.\nContacts"
  },
  {
    "body": "Tweet this\nLXT VP of Operations, Carolyn Harvey\n\"As an industry expert with extensive experience managing Service Delivery at scale, Carolyn was the natural choice for the VP of Operations role,\" commented\nYassin Omar\n, LXT's Chief Operations Officer. \"Carolyn's proven leadership ability and industry knowledge  as well as her experience in delivering large scale, multi-year programs for some of the largest global organizations  are huge assets as we continue to build a best-in-class service delivery organization. I am delighted to welcome her to the team.\"\nIn her role, Carolyn will be responsible for leading and expanding LXT's global operations organization, including defining and implementing strategies, structure, and processes to drive client satisfaction andensure that customers continue to receive high-quality AI data on time across a wide range of modalities and use cases. Her specialized skills and experience will also support LXT as it scales to service an increasing number of clients worldwide.\n\"Companies that are successfully deploying AI know that high-quality data is a critical component of their AI strategy,\" said Carolyn. \"Having worked in the AI data industry for over a decade, I understand that quality service delivery is complex and constantly evolving to meet customers' changing data needs. When considering my next opportunity, it was important for me to join an organization with a vision and culture that prioritizes operational excellence for clients of all types, no matter where they are in their AI maturity journey. I am honored to join the LXT team and am excited to use my experience to help the company continue to deliver high-quality data for its clients worldwide.\"\nBefore joining LXT, Carolyn led Global Service Delivery for Appen's strategic global clients. Her responsibilities included service delivery strategy and execution, and managing a large global team to increase operational efficiency, reduce operating costs and ensure high client satisfaction. She also brings prior experience from organizations including Expedia and Bank of America.\n\"In 2011, as part of our due diligence for Appen's acquisition of Butler Hill, we identified\nCarolyn Harvey\nas one of Butler Hill's most valuable assets,\" said\nPhil Hall\n, LXT's Chief Growth Officer. \"Working closely with Carolyn and her team over the years that followed only reinforced this initial impression, and I think it is fair to say that the exponential growth that Appen underwent prior to 2020 would have been difficult, maybe even impossible to achieve without her expertise. With this in mind, I am thrilled that LXT is now able to further strengthen its leadership team by inviting Carolyn aboard. She brings an unparalleled depth of experience in operational leadership, and I can't overstate how pleased we are to have Carolyn as part of our team.\"\nAbout LXT\nLXT is an emerging leader in AI training data to power intelligent technology for global organizations. In partnership with an international network of contributors, LXT collects and annotates data across multiple modalities with the speed, scale and agility required by the enterprise. Our global expertise spans more than 115countries and over 750 language locales. Founded in 2010, LXT is headquartered in\nToronto, Canada"
  },
  {
    "body": "+++lead-in-text\n\nArmed with a belief in technologys generative potential, a growing faction of researchers and companies aims to solve the problem of bias in AI by creating artificial images of people of color. Proponents argue that AI-powered generators can rectify the diversity gaps in existing image databases by supplementing them with synthetic images.[Some](https://ieeexplore.ieee.org/document/9304901) researchers are using machine learning architectures to map existing photos of people onto new races in order to balance the ethnic distribution of datasets. Others, like[Generated Media](https://generated.photos/datasets) and[Qoves Lab](https://laboratory.qoves.com/), are using similar technologies to create entirely new portraits for their image banks, building  faces of every race and ethnicity, as Qoves Lab puts it, to ensure a truly fair facial dataset. As they see it, these tools will resolve data biases by cheaply and efficiently producing diverse images on command.\n\n+++\n\nThe issue that these technologists are looking to fix is a critical one. AIs are riddled with defects, unlocking phones for the[wrong person](https://www.scmp.com/news/china/society/article/2124313/chinese-woman-offered-refund-after-facial-recognition-allows) because they cant tell Asian faces apart,[falsely accusing](https://www.nytimes.com/2020/12/29/technology/facial-recognition-misidentify-jail.html) people of crimes they did not commit, and mistaking darker-skinned people[for gorillas](https://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai). These spectacular failures arent anomalies, but rather inevitable consequences of the data AIs are trained on, which for the most part skews heavily white and malemaking these tools imprecise instruments for anyone who doesnt fit this narrow archetype. In theory, the solution is straightforward: We just need to cultivate more diverse training sets. Yet in practice, its proven to be an incredibly labor-intensive task thanks to the scale of inputs such systems require, as well as the extent of the current omissions in data (research by IBM, for example, revealed that[six out of eight](https://www.arxiv-vanity.com/papers/1901.10436/) prominent facial datasets were composed of over 80 percent lighter-skinned faces). That diverse datasets might be created without manual sourcing is, therefore, a tantalizing possibility.\n\nAs we look closer at the ways that this proposal might impact both our tools and our relationship to them however, the long shadows of this seemingly convenient solution begin to take frightening shape.\n\n+++lead-in-text\n\nComputer vision has been in development in some form since the mid-20th century. Initially, researchers attempted to build tools top-down, manually defining rules (human faces have two symmetrical eyes) to identify a desired class of images. These rules would be converted into a computational formula, then programmed into a computer to help it search for pixel patterns that corresponded to those of the described object. This approach, however, proved[largely unsuccessful](https://www.turing.ac.uk/sites/default/files/2020-10/understanding_bias_in_facial_recognition_technology.pdf) given the sheer variety of subjects, angles, and lighting conditions that could constitute a photo as well as the difficulty of translating even simple rules into coherent formulae.\n\n+++\n\n+++inset-left\n\n+++sidebar\n\n#### SUBSCRIBE\n\n\n[#image: /photos/5c830eaa9d5bf17d94aac27b]\n\n##### [Subscribe](https://subscribe.wired.com/subscribe/splits/wired/WIR_Edit_Hardcoded?source=HCL_WIR_ARTICLE_SUBSCRIBE_INSET_0) to WIRED and stay smart with more of your favorite [Ideas](https://www.wired.com/category/ideas/) writers.\n+++\n\n+++\n\nOver time, an increase in publicly available images made a more bottom-up process via machine learning possible. With this methodology, mass aggregates of labeled data are fed into a system. Through [supervised learning](https://www.ibm.com/cloud/blog/supervised-vs-unsupervised-learning), the algorithm takes this data and teaches itself to discriminate between the desired categories designated by researchers. This technique is much more flexible than the top-down method since it doesnt rely on rules that might vary across different conditions. By training itself on a variety of inputs, the machine can identify the relevant similarities between images of a given class without being told explicitly what those similarities are, creating a much more adaptable model.\n\nStill, the bottom-up method isnt perfect. In particular, these systems are largely bounded by the data theyre provided. As the tech writer Rob Horning[puts it](https://robhorning.substack.com/p/what-of-the-national-throat), technologies of this kind presume a closed system. They have trouble extrapolating beyond their given parameters, leading to[limited performance](https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html) when faced with subjects they arent well trained on; discrepancies in data, for example, led[Microsofts FaceDetect](https://www.turing.ac.uk/sites/default/files/2020-10/understanding_bias_in_facial_recognition_technology.pdf) to have a 20 percent error rate for darker-skinned women, while its error rate for white males hovered around 0 percent. The ripple effects of these training biases on performance are the reason that technology ethicists began preaching the importance of dataset diversity, and why companies and researchers are in a race to solve the problem. As the popular saying in AI goes, garbage in, garbage out.\n\nThis maxim applies equally to image generators, which also require large datasets to train themselves in the art of photorealistic representation. Most facial generators today employ[Generative Adversarial Networks](https://developers.google.com/machine-learning/gan) (or GANs) as their foundational architecture. At their core, GANs work by having two networks, a Generator and a Discriminator, in play with each other. While the Generator produces images from noise inputs, a Discriminator attempts to sort the generated fakes from the real images provided by a training set. Over time, this adversarial network enables the Generator to improve and create images that a Discriminator is unable to identify as a fake. The initial inputs serve as the anchor to this process. Historically,[tens of thousands](https://blogs.nvidia.com/blog/2020/12/07/neurips-research-limited-data-gan/#:~:text=It%20typically%20takes%2050%2C000%20to,sample%20images%20at%20their%20disposal.) of these images have been required to produce sufficiently realistic results, indicating the importance of a diverse training set in the proper development of these tools.\n\nThis means, however, that the plan to use synthetic data to fix the diversity gap relies on a circular logic. Like the computer vision technologies they are meant to supplement, these image generators are unable to escape this close"
  },
  {
    "body": "customers in\nMumbai, India's\nmost populous city, the new Demand Response Management Program aims to engage 55,000 residential consumers and 6,000 large C&I customers to achieve 75 MW of peak capacity reduction, within the first six months, and then continue to scale up to 200 MW by the summer of 2025.\nThe two companies' collaboration started in 2021 with Tata PowerDelhi Distribution'sresidential customersin\nDelhi\n. Based on the success of this engagement,\nTata Power\nsignificantly expanded the initiative within the\nDelhi\ndistribution region in 2022. AutoGrid is now extending this program across\nTata Power's\ndistribution territories to include all segments.\nIn addition to the behavioral demand response (BDR) program,\nTata Power\nwill stack on an automated demand response (ADR) program with direct load control assisted by customer participation with its in-house smart plug platform called EZ Home.\nWith\n(DERs) mainstream and promoting a culture of hi-tech energy conservation,\" said Dr.\nPraveer Sinha\n, CEO & MD,\nTata Power\n. \"Our partnership with AutoGrid allows us to partner with our customers to assist us in load management and help them save on their energy consumption.\"\n\"\nand\nTata Power\ncan reach ambitious sustainability goals by leveraging the flexible capacity available by adopting innovative approaches to leverage distributed energy resources,\" said\nAmit Narayan\n, AutoGrid founder and CEO. \"At AutoGrid, we feel privileged and passionate about supporting\nTata Power's\nvisionary efforts to collaborate with its customers through behavioral and AI-driven demand orchestration.\"\nOver the last two decades,\nIndia\nhas seen rapid growth in DERs, including solar, smart meters, electric vehicles (EVs), and EV charging infrastructure. The country has a huge opportunity to harness demand-side flexibility, strengthen the grid, and advance sustainability, but the lack of a singular, scalable program has hindered progress in the past.Additionally, the lack of adequate regulatory approval prevents these resources from being utilized at the incredible scale the\nIndia"
  },
  {
    "body": ",\nFeb. 1, 2023\n/PRNewswire/ -- The eSports industry has had to overcome major obstacles en route to its current status. In previous years, limited tournament infrastructure and a lower number of organizations have restricted the market growth. Such limitations resulted in fewer revenue streams for players and team owners. However, in 2017, Riot Games created the League of Legends for the\nNorth America\nand\nEurope\nregion, giving a structured format to the tournament. Later, in 2018, Activision Blizzard, Inc. launched its Overwatch league, creating the requisite infrastructure for the monetization of eSports tournaments. Among the many technological innovations that contribute to eSports, artificial Intelligence (AI) has become a useful tool for gamers and developers alike. For example, many players are demanding coaching apps, which are based on AI. AI-powered coaching offered by SenpAI suggests better strategies for some of the best video games such as DotA 2 and League of Legends by accessing player stats. SenpAI also offers in-game guidance by providing in-depth stats for players to analyze. React Gaming Group Inc.(TSX-V: RGG) (OTC: ITMZF), Electronic Arts Inc. (NASDAQ:\nMGAM\n)\nOutside of the eSports segment, AI is making impressive strides. Chat Generative Pre-Trained Transformer, commonly called ChatGPT, a chatbot launched by OpenAI in\nNovember 2022\n, quickly garnered attention for its detailed responses and articulate answers across many domains of knowledge. The popularity it has gained since has boosted OpenAI's value to\nUSD 29 Billion\n. In addition, last week Microsoft has confirmed that it is extending the partnership with OpenAI, with a rumored investment of\nUSD 10 billion\nas the tech giant is looking to accelerate the breakthroughs in AI. Microsoft Azure will also continue as the exclusive cloud provider for the chatbot as OpenAI uses Azure to train all its models.\nReact Gaming Group Inc.\n) just announced breaking news regarding, \"its 2023 plans to enhance the capabilities of its online esports tournament and betting platforms, Compete.gg and LOOT.BET, through the integration of artificial intelligence (AI) applications and machine learning (ML) techniques.\n\"Esports is a large and growing market with revenues that are expected to reach\n$1.87 billion\nin 2025, according to market analytics firm Statista. As this booming industry grows, AI is widely seen as having the potential to bring about significant revenue opportunities in the next decade. AI's ability to automate repetitive tasks, make smart decisions, and analyze large amounts of data faster than humans, makes it a valuable tool for businesses across various industries, including gaming and esports. In the online esports space, AI can help improve tournament organization and player engagement, provide valuable insights for sponsors, and streamline betting and wagering processes, amongst many other applications that could benefit Compete.gg and LOOT.BET. This is why we will focus in 2023 on enhancing our AI capabilities in both our online esports platforms,\" said\nLeigh Hughes\n, CEO of React Gaming.\nIn any sport, the ability to analyse performance and use that insight to predict the outcome is very valuable. Esports are different from traditional sports in that everything about them is digital. These digital landscapes generate a huge amount of data, in a way that no other sport can. This gives AI a huge advantage for analysis and prediction.\nReact Gaming's primary goal with Compete.gg is to pursue the development of its universal and accessible esports tournament platform that enables gamers worldwide to win money playing their favorite video games. AI and machine learning would come into play here by helping the Corporation to further develop its Smart AI Tournament System, which would enable it to scale with demand and facilitate and run online esports tournaments in a much more straightforward and effective manner. More precisely, this would involve exploring the exciting possibilities of AI technology to revolutionize the online esports tournament space. Our goal is to utilize AI algorithms to generate the fairest and most competitive tournaments possible, in real time. These algorithms will consider player performance, past tournament results, and various other factors to craft optimized schedules, matchups, and pairings. We also plan to use AI to help tournament organizers (TO), of any size, quickly establish a home for themselves on our platform, making it easier for TOs to run and facilitate a wide array of esports tournaments online while also strengthening their brand recognition.\nWith LOOT.BET, AI would be used to generate live-data integration, in-game analytics, predictive modeling and personalized recommendations, just to name a few. AI and ML would work together to derive high-quality insights that could be very useful for the people betting on React Gaming's LOOT.BET esports platform, while enhancing its performance.\n'Our main goal will be to use AI and ML to provide a best-in-class experience for our users, prevent cheating, and predict outcomes of matches to provide keen insights for our players, which could all lead to increased fan engagement, the main revenue driver in esports,' concluded Mr. Hughes.\"\nElectronic Arts Inc.\nAI\n), the Enterprise AI application software company, announced yesterday the launch of the C3 Generative AI Product Suite with the release of its first product  C3 Generative AI for Enterprise Search. \"C3 Generative AI fundamentally changes the human computer interaction model of enterprise application software,\" said C3 AI CEO\nThomas M. Siebel\n. \"Combining the full potential of natural language, generative pre-trained transformers, enterprise AI, and predictive analytics will change everything about enterprise computing.\"\nBuzzFeed, Inc.\nBZFD\n) announced last week it would rely on ChatGPT creator OpenAI to enhance its quizzes and personalize some content for its audiences, becoming the latest digital publisher to embrace artificial intelligence. According to the Wall Street Journal, in a memo to staff sent last Thursday, Chief Executive\nJonah Peretti\nsaid he intends for AI to play a larger role in the company's editorial and business operations this year.\nMobile Global Esports Inc.\n) is a mobile esports and social platform company that holds trademark and IP rights for collegiate esports tournaments, teams, and players in\nIndia\n. Mobile Global Esports was organized in March of 2021 to carry on and expand an esports business. Back in December the Company announced that its Indian operating subsidiary - MOGO Esports Private Ltd. - has signed the six winners of the MOGO National Championships to exclusive esports representation and tournament development contracts.\nSubscribe Now! Watch us report LIVE: https://www.youtube.com/FinancialBuzzMedia.\nFollow us on Twitter for real time Financial News Updates: https://twitter.com/financialbuzz.\nFollow and talk to us on Instagram: https://www.instagram.com/financialbuz"
  },
  {
    "body": "Iveda technology continues to help organizations and municipalities across Taiwan update surveillance infrastructure for enhanced safety and operational efficiency nation-wide  Mesa, Arizona, Feb.  01, 2023  (GLOBE NEWSWIRE) -- Iveda (NASDAQ:IVDA), the global solution for cloud-based AI video and sensor technologies, today announced $1M in new technology deals with organizations and municipalities across Taiwan. Through contracts with the Taiwan Stock Exchange, Tainan Solar Park, Taipei City Government Public Works Bureau, and additional Taiwanese government entities, Iveda technology will be implemented over the next several months in an effort to upgrade and improve upon network communication systems, effectively increasing video surveillance capacity while enhancing national safety and security.  As an organization on the forefront of digital transformation, were seeing cities and countries across the globe  especially those with dense populations  investing in smarter infrastructure to maintain and manage operational efficiencies through accurate, real-time data, said David Ly, Iveda Founder and CEO. Iveda is thrilled to be a part of Taiwans continued journey toward smart city status. Through these additional contracts, we are effectively equipping local organizations and municipalities with the technology needed to prepare their communication networks and safety systems, all while enabling personnel to automate wherever possible, limiting waste in both energy and human power for true smart city innovation.  Iveda will work with these organizations and government bodies to provide tailored, integrated solutions incorporating Ivedas legacy cloud video system, IvedaXpress, alongside video management command center technologies. IvedaXpress is an enterprise-level plug and play cloud-based video surveillance solution. IvedaXpress is supported by secure, remote data centers with fault-tolerant infrastructure, designed for high reliability, availability, and security; the technology can also be deployed in a private cloud.  Details surrounding Ivedas contracts with organizations and government entities across Taiwan include:  Taiwan Stock Exchange: Iveda technology will work to enhance overall system security and interoperability through upgraded IP video servers, network servers, and general workstations.Tainan Solar Park: Iveda has installed smart power electrical controls and monitoring equipment that will aid in automating demand response routing of power.Taipei City Government Public Works Bureau: Iveda has installed additional IP switches and video servers as well as IP cameras and Ivedas cloud surveillance solution.Additional Taiwan Government Municipalities: Iveda has installed network communication servers for seamless IoT and smart power management.  Iveda continues to work closely with key telecom and service provider partners throughout Taiwan, leveraging existing government relationships to connect with municipalities looking to upgrade smart city capabilities. As end-user needs evolve, service providers must work with innovative technology like Ivedas to offer flexibility to customers while leveraging existing infrastructure where possible. Through education and field expertise, Iveda continues to demonstrate leadership via IP video and data centric technology, with AI support to accomplish the continuously advancing goals of the end-customer.  This news comes on the heels of Ivedas $1.5M Utilus Smart Pole deployment in Kaohsiung, Taiwan as the organization continues to set the standard for smart city innovation worldwide.  About Iveda Solutions  Iveda (NASDAQ:IVDA) is the provider of global solutions for cloud-based, video AI search and surveillance technologies that protect the people, places, and things that matter the most. Ivedas technology has the power to provide instant intelligence to existing infrastructure, enabling cities and organizations around the world to seamlessly enter the fifth industrial revolution. Iveda operates at the forefront of digital transformation of cities across the world, using IoT platforms with smart sensors and devices developed to aid with use cases surrounding public safety, security, elderly care, energy efficiency, and environment preservation. Headquartered in Mesa, Arizona, with a subsidiary in Taiwan, Iveda is publicly traded under the ticker symbol IVDA.  +++++  Media ContactOlivia Civiletto Erwinolivia@dottedlinecomm.com 617.477.9857    "
  },
  {
    "body": "Beautiful and Strong Black Woman\nAI Newsletter Helps Creators Slay Doubt By Leveraging AI\nSACRAMENTO, CA, USA, February 1, 2023 /\nEINPresswire.com\n/ -- Imposter Syndrome in 2023 is a luxury tax.\nIn retail, a luxury tax is a sales tax or surcharge levied only on certain products or services that are deemed non-essential or accessible only to the super-wealthy, such as expensive cars, private jets, yachts and the like.\nImposter Syndrome causes a feeling of inadequacy, self-doubt and insecurity.\nIt is insidious.\nIt is vile.\nIt is a liar.\nWith the introduction of Open AI ChatGPT, creators can no longer afford to doubt themselves because AI will inevitably replace many skilled laborers today.\nThat's why in honor of Black History Month, 28-year postal veteran Meiko S. Patton has created The Peripheral newsletter to help underrepresented and marginalized creators gain access to tools needed to build a thriving AI business and slay doubt.\nMeiko created the newsletter out of necessity. After she was bullied and harassed on her job for nearly two years at the height of the pandemic, she had to take time to prioritize her mental health. She first did this by creating a WOC Adult Affirmation coloring book and then she dove into learning all she could about web3 and AI.\nBecause of the vile treatment I experienced at work, I created this free resource. I unfortunately know first-hand how awful it feels to not belong, to not be wanted, and made to feel less than. Thats why I created this newsletter, to give all creators a leg up on how to earn income from AI and web3 and no longer have to trade time for money, she said.\nThe Peripheral is a weekly newsletter that covers AI, Web3, and No-Code Tools for creators to begin making money immediately. In addition, Meiko curates the latest news in the industry to keep creators abreast of current trends.\nMost newsletters just want people to consume the content. The Peripheral is different. At the end of each newsletter, Meiko makes sure there is one actionable idea that can be implemented the same day. This 5-minute newsletter is meant to inspire action, not simply to be consumed and discarded.\nOne money-making idea involves Meikos coloring book.\nLast year, Meiko created I Am Unbreakable, a WOC Adult Affirmation Coloring Book. It took her over 30 days to create, format, and finally upload to Amazon. If she had known about AI or had access to The Peripheral newsletter,  it would have taken her far less time. With access to The Peripheral, creators can now make the same book in less than 10 minutes.\nThere is an AI software called MidJourney. It creates images from the prompts you give it.\nIn MidJourney, you can use the \"coloring book\" prompt to create black and white images. Creators can then create a series of these images in any specific genre, collate them into a book and publish it on Amazon.\nSo, instead of always paying Amazon for things, creators can now have Amazon pay them for the coloring books they make with AI.\nAI is here to stay, that's why Meiko teaches creators how to leverage and learn from it.\nWhat Creators Can Learn From AI\nAI is not doubting whether it can replace you. It just will.\nAI is not feeling fear or insecurity about being thought of as a fraud. It simply executes.\nAI is not a perfectionist. It knows it will not spit out perfect answers every time. But it gives you what its got.\nAI is not constantly comparing itself to other AI programs. It does what it can do and that is enough.\nAI isnt afraid of celebrating its success. ChatGPT reached over a million users in five days. Whoop, whoop!\nAI doesnt feel it doesnt deserve success. It bathes in it and eats it for breakfast.\nAI isnt afraid to accept compliments and accolades. It welcomes it and actively seeks it out.\nMeiko believes AI ChatGPT have done all creators a favor.\nCreators can no longer afford to think of themselves as less than, because they are not.\nThe world needs all creators to show up authentically as themselves because no one can Google or"
  }
]