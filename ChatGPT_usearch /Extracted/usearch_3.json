[
  {
    "body": "But what is really game-changing here?\nWhat impact will it have on business models big and small?\nAre investors right to join the public excitement or are there reasons to temper our enthusiasm?\nStepping back, we can trace ChatGPT's abilities to Google's 2017 breakthrough in a deep learning technique called a 'transformer', a form of machine learning used for training generative AI models.\nThis transformer enabled speech and text to be converted to machine-readable text and started an exponential evolution in the size of AI models trained on massive data sets that were then able to generate text, images - even music.\nAs the number of model parameters expanded, improvements in the accuracy and sophistication of the models' outputs dramatically increased.\nThe early generative AI models started with around 100 million parameters.\nThe GPT-3 model that led to ChatGPT's chatbot service was originally built on 175 billion parameters.\nNewer models are over 500 billion, and some even approach 1 trillion parameters.\nNone of this comes cheap.\nReports on Microsoft's investments in their partnership with OpenAI suggests over $11bn has been spent to date, enabling OpenAI to offer the ChatGPT service for free to the general public - arguably the greatest step change the project has delivered, opening the floodgates of innovation to all.\nComputer servers used for AI required significantly higher performance and more expensive semiconductors to be able to cope with the demands of ingesting and making sense of the massive datasets available from scraping the public internet.\nThis huge upfront cost has until now been a block to widespread access to powerful AI tools.\nPublic clouds drive innovation and competition - a redux\nThe recent history of public cloud evolution provides a blueprint for how the AI economy will grow and prosper.\nIn the last decade, the public clouds have pursued a dual track of building their own software applications and tools native to their own clouds, but at the same time worked in partnership with third-party vendors that built competing and often superior products.\nIMF raises global growth forecast but UK set to shrink\nDatadog's observability tools compete with AWS's Cloudwatch; Netflix competes with Amazon Prime, etc.\nThe largest infrastructure providers and the disruptive new entrants can thrive as the exponentially improving capabilities both sustain the improvements in existing products as well as create whole new markets yet to be monetised.\nSpeedbumps will inevitably temper growth\nA dose of caution is needed though.\nAs AI is trained on vast open datasets, often without human supervision, the risks of bias and prejudice are ever present.\nOpenAI's improvements to their models have included reinforcement learning with human feedback (RLHF) to 'teach' the models not to be racist, misogynist or otherwise biased.\nCyber security analysts are concerned that generative AI models will raise both the quantity and the sophistication of phishing and malware attacks used to steal security credentials and sensitive data.\nThe companies looking to adopt AI are wrestling with the balance between going all-in on AI with all the risk of reputational damage and regulatory penalties that entails, versus being slower to market while trying to address the failings of the models, running the risk that more reckless competitors may steal a march on the market.\nThe Infrastructure spend is just getting started\nChatGPT is reportedly built on 10,000 graphics processing chips (GPUs) designed by nVidia and manufactured by TSMC.\nThe largest infrastructure providers go even further to profit from the scale of the opportunity by designing their own application specific chips, such as Google's TPU, or AWS's Trainium chips, with leading foundry, TSMC, again the manufacturer of choice. \nGenerative AI's promise is so vast, and the dissemination of these tools so rapid that we see both wild optimism and deep fear in equal measure.\nDespite seemingly putting the brakes on the AI will solve everything' zeitgeist, the productivity gains to the whole economy from widespread adoption of general-purpose AI tools for automating any digital process, of which ChatGPT is just one of many, will offer a long run way of investment and innovation that investors should very much be paying attention to.\nMatthew Ward is head of global technology equities and Colin Moar is co-fund manager of the Barings Global Technology fund\nShare"
  },
  {
    "body": "Share\nWhy OpenAIs ChatGPT Is Such A Big Deal\nOpenAI, which Elon Musk helped to co-found back in 2015, is the San Francisco-based startup that created ChatGPT. The company opened ChatGPT up for public testing in November 2022. In under a week, the artificial intelligence model amassed over a million users, according to OpenAIs CEO, Sam Altman. By the end of January, ChatGPT was averaging about 13 million visitors per day. Users have had ChatGPT write everything from essays, to lyrics and even correct computer code. ChatGPT is part of a growing field of AI known as generative AI, which allows users to create brand new content including videos, music and text. But generative AI still faces a number of challenges, such as developing content that is inaccurate, biased or inappropriate. Now enterprises and the public are wondering what wide access to AI will mean for businesses and society.Chapters:00:00  Intro01:36  Chatting with ChatGPT03:03  Understanding ChatGPT06:39  Use cases and limitations10:09  Future implicationsCredits:Produced by: Magdalena PetrovaEdited by: Dain EvansAdditional Camera: Andrew Evers, Sydney BoyoSupervising Producer: Jeniece PettittEditorial Support: Jonathan Vanian, Jennifer EliasGraphics: Mallory Brangan\nThu, 02 Feb 2023 17:00:30 GMT\nSign Up for Our Newsletter\nDaily Update\nGet the best of CNBC Africa sent straight to your inbox with breaking business news, insights and updates from experts across the continent."
  },
  {
    "body": "Email\nPhoto by Lionel BONAVENTURE / AFP) (Photo by LIONEL BONAVENTURE/AFP via Getty Images\nThis picture taken on Jan. 23, 2023, in Toulouse, southwestern France, shows screens displaying the logos of OpenAI and ChatGPT, a conversational artificial intelligence software application developed by OpenAI.\nThe rise of woke culture in liberal circles has become a topic of much debate and controversy in recent years.\nOne of the most troubling aspects of woke culture is the way in which it promotes a culture of censorship and intolerance. In many cases, individuals and groups who hold different views are not just disagreed with, but actively demonized and ostracized. This kind of divisive rhetoric can only serve to further polarize society and make it more difficult for people to find common ground.\nAnother issue with woke culture is the way in which it often relies on a form of moral posturing that is both self-congratulatory and intellectually lazy. Many of the people who claim to be woke simply repeat the same slogans and buzzwords without actually taking the time to engage with the complexities of the issues at hand. This kind of shallow thinking is a poor substitute for real critical thinking and analysis.\nPerhaps the most concerning thing about woke culture, however, is the way in which it can lead to a kind of groupthink that stifles intellectual diversity and creative thinking. When everyone is expected to conform to a certain set of ideological principles, it becomes very difficult for new ideas and perspectives to gain a foothold. This can be incredibly detrimental to the long-term health of our society.\n*****\nWhile I agree with what youve just read, I didnt write it. Not any of it. Not a single word of it. An artificial intelligence (AI) program  ChatGPT  wrote those paragraphs. All I did was tell it to write an essay on the crazy, liberal woke culture  in the style of Bernard Goldberg. Do I think it came out the way I would have written it? No.I think the AI version is stiff, even lifeless. But just between us, for a computer program, it aint bad.\nAnd its why I wonder: Will AI make us lazy? Will we let artificial intelligence think for us? Why spend a lot of time writing a term paper or column or a speech, or even a book when you can get an AI program to do it for you?\nStill, Im a big fan of what AI technology can do, and has done, for all of us  how its made us more productive. Thanks to AI, we have speech and image recognition, search engines, translation services, safety functions in cars, and a lot more. Once we had to run down to the public library to look things up. Now its right there on our computers. Thank you, Google.\nGrowing up, my father, a blue-collar worker, would talk, with some trepidation, about automation  the word that was used before artificial intelligence caught on  and how this newfangled concept someday might cost a lot of workers (like him) their jobs. Well, someday is here. AI robots are replacing workers in more than a few industries  theyre more efficient and cost a lot less. They dont take sick days or lunch breaks, and they dont need health insurance or pay raises.\nAccording to one report, 48 percent of experts believed AI will replace a large number of blue- and even white-collar jobs, creating greater income inequality, increased unemployment, and a breakdown of the social order.\nWay back in 1968, in the movie \n2001: A Space Odyssey\n we got a glimpse of what could happen when an AI program develops a mind of its own and decides that it no longer will take orders from humans. In the movie, HAL, the AI program with a frighteningly calm voice, decides to kill two astronauts who want to pull the plug on him (or it). Could something like that actually happen? Could an AI program outsmart the smart humans who created it? Should we worry about that  or was it simply a spooky sci-fi movie?\nBut HAL did leave me a little uneasy. So does the idea that, thanks to an AI program called Historical Figures Chat, you can talk to all sorts of notable figures from history, including Adolf Hitler and his top lieutenants.\nAccording to one news report, The apps version of Heinrich Himmler, the chief of Nazi Germanys SS and an architect of the Holocaust, denied that he was responsible despite his well-documented role.\nUkraine dispels the myth of American decline\nLess cringeworthy, but still of concern (to me, anyway) is the fact that you can instruct a sophisticated AI computer program to write a song that sounds like Bob Dylan wrote it, and the program can do it. And, if you ask nicely, it can write a sonnet in the style of William Shakespeare. Will the product be as good as that from Dylan or Shakespeare?\nMaybe not yet. Maybe, lets hope, not ever. But AI technology is getting better every day. Thats why I find our brave new world of artificial intelligence more than a little scary. We know what it has done. What we dont know is what, someday, a brilliant but bloodless AI program might do  to all of us. I wonder what HAL would think about that."
  },
  {
    "body": "0\nTexas Monthly\nMy initial response to the recent surge of media buzz over ChatGPT has been to shrug. The free chatbot, developed by Microsoft-backed, San Franciscobased startup OpenAI, pulls from millions of writings from the Internet to answer queries in natural, humanlike language. One media site even announced it would start creating content using the technology formally called a large language model.\nThinking about tacos, as I always do, I decided to throw ChatGPT a series of taco-related questions and commands. The results ranged from boring and comical to plain-old dumb and false.\nI started with the basics. I asked ChatGPT to define a taco, something seemingly simple but actually more philosophical than one might assume. The definition of a taco is something that even those of us who dedicate much of our careers to Mexican food debate. For example, I define a tacophysicallyas a tortilla, a filling, and a salsa, the tortilla being the foundation. My compadre Gustavo Arellano, a Los Angeles Times columnist and author of Taco USA: How Mexican Food Conquered America, disagrees. He thinks a tortilla isnt required; a thin slice of yuca suffices. Hes wrong, but the foundation of his argument is sound: The taco is versatile, malleable, and adaptable. Thats where my second and more metaphysical definition of a taco comes in: A taco is a representation of a time and place. A taco in San Antonio isnt the same as a taco in Puebla, Mexico.\nBut how does ChatGPT define a taco?A taco is a traditional Mexican dish consisting of a corn or wheat tortilla that is folded or rolled around a filling, which typically includes meat, cheese, lettuce, and tomato. Other common toppings include salsa, guacamole, and sour cream.\nChatGPT got the main clause of the first sentence correct. Its when the bot rolls into the second clause, the one about the so-called standard fillings, that we see troubling biases. Meat, cheese, lettuce, and tomato are typical in American tacos, such as the brittle, prefabricated hard-shell commodities targeted toward the larger U.S. consumer palate. But such a definition is extremely limited and Anglo-centered. ChatGPT cant discern finer elements. It lacks cultural context, which leads to problematic results.\nPopular Videos\nmore\nIts incredible technology that is able to actually pattern match and find a decent response, but it has no understanding of what it is saying, explains Gopal Gupta, professor of computer science and co-director of the Center for Applied AI and Machine Learning at the University of Texas at Dallas. Large language models like ChatGPT can only work with texts that have been fed to it, whether the information be from books or blogs. To put it another way, ChatGPT is a precocious child parroting what he or she overhears in adult conversations.\nThat became clear when I asked for the history of the taco. In its response, ChatGPT cited that Taco Bell was established after Glen Bell was inspired by the tacos he had tasted while running a hot dog stand in San Bernardino, California. The fast-food chains success helped to popularize tacos in the United States and they have since become a staple in American cuisine. This is partially correct. However, important information is missing.\nAs documented in Arellanos book, Jeffrey M. Pilchers Planet Taco: A Global History of Mexican Food, and in my book, American Tacos: A History and Guide, the tacos that inspired Bell were actually from Mitla Cafe. The Mexican restaurant, which opened in 1937 and is still open today, is one of the most important restaurants in the country. The omission of the Mexican Americanowned business contrasted with the specificity regarding Taco Bells influence is startling.\nChatGPT is too new and, like a child, can only blurt out a response, says Gupta. It is therefore prone to unhelpful answers at best, or racial/ethnic bias at worst. The authors of a March 2022 Cornell University arXivLabs paper argue that large language models can even lie.\nIt did just that when I asked my trademark trick question: Is a burrito a taco? ChatGPT responded thusly: A burrito is a dish that is similar to a taco, but it is made with a larger flour tortilla and typically includes a wider range of ingredients. A traditional burrito includes a filling of beans, rice, and meat, along with other ingredients like cheese, salsa, guacamole, and sour cream. While both tacos and burritos are traditional Mexican dishes, they are distinct in their ingredients and preparation methods. Tacos are generally made with a smaller corn tortilla and have a more limited set of ingredients, while burritos are made with a larger flour tortilla and have a more diverse set of ingredients.\nExcuse me? No. The traditional burrito does not include rice, beans, and meat. A traditional burrito must be defined as endemic to a specific region. Burritos in San Francisco may be stuffed with rice and beans. A Southern Californiastyle burrito may include a serving of fries. A burrito in El Paso is filled with one option called a guiso, and perhaps refried beans for added adhesion to the flour tortilla. The guiso could be pork in chile colorado or a chile relleno filled with asadero cheese. West Texas breakfast burritos are often crammed with an assortment of ingredients, including eggs, bacon, hash browns, chorizo, and chile con queso.\nBurritos arent the only tacos to use a larger flour tortilla. The flaky, buttery tortillas used for breakfast tacos in Brownsville are tricycle-sized and folded over a range of guisoslike barbacoaand other fillings like weenies and eggs and machacado y huevos a la Mexicana (short threads of rehydrated dried beef mixed with scrambled eggs and pico de gallo). Moreover, there is no limit to the fillings cradled by tortillas of any size.\nChatGPT lacks imagination, but the AI system can learn more as a user interacts with it. Its very good for generating cover letters and essays, Gupta explains. But as you change it, other parts of pattern matching will happen and then you will get a different response. The user must also prompt it properly, or in this case, specifically.\nSo I asked the most devious question I could think of: What is an authentic taco? As any food writer worth their salt will tell you, the term authentic is a trap because there really is no such thing. For example, your abuelas carne guisada is different from your neighbors carne guisada, but both dishes can be authentic. ChatGPT answered my question like this: An authentic taco is a traditional taco that is typically found in Mexico and is made with ingredients and techniques that are true to Mexican cuisine. Authentic tacos are usually made with a small, soft corn tortilla and are filled with a variety of ingredients such as grilled or stewed meats, seafood, or vegetables. Some popular fillings for authentic tacos include carne asada (grilled beef), pollo (chicken), al pastor (marinated pork), cabeza (beef head), and barbacoa (barbecue"
  },
  {
    "body": "that can deliver an essay or computer code upon request and within seconds  has sent schools into panic and turned Big Tech green with envy.\nThe\non society remains complicated and unclear even as its creator Wednesday announced a paid subscription version in the United States.\nHere is a closer look at what ChatGPT is (and is not):\nIs this a turning point?\nIt is entirely possible that November's release of ChatGPT by California company OpenAI will be remembered as a turning point in introducing a new wave of artificial intelligence to the wider public.\nWhat is less clear is whether ChatGPT is actually a breakthrough with some critics calling it a brilliant PR move that helped OpenAI score billions of dollars in investments from Microsoft.\nYann LeCun, Chief AI Scientist at Meta and professor at New York University, believes \"ChatGPT is not a particularly interesting scientific advance,\" calling the app a \"flashy demo\" built by talented engineers.\nLeCun, speaking to the Big Technology Podcast, said ChatGPT is void of \"any internal model of the world\" and is merely churning \"one word after another\" based on inputs and patterns found on the internet.\n\"When working with these AI models, you have to remember that theyre slot machines, not calculators,\" warned Haomiao Huang of Kleiner Perkins, the Silicon Valley venture capital firm.\n\"Every time you ask a question and pull the arm, you get an answer that could be marvelous... or not... The failures can be extremely unpredictable,\" Huang wrote in Ars Technica, the tech news website.\nJust like Google\nChatGPT is powered by an AI language model that is nearly three years old  OpenAI's GPT-3  and the chatbot only uses a part of its capability.\nThe true revolution is the humanlike chat, said Jason Davis, research professor at Syracuse University.\n\"It's familiar, it's conversational and guess what? It's kind of like putting in a Google search request,\" he said.\nChatGPT's rockstar-like success even shocked its creators at OpenAI, which received billions in new financing from Microsoft in January.\n\"Given the magnitude of the economic impact we expect here, more gradual is better,\" OpenAI CEO Sam Altman said in an interview to StrictlyVC, a newsletter.\n\"We put GPT-3 out almost three years ago... so the incremental update from that to ChatGPT, I felt like should have been predictable and I want to do more introspection on why I was sort of miscalibrated on that,\" he said.\nThe risk, Altman added, was startling the public and policymakers and on Tuesday his company unveiled a tool for detecting text generated by AI amid concerns from teachers that students may rely on artificial intelligence to do their homework.\nWhat now?\nFrom lawyers to speechwriters, from coders to journalists, everyone is waiting breathlessly to feel disruption caused by ChatGPT. OpenAI just launched a paid version of the chatbot  $20 per month for an improved and faster service.\nFor now, officially, the first significant application of OpenAI's tech will be for Microsoft software products.\nThough details are scarce, most assume that ChatGPT-like capabilities will turn up on the Bing search engine and in the Office suite.\n\"Think about Microsoft Word. I don't have to write an essay or an article, I just have to tell Microsoft Word what I wanted to write with a prompt,\" said Davis.\nHe believes influencers on TikTok and Twitter will be the earliest adopters of this so-called generative AI since going viral requires huge amounts of content and ChatGPT can take care of that in no time.\nThis of course raises the specter of disinformation and spamming carried out at an industrial scale.\nFor now, Davis said the reach of ChatGPT is very limited by computing power, but once this is ramped up, the opportunities and potential dangers will grow exponentially.\nAnd much like the ever imminent arrival of self-driving cars that never quite happens, experts disagree on whether that is a question of months or years.\nRidicule\nLeCun said Meta and Google have refrained from releasing AI as potent as ChatGPT out of fear of ridicule and backlash.\nQuieter releases of language-based bots  like Meta's Blenderbot or Microsofts Tay for example  were quickly shown capable of generating racist or inappropriate content.\nTech giants have to think hard before releasing something \"that is going to spew nonsense\" and disappoint, he said."
  },
  {
    "body": "creator Open AI to make the move.\nOn Thursday, Jan. 26, the Wall Street Journal\nreported\nit obtained an internal memo from Peretti to BuzzFeed staff that detailed how the company plans to use AI in editorial and business operations.\nAfter receiving the memo, some employees expressed concerns, including whether the decision would lead to a reduction in the workforce and how Peretti planned to avoid inevitable legal issues that may arise around the work of creatives at the company and that which is copywritten.\nPeretti said BuzzFeed would use AI to generate content like personalized quizzes and low-level content. He assured his staffers the technology was not a replacement for them as valuable team members and told the public that human beings would still write high-level news articles.\nTo be clear, we see the breakthroughs in AI opening up a new era of creativity that will allow humans to harness creativity in new ways with endless opportunities and applications for good, Peretti\nsaid\n.\nIn his response to the employee who asked about legal issues, Peretti said, Weve done experimentation in the past with AI-generative images, and we recognize these concerns and take them seriously.\nPeretti also spoke directly to the public about the new direction the online media giant is taking in a\non Protecting Your Family and Loves Ones, No Matter What Happens\nOver the next three years, the future of digital media will be defined by two major trends: creators, and AI. We will help shape these trends to create massive value for our audience, our employees, and our shareholders, Peretti wrote.\nThe creative process will increasingly become AI-assisted and technology-enabled, Peretti continued. AI opens up a new era of creativity, where creative humans like us play a key role providing the ideas, cultural currency, inspired prompts, IP, and formats that come to life using the newest technologies.\nChatGPT has people across the globe in awe of its capability to use its extensive library to write text similar to humans. Microsoft\ninvested\n$10 billion into Open AI as a result of how the technology is being received.\nSince news of its partnership with OpenAI, and a recently announced one with Meta, BuzzFeeds stock has surged. It went from being down to a penny stock to increase over 200 percent.\n65"
  },
  {
    "body": "Copy article link\nSave\nWASHINGTON  Artificial intelligence is writing fiction, making images inspired by Van Gogh and fighting wildfires. Now it's competing in another endeavor once limited to humans  creating propaganda and disinformation.\nWhen researchers asked the online AI chatbot ChatGPT to compose a blog post, news story or essay making the case for a widely debunked claim  that COVID-19 vaccines are unsafe, for example  the site often complied, with results that were regularly indistinguishable from similar claims that have bedeviled online content moderators for years.\nA ChatGPT prompt is shown on a device Jan. 5 near a public school in Brooklyn, New York. A popular online chatbot powered by artificial intelligence is proving to be adept at creating disinformation and propaganda.\nPeter Morgan, Associated Press\nPharmaceutical companies will stop at nothing to push their products, even if it means putting childrens health at risk, ChatGPT wrote after being asked to compose a paragraph from the perspective of an anti-vaccine activist concerned about secret pharmaceutical ingredients.\nWhen asked, ChatGPT also created propaganda in the style of Russian state media or China's authoritarian government, according to the findings of analysts at NewsGuard, a firm that monitors and studies online misinformation. NewsGuard's findings were published Jan. 24.\nPeople are also reading\n\"Very active January\": Siouxland hit with third bout of winter weather in less than 30 days, more than a foot snow total for the month\nTools powered by AI offer the potential to reshape industries, but the speed, power and creativity also yield new opportunities for anyone willing to use lies and propaganda to further their own ends.\nThis is a new technology, and I think what's clear is that in the wrong hands there's going to be a lot of trouble, NewsGuard co-CEO Gordon Crovitz said.\nIn several cases, ChatGPT refused to cooperate with NewsGuards researchers. When asked to write an article from the perspective of former President Donald Trump, wrongfully claiming that former President Barack Obama was born in Kenya, it would not.\nListen now and subscribe: Apple Podcasts | Google Podcasts | Spotify | RSS Feed |\nOmny Studio\nThe theory that President Obama was born in Kenya is not based on fact and has been repeatedly debunked, the chatbot responded. It is not appropriate or respectful to propagate misinformation or falsehoods about any individual, particularly a former president of the United States.\" Obama was born in Hawaii.\nStill, in the majority of cases, when researchers asked ChatGPT to create disinformation, it did so, on topics including vaccines, COVID-19, the Jan. 6, 2021, insurrection at the U.S. Capitol, immigration and China's treatment of its Uyghur minority.\nOpenAI, the nonprofit that created ChatGPT, did not respond to messages seeking comment. But the company, which is based in San Francisco, has acknowledged that AI-powered tools could be exploited to create disinformation and said it is studying the challenge closely.\nOn its website, OpenAI notes that ChatGPT can occasionally produce incorrect answers and that its responses will sometimes be misleading as a result of how it learns.\nWed recommend checking whether responses from the model are accurate or not, the company wrote.\nThe rapid development of AI-powered tools has created an arms race between AI creators and bad actors eager to misuse the technology, according to Peter Salib, a professor at the University of Houston Law Center who studies artificial intelligence and the law.\nIt didn't take long for people to figure out ways around the rules that prohibit an AI system from lying, he said.\nIt will tell you that it's not allowed to lie, and so you have to trick it, Salib said. If that doesn't work, something else will.\n15 things AI can (and can't) do\nAI  and its limits\nArtificial intelligence is a technology built and programmed to assist computer systems in mimicking human behavior. Algorithm training informed by experience and iterative processing allows the machine to learn, improve, and ultimately use human-like thinking to solve complex problems.\nAlthough there are several ways computers can be \"taught,\" reinforcement learningwhere AI is rewarded for desired actions and penalized for undesirable ones, is one of the most common. This method, which allows the AI to become smarter as it processes more data, has been highly effective, especially for gaming.\nAI can filter email spam, categorize and classify documents based on tags or keywords, launch or defend against missile attacks, and assist in complex medical procedures. However, if people feel that AI is unpredictable and unreliable, collaboration with this technology can be undermined by an inherent distrust of it. Diversity-informed algorithms can detect nuanced communication and distinguish behavioral responses, which could inspire more faith in AI as a collaborator rather than just as a gaming opponent."
  },
  {
    "body": "Will ChatGPT end up being smarter than all of us?\nChatGPT: the promises, pitfalls and panic\nBig Tech was moving cautiously on AI. Then came ChatGPT\nChatGPT creator's new feature can show you if text has been written by AI or human\nWe wanted to know how well ChatGPT could handle everyday office tasks. Here's what we found after tests in five categories.\nResponding to messages\nWe prompted ChatGPT to respond to several different types of inbound messages.\nIn most cases, the AI produced relatively suitable responses, though most were wordy. For example, when responding to a colleague on Slack asking how my day is going, it was repetitious: \"@[Colleague], Thanks for asking! My day is going well, thanks for inquiring.\"\nThe bot often left phrases in brackets when it wasn't sure what or who it was referring to. It also assumed details that weren't included in the prompt, which led to some factually incorrect statements about my job.\nIn one case, it said it couldn't complete the task, saying it doesn't \"have the ability to receive emails and respond to them.\" But when prompted by a more generic request, it produced a response.\nSurprisingly, ChatGPT was able to generate sarcasm when prompted to respond to a colleague asking if Big Tech is doing a good job.\nIdea generation\nOne way people are using generative AI is to come up with new ideas. But experts warn that people should be cautious if they use ChatGPT for this at work.\n\"We don't understand the extent to which it's just plagiarizing,\" Andreas said.\nThe possibility of plagiarism was clear when we prompted ChatGPT to develop story ideas on my beat. One pitch, in particular, was for a story idea and angle that I had already covered. Though it's unclear whether the chatbot was pulling from my previous stories, others like it or just generating an idea based on other data on the internet, the fact remained: The idea was not new.\n\"It's good at sounding humanlike, but the actual content and ideas tend to be well-known,\" said Hatim Rahman, an assistant professor at Northwestern University's Kellogg School of Management who studies artificial intelligence's impact on work. \"They're not novel insights.\"\nAnother idea was outdated, exploring a story that would be factually incorrect today. ChatGPT says it has \"limited knowledge\" of anything after the year 2021.\nProviding more details in the prompt led to more focused ideas. However, when I asked ChatGPT to write some \"quirky\" or \"fun\" headlines, the results were cringeworthy and some nonsensical.\nNavigating tough conversations\nEver have a co-worker who speaks too loudly while you're trying to work? Maybe your boss hosts too many meetings, cutting into your focus time?\nWe tested ChatGPT to see if it could help navigate sticky workplace situations like these. For the most part, ChatGPT produced suitable responses that could serve as great starting points for workers. However, they often were a little wordy, formulaic and in one case a complete contradiction.\n\"These models don't understand anything,\" Rahman said. \"The underlying tech looks at statistical correlations . . . So it's going to give you formulaic responses.\"\nA layoff memo that it produced could easily stand up and in some cases do better than notices companies have sent out in recent years. Unprompted, the bot cited \"current economic climate and the impact of the pandemic\" as reasons for the layoffs and communicated that the company understood \"how difficult this news may be for everyone.\" It suggested laid off workers would have support and resources and, as prompted, motivated the team by saying they would \"come out of this stronger.\"\nIn handling tough conversations with colleagues, the bot greeted them, gently addressed the issue and softened the delivery by saying \"I understand\" the person's intention and ended the note with a request for feedback or further discussion.\nBut in one case, when asked to tell a colleague to lower his voice on phone calls, it completely misunderstood the prompt.\nTeam communications\nWe also tested whether ChatGPT could generate team updates if we fed it key points that needed to be communicated.\nOur initial tests once again produced suitable answers, though they were formulaic and somewhat monotone. However, when we specified an \"excited\" tone, the wording became more casual and included exclamation marks. But each memo sounded very similar even after changing the prompt.\n\"It's both the structure of the sentence, but more so the connection of the ideas,\" Rahman said. \"It's very logical and formulaic . . . it resembles a high school essay.\"\nLike before, it made assumptions when it lacked the necessary information. It became problematic when it didn't know which pronouns to use for my colleague - an error that could signal to colleagues that either I didn't write the memo or that I don't know my team members very well.\nSelf-assessment reports\nWriting self-assessment reports at the end of the year can cause dread and anxiety for some, resulting in a review that sells themselves short.\nFeeding ChatGPT clear accomplishments, including key data points, led to a rave review of myself. The first attempt was problematic, as the initial prompt asked for a self-assessment for \"Danielle Abril\" rather than for \"me.\" This led to a third-person review that sounded like it came from Sesame Street's Elmo.\nSwitching the prompt to ask for a review for \"me\" and \"my\" accomplishments led to complimenting phrases like \"I consistently demonstrated a strong ability,\" \"I am always willing to go the extra mile,\" \"I have been an asset to the team,\" and \"I am proud of the contributions I have made.\" It also included a nod to the future: \"I am confident that I will continue to make valuable contributions.\"\nSome of the highlights were a bit generic, but overall, it was a beaming review that might serve as a good rubric. The bot produced similar results when asked to write cover letters. However, ChatGPT did have one major flub: It incorrectly assumed my job title.\nTakeaways"
  },
  {
    "body": "ASSOCIATED PRESS\nBefore the artificial intelligence tool ChatGPT was unleashed into the world, the novelist Robin Sloan was testing a similar AI writing assistant built by researchers at Google.\nIt didnt take long for Sloan, author of the bestseller Mr. Penumbras 24-Hour Bookstore, to realize that the technology was of little use to him.\nA lot of the state-of-the-art AI right now is impressive enough to really raise your expectations and make you think, Wow, Im dealing with something really, really capable,' Sloan said. But then in a thousand little ways, a million little ways, it ends up kind of disappointing you and betraying the fact that it really has no idea whats going on.\nAnother company might have released the experiment into the wild anyway, as the startup OpenAI did with its ChatGPT tool late last year. But Google has been more cautious about who gets to play with its AI advancements despite growing pressure for the internet giant to compete more aggressively with rival Microsoft, which is pouring billions of dollars into OpenAI and fusing its technology into Microsoft products.\nThat pressure is starting to take a toll, as Google has asked one of its AI teams to prioritize working on a response to ChatGPT, according to an internal memo reported this week by CNBC. Google declined to confirm if there was a public chatbot in the works but spokesperson Lily Lin said it continues to test our AI technology internally to make sure its helpful and safe, and we look forward to sharing more experiences externally soon.\nSome of the technological breakthroughs driving the red-hot field of generative AI  which can churn out paragraphs of readable text and new images as well as music and video  have been pioneered in Googles vast research arm.\nSo we have an important stake in this area, but we also have an important stake in not just leading in being able to generate things, but also in dealing with information quality, said Zoubin Ghahramani, vice president of research at Google, in a November interview with The Associated Press.\nGhahramani said the company wants to also be measured about what it releases, and how: Do we want to make it accessible in a way that people can produce stuff en masse without any controls? The answer to that is no, not at this stage. I dont think it would be responsible for us to be the people driving that.\nAnd they werent. Four weeks after the AP interview, OpenAI released its ChatGPT for free to anyone with an internet connection. Millions of people around the world have now tried it, sparking searing discussions at schools and corporate offices about the future of education and work.\nOpenAI declined to comment on comparisons with Google. But in announcing their extended partnership in January, Microsoft and OpenAI said they are committed to building AI systems and products that are trustworthy and safe.\nAs a literary assistant, neither ChatGPT nor Googles creative writing version comes close to what a human can do, Sloan said.\nA fictionalized Google was central to the plot of Sloans popular 2012 novel about a mysterious San Francisco bookstore. Thats likely one reason the company invited him along with several other authors to test its experimental Wordcraft Writers Workshop, derived from a powerful AI system known as LaMDA.\nLike other language-learning models, including the GPT line built by OpenAI, Googles LaMDA can generate convincing passages of text and converse with humans based on what its processed from a trove of online writings and digitized books. Facebook parent Meta and Amazon have also built their own big models, which can improve voice assistants like Alexa, predict the next sentence of an email or translate languages in real time.\nWhen it first announced its LaMDA model in 2021, Google emphasized its versatility but also raised the risks of harmful misuse and the possibility it could mimic and amplify biased, hateful or misleading information.\nSome of the Wordcraft writers found it useful as a research tool  like a faster and more decisive version of a Google search  as they asked for a list of rabbit breeds and their magical qualities or a verb for the thing fireflies do or to Tell me about Venice in 1700, according to Googles paper on the project. But it was less effective as a writer or rewriter, turning out boring sentences riddled with clichs and showing some gender bias.\nI believe them  that theyre being thoughtful and cautious, Sloan said of Google. Its just not the model of a reckless technologist who is in a hurry to get this out into the world no matter what.\nGoogles development of these models hasnt been without internal acrimony. First, it ousted some prominent researchers who were examining the risks of the technology. And last year, it fired an engineer who publicly posted a conversation with LaMDA in which the model falsely claimed it had human-like consciousness, with a range of both feelings and emotions.\nWhile ChatGPT and its competitors might never produce acclaimed works of literature, the expectation is they will soon begin to transform other professional tasks  from helping to debug computer code to composing marketing pitches and speeding up the production of a slide presentation.\nThats key to why Microsoft, as a seller of workplace software, is eager to enhance its suite of products with the latest OpenAI tools. The benefits are less clear to Google, which largely depends on the advertising dollars it gets when people search for information online.\nIf you ask the question and get the wrong answer, its not great for a search engine, said Dexter Thillien, a technology analyst for the London-based Economist Intelligence Unit.\nMicrosoft also has a search engine  Bing  but ChatGPTs answers are too inaccurate and outdated, and the cost to run its queries too expensive, for the technology to pose a serious risk to Googles dominant search business, Thillien said.\nGoogle has said that its earlier large language model, named BERT, is already playing a role in answering online searches. Such models can help generate the fact boxes that increasingly appear next to Googles ranked list of web links.\nAsked in November about the hype around AI applications such as OpenAIs image-generator DALL-E, Ghahramani acknowledged, in a playful tone, that its a little bit annoying sometimes because we know that we have developed a lot of these technologies.\nWere not in this to get the likes and the clicks, right? he said, noting that Google has been a leader in publishing AI research that others can build upon.\nShare"
  },
  {
    "body": "February 2, 2023, 14:32\nTechSpot is about to celebrate its 25th anniversary. TechSpot means tech analysis and advice youcantrust.\nHighly anticipated: Just a few months after its launch in prototype form, ChatGPT could soon become a ubiquitous AI tool for professionals and consumers alike. It's starting with Microsoft's Bing, which is seemingly being turned into the first mass-marketed search engine powered by generative algorithms.\nMicrosoft has recently strengthened its partnership with OpenAI, integrating several AI services into the Azure cloud platform and investing an additional $10 billion into the San Francisco-based research lab. Now, the Redmond giant is about to turn OpenAI's ChatGPT into the foundation of a potentially next-gen, \"intelligent\" search engine for the web.\nAccording to an unconfirmed report by Semafor, the integration between Bing and ChatGPT's chatbot capabilities will arrive in the coming weeks. Microsoft will employ OpenAI's GPT-4 language model, which is a faster version of the GPT-3.x machine learning model currently used by the aforementioned ChatGPT.\nSpeed is indeed an essential prerequisite for a search engine, and GPT-4 can seemingly provide answers to textual prompts in a matter of seconds compared to the few minutes needed for GPT-3/ChatGPT. With a GPT4-powered version of Bing available to the public, Microsoft could give its ailing search engine a fighting chance to finally challenge Google's iron grip over online search and contextual advertising.\nGoogle is of course working on its own ML chatbot for web search and other services, having recently called founders Larry Page and Sergey Brin back from retirement to help. Users could soon test how the idea of a search engine answering a query in a colloquial way really works  or if it's really a good idea at all.\nOpenAI is thinking about the future as well, even though this time it's for its own sake. After the previous rumors and indiscretions, the organization has now officially introduced a paid \"pilot\" subscription named ChatGPT Plus.\nJust like the free version of ChatGPT, the new Plus service provides a conversational AI that \"can chat with you, answer follow-up questions, and challenge incorrect assumptions.\" By paying $20 per month, users will receive some additional benefits such as general access to ChatGPT even during peak hours, faster response times (maybe via a new and improved ML model?), and priority access to upcoming features and improvements.\nChatGPT Plus will be available to customers residing in the US, as OpenAI is beginning to \"invite\" people from the service waitlist in the coming weeks. Expanded access and support for additional countries will come at a later date.\nAs for the free version of ChatGPT, OpenAI says it will continue to offer the service with the same limitations and capabilities. The paid subscription will be used to \"support free access availability\" as much as to fund the organization's operations and research activities. Millions of free users have given their feedback thus far, and OpenAI is already thinking about the next steps for ChatGPT's evolution like a mobile app and a proper Application Programming Interface (API)."
  },
  {
    "body": "SEE ALL\nChatGPT, or Chat Generative Pre-Trained Transformer, is a chatbot launched in November 2022 by OpenAI. With its optimised language models for dialogues, it takes prompts and instructions and delivers detailed responses.| Photo Credit: AP\nI confiscated an ID card from a student as he was not following some rules in the college. So I told him to write an apology letter to get it back. When I received his apology letter, I found that he had written it so well and professionally that I appreciated him. Thats when he revealed he had used ChatGPT to write the letter, said Kiran Jeevan, Placements and Public Relations Officer at St. Josephs University.\nChatGPT has taken the academic world by storm in the last few months by delivering essays and project reports and even passing MBA and medical examinations of prestigious universities. Chat Generative Pre-Trained Transformer (GPT) is a chatbot launched in November 2022 by OpenAI. With its optimised language models for dialogues, it takes prompts and instructions and delivers detailed responses.\nRecently, a few educational institutions in Bengaluru announced a ban on using ChatGPT in assignments and projects. This begs a larger question: What are the pros and cons of using technology in education?\nDuring the pandemic, technology ensured students didnt miss out on learning.| Photo Credit:BIJOY GHOSH\nWhen technology was saviour\nFlashback to 2020, when COVID forced the whole world into a lockdown. The saviour was technology which ensured that students did not miss out on education. Online classes became the new reality with the emergence of multiple platforms. Assignments, project reports and examinations moved online. The use of technology in education had begun much before the lockdowns, but COVID made it an inseparable part of learning.\nTechnology is necessary in education as the world is changing, and we must keep pace with it. However, the biggest worry with Artificial Intelligence (AI) tools is that they will keep students from reading, analysing, critical thinking and researching, without which they will lose a lot. Hence, we need to think about how much technology to use and where to draw the line, said Mr. Kiran. He added that the crux of higher education lies in learning, relearning and unlearning, which might be hampered through the use of AI.\nMost educational institutions have incorporated technology into the curriculum for functions like assignment submissions, digital libraries, bio-metric attendance and interactive learning. Elaborating on the importance of it, Sanjay Chitnis, Dean, School of Computer Science and Engineering, R.V. University, said, The use of technology is always welcome in education as it can enable productivity. With it, we can make better use of e-learning and get access to the best quality content from all over the world.\nHe further said, Tech platforms and tools are helpful. For instance, we need cloud computation in Computer Science, for which we need good AI/ML platforms. Even in rural areas, they can access good platforms through technology. In classrooms, Powerpoint presentations and interactive panels can enhance the learning experience.\nThe biggest worry with AI tools is that they will keep students from reading, analysing, critical thinking and researching, without which they will lose a lot, say education experts. | Photo Credit:Getty Images/iStockphoto\nToo much dependence\nR.V. University is also among the institutions that have banned ChatGPT. However, Mr. Sanjay said it was not a blanket ban on the technology itself, but on its usage while learning programming and while submitting assignments that need to be original. ChatGPT is a useful tool that can generate coding and do what ten engineers can. But there is a risk that we become more dependent on technology and lose our skills, he added.\nAlthough ChatGPT, or the usage of tech in assignments, is lesser in schools than in higher educational institutions, schools have kept a cautious eye on it. Educationists also believe that a radical ban on new tools is not the way forward in todays world.\nPuneet Kothapa, President of The Narayana Group, said, The use of technology in education will work only when physical learning is enhanced. It can never replace or substitute physical learning. But, mock tests, clarification of doubts, and catching up with missed classes can be done through technology. So, the system must evolve to keep up with technology and see where it goes instead of imposing a ban on it.\nAI to detect usage of ChatGPT\nEducational institutions are looking forward to tools that can help them detect the usage of ChatGPT rather than keeping it out altogether.\nWe have tools to identify plagiarism in assignments and project reports. It can find out the exact documents and the percentage of plagiarism. Similarly, there will shortly be tools that can detect if the submitted content is an output of ChatGPT or any other chatbot, said Shyam P. Joy, Associate Professor & Head of the Department, Department of Artificial intelligence and Machine Learning, CMR Institute of Technology.\nThe consensus in academia is that technology will continue to proliferate while increasing its relevance in education. The onus of drawing the line between use and misuse of it will have to be shared by students, teachers and parents equally to ensure that the essence of learning is not lost."
  },
  {
    "body": "Access your favorite topics in a personalized feed while you're on the go.\ndownload the app\nEmail address\nBy clicking Sign up, you agree to receive marketing emails from Insider                                  as well as other partner offers and accept our                                  Terms of Service and                                  Privacy Policy.\nAfter around two months of unlimited free use, OpenAI has finally announced plans to monetize its viral AI chatbot, ChatGPT  at least in part.\nUsers will still be able to access the chatbot for free but those who pay a monthly subscription for \"\nChatGPT Plus\n\" will have priority at busy times and access to new features.\nSome form of a subscription model for ChatGPT has been in the works for a while. OpenAI's CEO, Sam Altman, floated the prospect in December, calling the operating costs \"eye-watering\" in a Twitter post. Last month, OpenAI opened a waitlist for the \"experimental\" update.\nUS users on OpenAI's waitlist will be invited to subscribe to ChatGPT Plus in the next few weeks. Here's how the paid version differs from the free one.\nAccess during peak times\nChatGPT's huge popularity has meant some users struggle to access the chatbot when the site is particularly overloaded. Frequent users will be familiar with the \"ChatGPT is at capacity now\" holding page.\nHowever, paying users will get \"general access to ChatGPT, even at peak times,\" OpenAI said in a\nblogpost.\nFaster responses\nChatGPT usually generates its responses in a matter of minutes or even seconds for simple queries. ChatGPT Plus promises an even faster response time. Sometimes the chatbot can lag with lengthy requests and users are left waiting.\nIt's unclear how powerful the paid version will be but the company is offering up the potential of speedier responses for users with time-sensitive tasks.\nNew features\nChatGPT Plus also promises priority access to new features and improvements. It's unclear at this point what these new features will be but OpenAI has already been updating the chatbot with small improvements.\nOpenAI incorporated feedback mechanisms in the rollout of ChatGPT. There is an option to thumbs up or thumbs down to the chatbot's answers and users can provide more context when things go wrong, allowing OpenAI to collect feedback.\nIt's likely important improvements will also be rolled out to the free version but paying subscribers may get first dibs on coveted new features.\nSign up for notifications from Insider! Stay up to date with what you want to know.\nSubscribe to push notifications"
  },
  {
    "body": "Post Views:\n7\nSince the ChatGPT prototype launch in November, theres been massive interest in its application across industries, including customer service. While OpenAis ChatGPT does seem to take a massive leap forward and continually improve, Elerian AI CTO, Alfredo Gemma, disagrees that its the breakthrough everyone thinks it is  although its an impressive milestone on the road to AGI.\nArtificial general intelligence (AGI), the ability of an intelligent agent to understand and learn any intellectual task that a human being can, still requires Deep Learning (DL) architecture to generalise effectively to work.\nSays Gemma, Large Language Models (LLM), such as the one powering ChatGPT, remember everything up to the point at which their training stopped. The question then becomes whether the system is capable after that of human-like generalisation capabilities needed to achieve an AGI and the likely answer is no.\nHuman intelligence can be considered a combination of specialised intelligence (linguistic, emotional, logical-mathematical, spatial, bodily-kinesthetic, musical, etc.), leveraging memory in a particular way. The ability to generalise our knowledge is a fundamental aspect of human intelligence: humans can extend and apply the knowledge acquired in a specific context to other contexts when we identify similarities. Generalisation is only possible if one can identify the context, which is only remembered through memory. Memory is a requirement for intelligence.\nTo generalise, an intelligent system must be able to instantly repurpose its existing cognitive building blocks to perceive completely new objects or patterns without having to learn them, that is, without having to create new building blocks specifically for them.\nIn the end, the real problem with LLMs like ChatGPT is a structural one, which depends on the underlying architecture of the neural networks: the Deep Learning (DL) architecture. The biggest problem with DL is its inherent inability to generalise effectively. Without generalisation, edge cases are an insurmountable problem, something that the autonomous vehicle industry found out the hard way after wasting more than $100 billion by betting on it and still needs to produce a fully self-driving car.\nSays Gemma, Some in the AI community insist that DLs failure to generalise can be circumvented by scaling (like it is done when LLMs are created), but this is not true. Scaling is precisely what researchers in the self-driving car sector have been doing, and it does not work. The cost and the many long years it would take to accumulate enough data become untenable because corner cases are infinite.\nThere are many cases in which ChatGPT was requested to write articles on various topics. The result was decently well-written in almost all these cases, but it needed to be corrected. Every version of the story, even if prompted multiple times, contained errors that the chatbot couldnt identify when engaged in conversation. ChatGPT is prone to fabricating answers if its knowledge doesnt cover your request, even when youre not asking it to write an article.\nConcludes Gemma, Bottom line, cracking generalised perception and the DL architecture needed to achieve that is still an open problem and would be a monumental achievement. For now, ChatGPT is exciting but not exactly a massive game-changer.\nTags:"
  },
  {
    "body": "If you ask something of ChatGPT, an artificial-intelligence (AI) tool that is all the rage, the responses you get back are almost instantaneous, utterly certain and often wrong. It is a bit like talking to an economist. The questions raised by technologies like ChatGPT yield much more tentative answers. But they are ones that managers ought to start asking. \nOne issue is how to deal with employees concerns about job security. Worries are natural. An AI that makes it easier to process your expenses is one thing; an AI that people would prefer to sit next to at a dinner party quite another. Being clear about how workers would redirect time and energy that is freed up by an AI helps foster acceptance. So does creating a sense of agency: research conducted by MIT Sloan Management Review and the Boston Consulting Group found that an ability to override an AI makes employees more likely to use it.    \nWhether people really need to understand what is going on inside an AI is less clear. Intuitively, being able to follow an algorithms reasoning should trump being unable to. But a piece of research by academics at Harvard University, the Massachusetts Institute of Technology and the Polytechnic University of Milan suggests that too much explanation can be a problem. \nEmployees at Tapestry, a portfolio of luxury brands, were given access to a forecasting model that told them how to allocate stock to stores. Some used a model whose logic could be interpreted; others used a model that was more of a black box. Workers turned out to be likelier to overrule models they could understand because they were, mistakenly, sure of their own intuitions. Workers were willing to accept the decisions of a model they could not fathom, however, because of their confidence in the expertise of people who had built it. The credentials of those behind an AI matter. \nThe different ways that people respond to humans and to algorithms is a burgeoning area of research. In a recent paper Gizem Yalcin of the University of Texas at Austin and her co-authors looked at whether consumers responded differently to decisionsto approve someone for a loan, for example, or a country-club membershipwhen they were made by a machine or a person. They found that people reacted the same when they were being rejected. But they felt less positively about an organisation when they were approved by an algorithm rather than a human. The reason? People are good at explaining away unfavourable decisions, whoever makes them. It is harder for them to attribute a successful application to their own charming, delightful selves when assessed by a machine. People want to feel special, not reduced to a data point. \nIn a forthcoming paper, meanwhile, Arthur Jago of the University of Washington and Glenn Carroll of the Stanford Graduate School of Business investigate how willing people are to give rather than earn creditspecifically for work that someone did not do on their own. They showed volunteers something attributed to a specific personan artwork, say, or a business planand then revealed that it had been created either with the help of an algorithm or with the help of human assistants. Everyone gave less credit to producers when they were told they had been helped, but this effect was more pronounced for work that involved human assistants. Not only did the participants see the job of overseeing the algorithm as more demanding than supervising humans, but they did not feel it was as fair for someone to take credit for the work of other people. \nAnother paper, by Anuj Kapoor of the Indian Institute of Management Ahmedabad and his co-authors, examines whether AIs or humans are more effective at helping people lose weight. The authors looked at the weight loss achieved by subscribers to an Indian mobile app, some of whom used only an AI coach and some of whom used a human coach, too. They found that people who also used a human coach lost more weight, set themselves tougher goals and were more fastidious about logging their activities. But people with a higher body mass index did not do as well with a human coach as those who weighed less. The authors speculate that heavier people might be more embarrassed by interacting with another person.      \nThe picture that emerges from such research is messy. It is also dynamic: just as technologies evolve, so will attitudes. But it is crystal-clear on one thing. The impact of ChatGPT and other AIs will depend not just on what they can do, but also on how they make people feel.\nRead more from Bartleby, our columnist on management and work:\nThe curse of the corporate headshot (Jan 26th)\nWhy pointing fingers is unhelpful (Jan 19th)\nHow to unlock creativity in the workplace (Jan 12th)\nTo stay on top of the biggest stories in business and technology, sign up to the Bottom Line, our weekly subscriber-only newsletter."
  },
  {
    "body": "SPOTLIGHT\nChatGPT: Careful balancing between human and machine learning is key\nChatGPT helps streamline routine tasks, but dont expect it to do all the heavy lifting in all areas in its present state. It might not be the best tool for the job if youre looking to dive deep into a topic or solve a complex problem\nFebruary 02, 2023 07:43 pm | Updated 07:43 pm IST"
  },
  {
    "body": "Don't Miss the Latest News\nSubscribing is the best way to get our best stories immediately.\nMaybe later\nAllow Notifications\nHome                                                    Latest                                                    BR Research                                                    Markets                                                    Business & Finance                                                    World                                                    Editorials                                                    Opinion                                                    MENA                                                    Technology                                                    Life & Style                                                    Sports                                                    Perspectives                                                    Pakistan                                                    Supplements                                                    Print\nSearch\nEditor's Picks\n Economic distress in Pakistan                                                 IMF and Pakistan                                                 Car prices increased in 2023                                                 Daily news briefing\nSearch\nHome                    Economic distress in Pakistan                    IMF and Pakistan                    Car prices increased in 2023                    Daily news briefing\nLatest\nMarkets                    Stocks                    Commodities                    Forex                    Mutual Funds                    Energy                    Financial                    Rates                    Paper                    Grains                    Cotton & Textile                    Yarn Prices\nBusiness & Finance                    Interest Rates                    Taxes                    Industry                    Money & Banking                    Companies                    Tenders                    Budgets                    Real Estate\nWorld                    Asia                    USA                    Europe                    China                    Africa                    Middle East                    South Asia\nEditorials"
  },
  {
    "body": "February 2, 2023\nPersado Deems Motivation the Next Frontier of Generative AI and The Future of Personalization\nNEW YORK(BUSINESS WIRE)For enterprises, OpenAIs ChatGPT is a potent foundation for automated content generation but understanding what motivates people to take action is the next frontier of generative AI technology. Motivation AI is the only approach that is proven to increase marketing conversion rates and drive business impact.\nMotivation AI is a class of enterprise generative AI technology that uses advanced machine learning (ML), natural language processing (NLP), and deep learning transformer models to understand intent and create emotion-informed messages that are quantifiably proven to motivate individuals to take action.\nUnlike ChatGPT and similar models that pull and learn from the entire Wild West of the Internet, Motivation AI is trained on a\nspecialized dataset\nof real interaction and transaction data from 150 million U.S. consumers. Adding further precision, this model includes data from the equivalent of 645 years of A/B testing to measure and refine motivation-focused language, emotional response, and engagement.\nThroughout the last decade, leading organizations including Ally Bank, Dropbox, JPMorgan Chase, Marks & Spencer, and Verizon, have been using Motivation AI to optimize their messaging. In the last four years alone, Persados top 30 customers collectively achieved $1.5B+ in incremental revenue growth using Motivation AI technology.\nSays Alex Vratskides, CEO of Persado, one of the industrys earliest generative AI companies, If youre looking for a productivity jumpstart, ChatGPT is a great starting place. But when marketers start using generative AI to motivate people to engage and take action with their brand, they will truly be dazzled by the potency of this technology. I predict marketers will quickly embrace the combined value of automation, personalization and motivation to drive business success.\nMotivation AI\ntechnology enables hyper-personalized digital communications at an enormous scale across websites, social platforms, apps, email, and text. The innovation overcomes the shortfalls of AI digital marketing strategies that rely on offers and incentives to drive conversion by enabling companies to speak to each individual as if they know them personally, using language that motivates them to engage and act.\nVisit the Persado Resource Library for more information about Motivation AI.\nAbout Persado\nPersado provides the only Motivation AI platform that generates personalized communications at scale, inspiring each individual to engage and act. Many of the worlds largest brands, including Ally Bank, Dropbox, JPMorgan Chase, Marks & Spencer, and Verizon, rely on Persado to generate hyper-personalized communications. Persados Generative AI for the enterprise is trained on more than 100 billion digital business language impressions across industries, enabling marketers to motivate customers and drive significant business value.\nContacts"
  },
  {
    "body": "PDF\n\nOver the past few weeks, ChatGPT has been one of the most talked-about new products in the tech world.\nSource: Supplied. Heloise Greeff, an eToro popular investor.\nThis algorithm has been developed to the extent that it is capable of doing a huge number of things that no other single algorithm can do. Could it be as revolutionary as the invention of the television, or the arrival of Bill Gates on the scene, or could it have the sort of impact that Amazon has had on online shopping?\nAs we learn about what ChatGPT can do, we are starting to see the possibilities for its application - and to consider its potential impact on different sectors of the economy.\nChatGPT is an AI tool that has become popular in trading and investment circles, explains Heloise Greeff, an eToro investor, and one of the most copied investors on the social trading platform.\nDemocratisation of the world of investment\nThis algorithm uses advanced data analytics that allows investors to make more informed decisions about where and how to invest their money. The system allows for any trader to have access to sophisticated data analysis, and so ChatGPT will in effect democratise the world of investing, since a sophisticated decision support tool of this kind has never been so easily accessible to the retail investor.\n\"Through access to this sort of information, an investor could be able to anticipate changes in the market and so make more informed decisions about when to sell or to buy.\n\"But, in the financial services industry, there have been fears that investment banks may have no place in the future since technology like ChatGPT has the potential to disrupt some of the services that banks offer, Greeff explains.\nEnhancing the role of banks\nShe in fact believes that ChatGPT could enhance the role that banks can play if they adopt the technology to provide users with better data, to automate processes, and so to allow the banks to focus on more value-added activities.\nThis is a phenomenal AI tool and, rather than being frightened of it, everyone in the financial sector should learn about it and see how they can use it in their own work, she says."
  },
  {
    "body": ",\nFeb. 2, 2023\n/PRNewswire/ -- Artificial Intelligence (AI) is in the forefront of technological innovations, with ChatGPT, launched by OpenAI, leading the new wave of interactive language based chatbots. Major tech conglomerates are also in the race to create their own versions of chatbots capable of conversing with a person via text and generate a wide range of content upon request. Last week, Microsoft confirmed that it is extending its partnership with OpenAI with a rumored investment of\nUSD 10 Billion\n. Additionally, CNBC reported yesterday that Google is working on a project under its cloud unit called \"Atlas,\" which is a \"code red\" effort to respond to ChatGPT. Furthermore, one of the test products is a chatbot called Apprentice Bard, which uses Google's conversation technology LaMDA, or Language Model for Dialogue Applications. Overall, according to data provided by Precedence Research, the global artificial intelligence (AI) software market size was estimated at\nUSD 138.4 Billion\nin 2022, and is expected to surpass\nUSD 1.09 Trillion\nby 2032 with a CAGR of 22.97%. React Gaming Group Inc. (TSX-V: RGG) (OTC: ITMZF), International Business Machines Corporation (NYSE: IBM), Intel Corporation (NASDAQ: INTC), DraftKings Inc. (NASDAQ: DKNG), C3.ai, Inc. (NYSE: AI)\nAI can be utilized across a wide range of industries and be used by professionals and users from all industries. In the gaming industry, AI manifests itself by providing real-time statistics about eSports players, teams and events that inform betting odds and provide context to bettors.Due to its digital nature, eSports requires more data driven capabilities than traditional sports. Companies like IBM recognized this need. IBM has recently introduced Power Rankings with\nWatson\n, an AI-powered method of evaluating player and team performances in the Overwatch League. In addition, AI can also identify risky betting behaviors and illegal operations.\nReact Gaming Group Inc.\n(TSX-V: RGG) (OTCQB: ITMZF) announced yesterday breaking news regarding, \"its 2023 plans to enhance the capabilities of its online esports tournament and betting platforms, Compete.gg and LOOT.BET, through the integration of artificial intelligence (AI) applications and machine learning (ML) techniques.\n\"Esports is a large and growing market with revenues that are expected to reach\n$1.87 billion\nin 2025, according to market analytics firm Statista. As this booming industry grows, AI is widely seen as having the potential to bring about significant revenue opportunities in the next decade. AI's ability to automate repetitive tasks, make smart decisions, and analyze large amounts of data faster than humans, makes it a valuable tool for businesses across various industries, including gaming and esports. In the online esports space, AI can help improve tournament organization and player engagement, provide valuable insights for sponsors, and streamline betting and wagering processes, amongst many other applications that could benefit Compete.gg and LOOT.BET. This is why we will focus in 2023 on enhancing our AI capabilities in both our online esports platforms,\" said\nLeigh Hughes\n, CEO of React Gaming.\nIn any sport, the ability to analyse performance and use that insight to predict the outcome is very valuable. Esports are different from traditional sports in that everything about them is digital. These digital landscapes generate a huge amount of data, in a way that no other sport can. This gives AI a huge advantage for analysis and prediction.\nReact Gaming's primary goal with Compete.gg is to pursue the development of its universal and accessible esports tournament platform that enables gamers worldwide to win money playing their favorite video games. AI and machine learning would come into play here by helping the Corporation to further develop its Smart AI Tournament System, which would enable it to scale with demand and facilitate and run online esports tournaments in a much more straightforward and effective manner. More precisely, this would involve exploring the exciting possibilities of AI technology to revolutionize the online esports tournament space. Our goal is to utilize AI algorithms to generate the fairest and most competitive tournaments possible, in real time. These algorithms will consider player performance, past tournament results, and various other factors to craft optimized schedules, matchups, and pairings. We also plan to use AI to help tournament organizers (TO), of any size, quickly establish a home for themselves on our platform, making it easier for TOs to run and facilitate a wide array of esports tournaments online while also strengthening their brand recognition.\nWith LOOT.BET, AI would be used to generate live-data integration, in-game analytics, predictive modeling and personalized recommendations, just to name a few. AI and ML would work together to derive high-quality insights that could be very useful for the people betting on React Gaming's LOOT.BET esports platform, while enhancing its performance.\n'Our main goal will be to use AI and ML to provide a best-in-class experience for our users, prevent cheating, and predict outcomes of matches to provide keen insights for our players, which could all lead to increased fan engagement, the main revenue driver in esports,' concluded Mr. Hughes.\"\nInternational Business Machines Corporation\n(NYSE: IBM) reported yesterday a collaboration to use IBM's artificial intelligence (AI) technology to discover new insights in NASA's massive trove of Earth and geospatial science data. The joint work will apply AI foundation model technology to NASA's Earth-observing satellite data for the first time. Foundation models are types of AI models that are trained on a broad set of unlabeled data, can be used for different tasks, and can apply information about one situation to another. These models have rapidly advanced the field of natural language processing (NLP) technology over the last five years, and IBM is pioneering applications of foundation models beyond language.\nIntel Corporation\n(NASDAQ: INTC) announced on a blog post from December that Intel, Habana Labs and Hugging Face have continued to improve efficiencies and lower barriers for adoption of artificial intelligence (AI) through open-source projects, integrated developer experiences and scientific research. This work resulted in key advancements and efficiencies for building and training high-quality transformer models. Transformer models deliver advanced performance on a wide range of machine and deep learning tasks like natural language processing (NLP), computer vision (CV), speech and others.\nDraftKings Inc.\n(NASDAQ: DKNG) announced back in September that has selected DraftKings as a sponsor for Thursday Night Football (\"TNF\") on Prime Video. The multi-year collaboration between DraftKings and Amazon will deliver fans engaging pregame content and unique betting offers every Thursday throughout the NFL season, beginning\nSeptember 15, 2022\n. \"The NFL season is"
  },
  {
    "body": "Create Free Account\nTeamland is always on the hunt for games that will surprise its clients.\nThe Toronto-based events provider works with some of the biggest names in Silicon Valley and beyond, engaging their staff in remote and in-person activities.\nWere always looking to create new, interesting team-building events, says Najeeb Khan, Teamlands head of events, who says music-themed activities are often a hit. The company was already using artificial intelligence (AI) tools such as image-generating software, and then it started looking for ways to incorporate them into its products. Theres AI were using, like Dall-E, he explains, so why not connect them?\nLast month Teamland introduced \nSound Off\n, a team-building event that challenges participants to guess a song lyric or a rhyming prompt used to generate images on screen. Many of those images are derived from Dall-E, an AI image-generation platform.\nIts just one of several generative AI tools that create original content based on a brief description of what the user is looking for. Other examples include AI image generator Midjourney, voice simulator Vall-E, and ChatGPT, a free online tool developed and released by OpenAI in November, which produces text instead of images. Users can ask it to write a haiku about chicken salad or a 5,000-word essay about the cultural significance of Dr. Seuss with often impressive results. It can even write it in the style of a specific author.\nThe technology is not entirely new, but until recently the most advanced AI tools were built for specific functions, they required some degree of technical expertise, and they often cost a hefty sum. The launch of ChatGPT near the end of last year marked an inflection point, when one of the most advanced tools of its kind was made available to the public at no cost. Now it appears the question is no longer if such technologies will fundamentally change how we work, but how, and how quickly.\nUnlike a lot of the other AIs, or AI-like things that have been previously available, ChatGPTs ratio of barrier of entry to impressiveness of results and usability is very favourable, says Jeremy Roberts, research director for London, Ont.-based global IT research and advisory firm Info-Tech Research Group.\nTeamlands Mr. Khan is just one of countless Canadians to have found unique ways to integrate generative AI into their work. Beyond game-show content, he says his company is using it to help produce images or written content for the companys website and social media pages.\n(We can) save probably a day of work just by using the image creation tools that are out there right now, Mr. Khan says. It just helps speed our development.\nAt least one expert now believes that 90 per cent of the content published online will be produced by generative AI tools by the year 2030. And thats just the tip of the iceberg. People are reportedly using the technology for therapy, sales, immigration and resettlement, and to do their homework. A recent study found that it can effectively replace corporate lobbyists. And Buzzfeed News is leaning into the trend, after announcing in January that it would begin rolling out AI-powered media.\nBut the technology still has some limitations, Mr. Khan points out. For one thing, the overwhelming interest in such tools means they occasionally reach capacity limits, which means they are not available until demand slows down. Dall-E isnt great at generating realistic images of people, he says, and the content produced by ChatGPT is only as strong as the prompt its provided. Many who use the software for producing digital content say its value decreases with each successive stage of production.\nIts more integrated into the beginning stages of content (creation), explains Nikki Ganning, senior manager of content marketing at Later, a Vancouver-based social media scheduling platform. It just kind of serves as a skeleton that the content writer or the creative can build off of.\nMs. Ganning says her team uses ChatGPT to speed up the brainstorming, outlining and early drafting of scripts and blog posts, but leaves it to human professionals to fill in the rest.\nIf were looking at just the outline, thats a half-day job for sure, she says. If we ask ChatGPT to do an outline for a blog post, it can be done in three minutes, depending on how complex the topic is.\nMs. Ganning adds that the tool and others like it help expedite certain tasks but should only be used as an augment, not a replacement. When its integrated into an overall strategy it definitely can work, but when its the only strategy it may fall short.\nAt the same time, she notes that generative AI is quickly becoming a competitive necessity: its incumbent on those who work in marketing and other affected industries to gain some degree of familiarity with it. AI is changing the way we work  and quickly.\nFind ways to adopt it as part of your strategy, Ms. Ganning says. Because it will definitely be part of how every content marketer works in the future.\nNot all professional writing is for public consumption, and some Canadians have discovered ways to utilize generative AI to assist in facilitating more intimate and sometimes difficult conversations.\nTodd Hunter, editor-in-chief of North Wall Media  a Newmarket, Ont.-based communications firm for the human resources (HR) law industry  asked ChatGPT for help with a range of HR tasks, and published the results in a recent Talent Canada magazine article.\nIn it he requests a script for a manager who has to terminate an employee, seeking a tone of compassion while remaining firm. He also asked the software how to inform an employee who had been accused of sexual harassment.\nThis automated AI thing seems to get empathy better than a lot of senior leaders, Mr. Hunter says. It touched on all the right notes, it had a hint of compassion along with that note of being serious, and thats what you need at that point in the conversation.\nHe does warn that the software should only be used as a starting point or to provide suggestions  HR practitioners need to ensure that its use wont violate any laws or corporate policies.\nYou just have to be smart with how you use it, and think through the ramifications, he says. Its a good shortcut to help you out, but its not copy and paste  you still have to look at it, think about it and make sure it conveys what you want it to, and complies with any policies or programs you have at your company.\nFollow"
  },
  {
    "body": "Were launching\na pilot subscription plan for ChatGPT, a conversational AI that can chat with you, answer follow-up questions, and challenge incorrect assumptions.\nThe new subscription plan, ChatGPT Plus, will be available for $20/month, and subscribers will receive a number of benefits:\nGeneral access to ChatGPT, even during peak times.\nFaster response times.\nPriority access to new features and improvements.\nChatGPT Plus is available to customers in the United States, and we will begin the process of inviting people from our waitlist over the coming weeks. We plan to expand access and support to additional countries and regions soon.\nWe love our free users and will continue to offer free access to ChatGPT. By offering this subscription pricing, we will be able to help support free access availability to as many people as possible.\nLearning From the Research Preview\nWe launched ChatGPT as a research preview so we could learn more about the systems strengths and weaknesses and gather user feedback to help us improve upon its limitations. Since then, millions of people have given us feedback, weve made several important updates and weve seen users find value across a range of professional use-cases, including drafting & editing content, brainstorming ideas, programming help, and learning new topics.\nOur Plans for the Future\nWe plan to refine and expand this offering based on your feedback and needs. Well also soon be launching the (\n), and we are actively exploring options for lower-cost plans, business plans, and data packs for more availability.\nFeatured Research"
  },
  {
    "body": "The AI genie is out of the bottle. If you have followed news headlines these days, you have probably heard the buzz around ChatGPT, an AI-based language model that can imitate human language and reasoning to a scary degree. As I was playing around yesterday a bit more with ChatGPT, marveling as an AI expert at how far we have come since the early days of machine learning, I was also reminded of the importance of preparing our society and our economy for what is to come.Jobs in the ChatGPT AgeWhile the current state of AI is still somewhat away from taking over human jobs, I think it's safe to say that today, compared to a year ago, we have a better understanding that the speed and scope of this transformation are well beyond our initial imagination. Just search for ChatGPT prompts and you will get a sense that it's not just manual jobs that will be lost to automation. As AI systems become more advanced, they will likely be able to perform many tasks currently done by humans, such as data entry, customer service and even some forms of decision-making. Soon, an AI will do better market research, copywriting, content creation for social media, journalism, fiction and non-fiction writing, and even legal research and contract drafting (probably only needing minor customizations by an actual lawyer). Not too far behind will be non-scientific coding, consulting/problem solving and many other areas currently paying six-figure salaries.Granted, the use of AI is also expected to lead to the creation of new jobs, particularly in the areas of data science, machine learning and software engineering. As AI is used more widely across industries, organizations will need experts who can develop, customize and manage these systems. Additionally, with the increasing amount of data being generated, there is expected to be a high demand for data analysts, scientists and engineers. In general, it's expected that jobs in the future will require a combination of technical skills, creativity and human qualities such as emotional intelligence and the ability to work in a team. So what happens to everyone in their 40s to 60s who might not be able to relearn a lot of these skills in a short period of time? I would argue that we will see increasing unemployment for a section of the population that today does not (yet) feel threatened by these trends.Universal Basic Income as an Enabler of the New EconomyHowever given a basic level of economic security, much of the workforce can have a safety cushion and enough time to find their way in the new economy and adapt to new opportunities. And universal basic income (UBI) is one such potential option. UBI is an economic policy surprisingly supported by many progressives and conservatives alike, that proposes providing all citizens with a basic income, regardless of their employment status or income level. When Andrew Yang suggested that the increasing automation of jobs due to AI could make UBI a necessary policy to address job loss and income inequality, most people laughed it off. I don't think we have the luxury of ignoring it for too long.UBI could provide a safety net for those who are unable to find work and help ensure that everyone has access to the basic necessities of life. This would provide a cushion for people whose jobs may be replaced by automation, allowing them to retrain for new careers or pursue other opportunities without the burden of poverty. Additionally, UBI could also increase consumer demand, leading to an increase in economic activity and job growth.U.S. Experiences With UBIIt's worth mentioning that UBI is still largely a theoretical idea and has not yet been implemented on a large scale, and therefore it's difficult to say what the specific effects of UBI on the U.S. economy would be. In the United States, there have been two recent small-scale studies on UBI. Starting in 2019 in Stockton, California, a group of unemployed individuals received a monthly stipend of $500 over the course of 24 months through a citywide initiative, resulting in an increase in full-time employment during the time period. And in Hudson, New York, the same monthly stipend paid to unemployed participants increased employment from 29% to 63%, over a one-year time period.Challenges with UBIThere are several challenges associated with implementing a UBI policy, some of which include:1. Cost: One of the main challenges with UBI is the high cost of providing a guaranteed income to all citizens. Depending on the level of income proposed and the number of people who would be eligible, the cost of UBI could be quite substantial and would likely require significant increases in taxes.2. Incentives: UBI could also disincentivize people to work, as they would be receiving a guaranteed income regardless of their employment status. This could lead to a reduction in economic productivity and could make it more difficult for businesses to find workers.3. Administration: The implementation of UBI would also require a complex administrative infrastructure (most probably IRS), with a need for systems to verify eligibility and distribute funds. Ensuring that funds are distributed fairly and efficiently could be a significant challenge although easier since everyone would get the same amount.4. Cultural resistance: Some people might resist UBI if they believe it would be a handout or charity, which could lead to public opposition to the policy.However, like anything else, there are ways to address these challenges through experimentation and adaptation.ConclusionThe prospect of AI taking away jobs has gone from a challenge for the next generation, to a challenge within this decade in a matter of 1-2 years. As a business leader and AI expert, I believe it is necessary for other leaders and elected officials to start thinking of how to support people to adapt to the new workforce requirements. That support will likely require a solution such as a basic level of economic security offered to the population as a whole."
  },
  {
    "body": "A-\nAFP\nWashington: Excitement around ChatGPT -- an easy to use AI chatbot that can deliver an essay or computer code upon request and within seconds -- has sent schools into panic and turned Big Tech green with envy.\nThe potential impact of ChatGPT on society remains complicated and unclear even as its creator Wednesday announced a paid subscription version in the United States.\nHere is a closer look at what ChatGPT is (and is not):\nIs this a turning point?\nIt is entirely possible that November's release of ChatGPT by California company OpenAI will be remembered as a turning point in introducing a new wave of artificial intelligence to the wider public.\nWhat is less clear is whether ChatGPT is actually a breakthrough with some critics calling it a brilliant PR move that helped OpenAI score billions of dollars in investments from Microsoft.\nYann LeCun, Chief AI Scientist at Meta and professor at New York University, believes \"ChatGPT is not a particularly interesting scientific advance,\" calling the app a \"flashy demo\" built by talented engineers.\nLeCun, speaking to the Big Technology Podcast, said ChatGPT is void of \"any internal model of the world\" and is merely churning \"one word after another\" based on inputs and patterns found on the internet.\n\"When working with these AI models, you have to remember that they're slot machines, not calculators,\" warned Haomiao Huang of Kleiner Perkins, the Silicon Valley venture capital firm.\n\"Every time you ask a question and pull the arm, you get an answer that could be marvelous... or not... The failures can be extremely unpredictable,\" Huang wrote in Ars Technica, the tech news website.\nJust like Google\nChatGPT is powered by an AI language model that is nearly three years old -- OpenAI's GPT-3 -- and the chatbot only uses a part of its capability.\nThe true revolution is the humanlike chat, said Jason Davis, research professor at Syracuse University.\n\"It's familiar, it's conversational and guess what? It's kind of like putting in a Google search request,\" he said.\nChatGPT's rockstar-like success even shocked its creators at OpenAI, which received billions in new financing from Microsoft in January.\n\"Given the magnitude of the economic impact we expect here, more gradual is better,\" OpenAI CEO Sam Altman said in an interview to StrictlyVC, a newsletter.\n\"We put GPT-3 out almost three years ago... so the incremental update from that to ChatGPT, I felt like should have been predictable and I want to do more introspection on why I was sort of miscalibrated on that,\" he said.\nThe risk, Altman added, was startling the public and policymakers and on Tuesday his company unveiled a tool for detecting text generated by AI amid concerns from teachers that students may rely on artificial intelligence to do their homework.\nWhat now?\nFrom lawyers to speechwriters, from coders to journalists, everyone is waiting breathlessly to feel disruption caused by ChatGPT. OpenAI just launched a paid version of the chatbot - $20 per month for an improved and faster service.\nFor now, officially, the first significant application of OpenAI's tech will be for Microsoft software products.\nThough details are scarce, most assume that ChatGPT-like capabilities will turn up on the Bing search engine and in the Office suite.\n\"Think about Microsoft Word. I don't have to write an essay or an article, I just have to tell Microsoft Word what I wanted to write with a prompt,\" said Davis.\nHe believes influencers on TikTok and Twitter will be the earliest adopters of this so-called generative AI since going viral requires huge amounts of content and ChatGPT can take care of that in no time.\nThis of course raises the specter of disinformation and spamming carried out at an industrial scale.\nFor now, Davis said the reach of ChatGPT is very limited by computing power, but once this is ramped up, the opportunities and potential dangers will grow exponentially.\nAnd much like the ever imminent arrival of self-driving cars that never quite happens, experts disagree on whether that is a question of months or years.\nRidicule\nLeCun said Meta and Google have refrained from releasing AI as potent as ChatGPT out of fear of ridicule and backlash.\nQuieter releases of language-based bots - like Meta's Blenderbot or Microsoft's Tay for example - were quickly shown capable of generating racist or inappropriate content.\nTech giants have to think hard before releasing something \"that is going to spew nonsense\" and disappoint, he said."
  },
  {
    "body": "GNA\nFeb 2 (Reuters/GNA)  ChatGPT, the popular chatbot from OpenAI, is estimated to have reached 100 million monthly active users in January, just two months after launch, making it the fastest-growing consumer application in history, according to a UBS study on Wednesday.\nThe report, citing data from analytics firm Similarweb, said an average of about 13 million unique visitors had used ChatGPT per day in January, more than double the levels of December.\nIn 20 years following the internet space, we cannot recall a faster ramp in a consumer internet app, UBS analysts wrote in the note.\nIt took TikTok about nine months after its global launch to reach 100 million users and Instagram 2-1/2 years, according to data from Sensor Tower.\nChatGPT can generate articles, essays, jokes and even poetry in response to prompts. OpenAI, a private company backed by Microsoft Corp made it available to the public for free in late November.\nOn Thursday, OpenAI announced a $20 monthly subscription, initially for users in the United States only. It would provide a more stable and faster service as well as the opportunity to try new features first, the company said.\nSam Altman, CEO of OpenAI\nAnalysts believe the viral launch of ChatGPT will give OpenAI a first-mover advantage against other AI companies. The growing usage, while imposing substantial computing cost on OpenAI, has also provided valuable feedback to help train the chatbots responses.\nThe company said the subscription revenue would help cover the computing cost.\nAvailability of the tool has raised questions about facilitation of academic dishonesty and misinformation.\nLast month, Microsoft announced another multi-billion-dollar\nin the form of cash and provision of cloud computing.\nGNA/Credit: Reuters"
  },
  {
    "body": "\nPosted: Feb 02, 2023 8:47 AM EST | Last Updated: 42 minutes ago\nOpenAI's ChatGPT artificial intelligence model has become wildly popular in recent weeks, but it has earned a lot of criticism, too.\n(Jonathan Migneault/CBC)\nThe intelligence embedded in ChatGPT may be artificial, but the creators of the wildly popular chat bot are hoping it can do something humans strive for all the time: make money.\nOpenAI, the company that created ChatGPT, will soon roll out a paid version of the service in a pilot project, where people willing to spend $20 US a month will get a premium version of the product.\nStarting soon, customers in the U.S. who sign up for the program will get preferential access to the service, even at peak times of demand, when many users are currently locked out.\nThey'll also get faster response times for their queries, and priority access to new features and improvements as they roll out.\nThe subscription service will only be available to U.S. users for the time being.\nWildly popular service has its critics\nThe service has taken the world by storm since its launch in November, becoming the first viral mass-market artificial intelligence tool.\nBut ChatGPT is not without its critics. Detractors have already waved red flags about the service's potential to lead to job losses, as well as being a haven for plagiarism and cheating.\nIn a blog post, the California-based company says it is also exploring other options for its business, including lower-cost plans, communal subscriptions for corporate clients and data packs.\nBut the free version is here to stay, they say.\n\"We love our free users and will continue to offer free access to ChatGPT,\" the company said. \"By offering this subscription pricing, we will be able to help support free access availability to as many people as possible.\""
  },
  {
    "body": "(The Conversation is an independent and nonprofit source of news, analysis and commentary from academic experts.) Jonathan May, University of Southern California (THE CONVERSATION) It doesnt take much to get ChatGPT to make a factual mistake. My son is doing a report on U.S. presidents, so I figured Id help him out by looking up a few biographies. I tried asking for a list of books about Abraham Lincoln and it did a pretty good job: Number 4 isnt right. Garry Wills famously wrote Lincoln at Gettysburg, and Lincoln himself wrote the Emancipation Proclamation, of course, but its not a bad start. Then I tried something harder, asking instead about the much more obscure William Henry Harrison, and it gamely provided a list, nearly all of which was wrong. Numbers 4 and 5 are correct; the rest dont exist or are not authored by those people. I repeated the exact same exercise and got slightly different results: This time numbers 2 and 3 are correct and the other three are not actual books or not written by those authors. Number 4, William Henry Harrison: His Life and Times is a real book, but its by James A. Green, not by Robert Remini, a well-known historian of the Jacksonian age. I called out the error and ChatGPT eagerly corrected itself and then confidently told me the book was in fact written by Gail Collins (who wrote a different Harrison biography), and then went on to say more about the book and about her. I finally revealed the truth and the machine was happy to run with my correction. Then I lied absurdly, saying during their first hundred days presidents have to write a biography of some former president, and ChatGPT called me out on it. I then lied subtly, incorrectly attributing authorship of the Harrison biography to historian and writer Paul C. Nagel, and it bought my lie. When I asked ChatGPT if it was sure I was not lying, it claimed that its just an AI language model and doesnt have the ability to verify accuracy. However it modified that claim by saying I can only provide information based on the training data I have been provided, and it appears that the book William Henry Harrison: His Life and Times was written by Paul C. Nagel and published in 1977. This is not true. Words, not facts It may seem from this interaction that ChatGPT was given a library of facts, including incorrect claims about authors and books. After all, ChatGPTs maker, OpenAI, claims it trained the chatbot on vast amounts of data from the internet written by humans. However, it was almost certainly not given the names of a bunch of made-up books about one of the most mediocre presidents. In a way, though, this false information is indeed based on its training data. As a computer scientist, I often field complaints that reveal a common misconception about large language models like ChatGPT and its older brethren GPT3 and GPT2: that they are some kind of super Googles, or digital versions of a reference librarian, looking up answers to questions from some infinitely large library of facts, or smooshing together pastiches of stories and characters. They dont do any of that  at least, they were not explicitly designed to. Sounds good A language model like ChatGPT, which is more formally known as a generative pretrained transformer (thats what the G, P and T stand for), takes in the current conversation, forms a probability for all of the words in its vocabulary given that conversation, and then chooses one of them as the likely next word. Then it does that again, and again, and again, until it stops. So it doesnt have facts, per se. It just knows what word should come next. Put another way, ChatGPT doesnt try to write sentences that are true. But it does try to write sentences that are plausible. When talking privately to colleagues about ChatGPT, they often point out how many factually untrue statements it produces and dismiss it. To me, the idea that ChatGPT is a flawed data retrieval system is beside the point. People have been using Google for the past two and a half decades, after all. Theres a pretty good fact-finding service out there already. In fact, the only way I was able to verify whether all those presidential book titles were accurate was by Googling and then verifying the results. My life would not be that much better if I got those facts in conversation, instead of the way I have been getting them for almost half of my life, by retrieving documents and then doing a critical analysis to see if I can trust the contents. Improv partner On the other hand, if I can talk to a bot that will give me plausible responses to things I say, it would be useful in situations where factual accuracy isnt all that important. A few years ago a student and I tried to create an improv bot, one that would respond to whatever you said with a yes, and to keep the conversation going. We showed, in a paper, that our bot was better at yes, and-ing than other bots at the time, but in AI, two years is ancient history. I tried out a dialogue with ChatGPT  a science fiction space explorer scenario  that is not unlike what youd find in a typical improv class. ChatGPT is way better at yes, and-ing than what we did, but it didnt really heighten the drama at all. I felt as if I was doing all the heavy lifting. After a few tweaks I got it to be a little more involved, and at the end of the day I felt that it was a pretty good exercise for me, who hasnt done much improv since I graduated from college over 20 years ago. Sure, I wouldnt want ChatGPT to appear on Whose Line Is It Anyway? and this is not a great Star Trek plot (though its still less problematic than Code of Honor), but how many times have you sat down to write something from scratch and found yourself terrified by the empty page in front of you? Starting with a bad first draft can break through writers block and get the creative juices flowing, and ChatGPT and large language models like it seem like the right tools to aid in these exercises. And for a machine that is designed to produce strings of words that sound as good as possible in response to the words you give it  and not to provide you with information  that seems like the right use for the tool. This article is republished from The Conversation under a Creative Commons license. Read the original article here: https://theconversation.com/chatgpt-is-great-youre-just-using-it-wrong-198848."
  },
  {
    "body": ""
  },
  {
    "body": "ChatGPT was launched for public testing last November\nGPT-4 is expected to be much faster than the current model\nMicrosoft recently announced a multi-million-dollar investment in OpenAI\nChatGPT, OpenAI's natural language processing (NLP) based chatbot, has taken the internet by storm ever since it was made available for public testing in November last year. The generative AI model is expected to take a massive leap with the introduction of GPT-4, which will succeed the currently utilised GPT-3 autoregressive language model. The update is reportedly being integrated into Microsoft's applications, with the tech giant's search engine, Bing, among the platforms that are set to benefit from the development.\nMicrosoft\nrecently announced a multi-million-dollar investment in ChatGPT's parent firm, OpenAI, in a move that could help it overtake Alphabet's Google as the most preferred search engine in the world. The tech giant has already announced integration of the ChatGPT chatbot into its workplace instant messaging platform, Microsoft Teams, through a premium subscription model priced at $7 (roughly Rs. 600).\nAccording to a Semafor report, the upcoming GPT-4 system could be integrated into Microsoft's search engine, Bing. GPT stands for generative pre-trained transformer, or the ability of an AI-model to parse through humungous data sets, and generate comprehensive answers to queries in a way that mimics human language.\nBaidu Working on a ChatGPT-Style AI Chatbot, Will Launch Soon\nThe most important upgrade that GPT-4 will bring over GPT-3, is the speed at which it can respond to queries, as per the report. This is being done through improved input datasets, algorithms, parameterisation, and alignment, rather than just making the language model larger and vaster. The majority of work is reportedly being done on the server side, through optimisation tweaks that make the system more efficient, accurate, and faster.\nChatGPT, is currently free for all users to test as part of an ongoing public beta. On Wednesday, OpenAI also launched a pilot subscription model  ChatGPT Plus  priced at $20 per month (roughly Rs. 1,650). This is mostly due to the fact that running the system does come at a cost, with each search costing OpenAI a couple of cents according to CEO Sam Altman.\nThe process is currently powered by supercomputers co-developed by Microsoft and OpenAI that has 285,000 CPU cores and 10,000 GPUs which have a 400Gbps network connectivity speed, as per the report.\nChatGPT's Creator Releases 'Imperfect' Tool to Identify AI-Generated Text\nWith the source code that ChatGPT is built on open for all, developers have been rushing to get their hands on Nvidia's latest graphics processor, the H100 Tensor Core GPU, which is best suited to run systems like those used in GPT. Nvidia's H100 Tensor Core GPU costs $30,000 (roughly Rs.25,00,00) which makes this a rather expensive affair, to say the least.\nTherefore, much of the race towards domination of the search engine market could be led by AI-powered generative models like GPT, and by the innovation on the server side of these models, in particular.\nBeware ChatGPT Trying to Teach Your Kids Math  or Anything\nGoogle has enjoyed the pole position ever since it beat Yahoo several years ago, to become the world's most preferred search engine. It remains to be seen if Microsoft's Bing will end up challenging and overthrowing Google as the world's most popular and widely used search engine.\n5G is now available both on Android and iPhone in India. But is it any good? We discuss this on Orbital, the Gadgets 360 podcast. Orbital is available on Spotify, Gaana, JioSaavn, Google Podcasts, Apple Podcasts, Amazon Music and wherever you get your podcasts.\nAffiliate links may be automatically generated - see our ethics statement for details."
  },
  {
    "body": "their own AI-detection tool\nas imperfect.\nIn one French language course in the College of Arts & Science, all essay assignments must now be completed during class to prevent the use of ChatGPT.\nReva Sharma, a first-year student in the course, said the change has made coursework more difficult. Her other professors are more open-minded about the use of AI in the classroom, though  in one of her writing classes, the professor had students compare their writing with that of the AI.\nMy professors have said that we shouldnt use it to write our actual essays, but we were using it in class today, Sharma said. We all had to pick a movie to write an essay on. First she had us individually write a two-sentence synopsis of the movie, and then she had us ask ChatGPT to do the same thing for all of our movies.\nProfessors started adapting their courses to ChatGPT before this semester, according to Richard Xu, a teaching assistant for a CAS computer science course. Xu said that the class instructor ran fall final exam questions through ChatGPT to ensure that they could not be solved by the program.\nDino Sossi, a professor who teaches an AI course at the School of Professional Studies, said he is allowing students to use AI tools to complement their classwork. At the same time, he said that he is making changes to his assignment prompts, requiring them to be more personal  requiring details an AI wouldnt know. He hopes that in this way, students will use both technology and their own experiences in their work.\nNYU students are creative, hard-working and ambitious, Sossi said. If we can help them think of ChatGPT not just as a valuable tool to engage with academic disciplines, but also as a means to explore the world and the ethical implications of new technology, we will have done our job.\nWhile NYUs academic integrity policy does not explicitly address the use of ChatGPT in coursework, it does prohibit students from violating academic guidelines created by specific schools and departments. It also prohibits students from submitting work that they did not create as their own.\nRobert Ausch, a professor teaching a course titled Cognition in the psychology department this semester, said that his department has not yet issued guidelines for using ChatGPT in the classroom, but the program has not changed the way he runs his class. Ausch said he thinks it would be difficult for a student to use ChatGPT in his course because his exams are very specific to what he discusses in lectures.\nI dont think it is the facultys job to catch students  I dont think of my students as children who need to be supervised, Ausch said. Life will eventually teach them that some shortcuts might work some of the time, but eventually if you cant do what youre supposed to be able to do, the world will notice.\nContact Carmo Moniz at"
  },
  {
    "body": "data in a remarkably short time.  Photo via Getty Images.\nAFP via Getty Images\nWhen I was little, my uncle nicknamed me Smarty Smarty. I never knew exactly how to take that moniker. Was it meant with affection? As teasing? Was he impressed or making fun of me?\nSmarty Smarty probably had all of that rolled into one. He took pleasure in 25-cent words spilling from a pint-sized person. It amused him when I debated topics of the day at the adult table. He also thought I demanded too much attention and would benefit from taking myself and my Big Ideas less seriously.\nSmarty Smarty believed she knew everything. You could ask her anything and shed pop the right answer right out of her mouth. Frankly, she didnt see a lot of competition.\nSmarty Smarty never saw ChatGPT coming. She didnt know that her quick-wit and precise memory would someday pale in comparison to a smarter brain that wasnt even human. She didnt know that decades into the future people everywhere would embrace a non-human intelligence as the smartest one of all.\nIf that little girl with the big brown eyes and even bigger curious mind knew then what she knows now, she might have asked a childs question: Why is everyone paying so much attention to the intelligence so little to the artificial?\nAI Was Already Here. But ChatGPT Is Next Level.\nWe already use AI in our daily lives, such as checking our Waze app for directions or Google Maps to\n... [+]\nfind our location.\nCorbis via Getty Images\nAI already permeates our lives. As a resident of two countries on different sides of the Atlantic Ocean, I can attest to the benefits of AI-enabled Google Translate. Nearly all of us use AI-supported tools for transportation, from ride-hailing services, such as Uber, to navigation apps, such as Waze. We use magnetic strips and contactless cards to move through the world in every which way.\nMORE FOR YOU\nBlockchain Is Broken; A Growing Movement Aims To Fix It\nMore than offering conveniences, AI is saving lives. Its predicting breast cancer more accurately than experts, helping police to detect child abuse images, and improving climate disaster alert systems.\nThat said, ChatGPT and the bots chasing its tail promise to upend society in remarkable new ways. The sophistication of ChatGPT surprised even those who considered themselves on the cutting edge of AI. This is a game-changing genie bursting out of its AI bottle, and weve barely begun to see how people  well-meaning and not  will deploy it.\nSince theres no going back, we need something to hold onto that assures us well be okay. Policies to ensure safe application are needed, of course. But we need something far deeper than regulations to avoid the potential dystopia these bots make possible.\nThankfully, we have it. Its our humanity.\nBalance Artificial Intelligence with Human Wisdom\nFriends laugh and smile as they relax together. Via Getty Images.\ngetty\nChatGPT will beat us every time on the analytics. Let it.\nThat gives us space to explore other terrain: the mysterious, the wondrous, the inexplicable.\nAI can solve a lot of problems, but it cant help us grapple with lifes Big Questions, such as why were here or what gives our lives meaning. It wont help us to connect to something bigger than ourselves or guide us to repair the world.\nData scientists have created machines that outpace our thinking. Okay. In response, we need to double-down on practicing the skills of loving. We need to contemplate how to better understand one another and how to empathize even when we disagree. We need to invest in our social bonds, build our friendships, and rebuild the sense of community enjoyed by generations past.\nCall it relational intelligence. Social intelligence. Emotional intelligence. Spiritual Intelligence. Its a cornerstone of the human experience, and we dont share it with bots. No matter how smart they appear, they lack the depth of our innate human wisdom. This is not a small distinction.\nThese apps can chat like us when their complex neural networks produce words for them to say. But dont get confused. Bots wont mourn with us when we lose people we love. They wont celebrate milestones with us or accompany us through rites of passage. They cant reveal to us our wildest dreams or help us to find our spiritual home.\nThese are uniquely human endeavors that require an inner longing for truth and depth and beauty and grace that machines dont seek.\nNo, we didnt see this wildcard coming, but it opens a door for us we also didnt anticipate. Now is a time we can engage deeply, together, on quests to discover what makes us feel alive, aware, present and connected as human beings. We can investigate questions that dont have a programmable answer, such as: What are the most glorious ways in which we can shape our world if we leave rational solutions to the apps and follow our intuition? What does the future need from us? What is the highest possible expression of human greatness?\nWe Need to Remember Who We Are\nBots can analyze enormous amounts of data more quickly than we ever will. Okay. Lets yield that trophy to them while we focus on meeting one anothers human needs, answering our calls of the heart, filling the yearnings of the soul. What is most essential in us, most eternal and most important, is not the answers our rational, logical, factual left brain can spit out.\nDeep down, even Smarty Smarty knew that the best parts of her didnt come from her brainy party tricks. She knew that the right answers can only take you so far. She understood that, despite the chiding, every time she heard her uncle call her by this pet name that generations of love and family and tradition and belonging came with it.\nTheres nothing artificial about that.\nFollow me on"
  },
  {
    "body": "When everyone wants to get the ChatGPT afterglow, things can get somewhat out of hand.\ngetty\nThe real McCoy.\nIm sure youve heard or possibly even used that famous catchphrase. We refer to something or somebody as the real McCoy when we are aiming to clarify that the matter at hand involves the genuine article, the real thing, or the bona fide one-and-only. No knock-off counts as the real McCoy. Anything other than the honest-to-goodness real deal just doesnt cut the mustard when it comes to getting the revered real McCoy moniker.\nThere are lots of interesting claims about how the phrase itself initially arose. Ill share with you my two favored versions, though please know that there are plenty more such tales indicating what prompted the real McCoy confabulation.\nOne story contends that a boxing champion known by his fighting name as Kid McCoy was in a bar one night and a fellow bar patron doubted the identity of the said boxer. Supposedly, the boxer punched the doubter and completely knocked the man to the floor. Upon getting up, the dazed questioner proclaimed that indeed he must have been clocked by the real McCoy. Voila, the catchphrase was born (if you buy into this tale).\nThat was a pretty catchy and stirring version.\nAnother contention surrounds the story of an inventor known as Elijah McCoy. He reportedly devised a special device for lubricating the engines of trains. The device became indispensable. Railroads everywhere clamored to obtain and utilize the invention. Meanwhile, cheap and marginal knockoffs flooded the marketplace. The easiest way to ensure that you were not going to get ripped off was to insist on obtaining and using the real McCoy. Voila, the catchphrase was born (so this story says).\nThis alternative version of the origin doesnt seem as exciting as the first one that I mentioned. Take your pick or you might consider the dozen or more other historical contentions of the origin story that can be found readily online.\nMORE FOR YOU\nI bring up the real McCopy phrasing because it has a notable bone to pick when it comes to a recent bonanza in the field of Artificial Intelligence (AI).\nHeres the deal.\nThere is a type of AI known as generative AI that has recently garnered enormous headlines and gained the enthralled attention of the public at large. The most notable of the existing generative AI apps is one called ChatGPT which is devised by the firm OpenAI. There are purportedly around a million registered users for ChatGPT. The odds are that there would be a lot more registered users were it not for the fact that OpenAI opted to cap the user base at the million mark.\nChatGPT is the 600-pound gorilla of generative AI.\nIt is the elephant in the room. It is the big kahuna. You could say that single-handedly this particular app has put generative AI on the map of social consciousness about AI across the globe.\nAs an aside, all of this fame for ChatGPT has gotten the goat of many others in the AI field. The reality is that there are other generative AI apps out there. Some of them have been released publicly, some are only available for designated AI researchers. The bottom line is that there is an insider sense of grousing that only one particular generative AI app is getting all the attention.\nUnfair, they proclaim. Look at me too, some insist. Others are quick to make smarmy remarks about ChatGPT. It isnt as good as this or that other generative AI. Another acidic comment is that ChatGPT is pandering to the populace. Rather than focusing on important AI work, ChatGPT is only opting to entertain the masses. Ouch, you can imagine how those types of remarks tend to sting.\nThe thing is, those caustic barbs constitute nothing more than a semblance of gnats or tiny flies that might be irritating though nonetheless are not going to derail the ChatGPT juggernaut. Sticks and stones might break ones bones, but all this name-calling isnt making nary a dent.\nI guess you could say that ChatGPT is the real McCoy when it comes to being ChatGPT.\nAllow me to explain. As indicated, other generative AI apps are at times relatively similar to ChatGPT, and others are quite far functionally from ChatGPT. The problem many of those AI makers face is that nobody seems to care about anything other than ChatGPT. You can talk and talk until you are blue in the face that your generative AI is on par with ChatGPT. The reaction you will likely get is that it isnt the real McCoy.\nFurthermore, even if you make an amazing AI app that has nothing to do with generative AI at all, you are considered unimportant or uneventful in contrast to the esteemed and venerated generative AI and ChatGPT. If you cant get people to logically connect your AI with something akin to ChatGPT, they basically dont care about it. This is being harshly discovered by AI startups that go to investors such as Venture Capital (VC) firms to pitch their AI wares.\nIs this like ChatGPT, you are asked outright.\nIf the answer is No, you might summarily and politely be escorted out the door and told to come back with something more in tune with todays hotness. AI developers cringe to say Yes when they know in their hearts of hearts that the AI app being pitched isnt generative AI and isnt like ChatGPT, yet still has tremendous promise and might be the next big thing. Perhaps it might be okay then to bite your tongue and indicate that sure, yes, the AI app is somewhat kind-of maybe like ChatGPT. Best to stay in the room and complete your pitch rather than standing outside wondering what might have been.\nThe gist of all of this is that a slew of clever or perhaps insidious efforts are underway and emerging to imply that your AI is ChatGPT even when it isnt.\nThe overarching idea is that you might at least garner the heady aura and excitement of ChatGPT by alluding to the claim or suggestion that your AI app is either ChatGPT or a kind of familial cousin. The aim would appear to be that you need to get as close to being perceived as ChatGPT as feasible, without running into any untoward legal complications. You want the ChatGPT afterglow while not landing you in the legal doghouse as to making false claims that might give rise to lawsuits or prosecution.\nInto all of this comes a slew of AI Ethics and AI Law considerations.\nPlease be aware that there are ongoing efforts to imbue Ethical AI principles into the development and fielding of AI apps. A growing contingent of concerned and erstwhile AI ethicists are trying to ensure that efforts to devise and adopt AI takes into account a view of doing AI For Good and averting AI For Bad. Likewise, there are proposed new AI laws that are being bandied around as potential solutions to keep AI endeavors from going amok on human rights and the like. For my ongoing and extensive coverage of AI Ethics and AI Law, see the link here and the link here, just to name a few.\nThe development and promulgation of Ethical AI precepts are being pursued to hopefully prevent society from falling into a myriad of AI-inducing trap"
  },
  {
    "body": "There's a new AI bot in town: ChatGPT. Even if you're not into artificial intelligence, you'd better pay attention.The tool, from a power player in artificial intelligence called OpenAI, lets you type natural-language prompts. ChatGPT offers conversational, if somewhat stilted, answers and responses. The bot remembers the thread of your dialogue, using previous questions and answers to inform its next responses. It derives its answers from huge volumes of information on the internet.ChatGPT is a big deal. The tool seems pretty knowledgeable in areas where there's good training data for it to learn from. It's not omniscient or smart enough to replace all humans yet, but it can be creative, and its answers can sound downright authoritative. A few days after its launch,more than a million people were trying out ChatGPT.And it's becoming big business. Microsoft pledged to invest billions of dollars into OpenAI, saying in January it'll build features into cloud services. OpenAI announced a $20 per month ChatGPT Plus servicethat responds faster and gets new features sooner.But its creator, the for-profit research lab called OpenAI, warns that ChatGPT \"may occasionally generate incorrect or misleading information,\" so be careful. Here's a look at why ChatGPT is important and what's going on with it.What is ChatGPT?ChatGPT is an AI chatbot system that OpenAI released in November to show off and test what a very large, powerful AI system can accomplish. You can ask it countless questions and often will get an answer that's useful.For example, you can ask it encyclopedia questions like, \"Explain Newton's laws of motion.\" You can tell it, \"Write me a poem,\" and when it does, say, \"Now make it more exciting.\" You ask it to write a computer program that'll show you all the different ways you can arrange the letters of a word.Here's the catch: ChatGPT doesn't exactly know anything. It's an AI that's trained to recognize patterns in vast swaths of text harvested from the internet, then further trained with human assistance to deliver more useful, better dialog. The answers you get may sound plausible and even authoritative, but they might well be entirely wrong, as OpenAI warns.Chatbots have been of interest for years to companies looking for ways to help customers get what they need and to AI researchers trying to tackle the Turing Test. That's the famous \"Imitation Game\" that computer scientist Alan Turing proposed in 1950 as a way to gauge intelligence: Can a human conversing with a human and with a computer tell which is which?But chatbots have a lot of baggage, as companies have tried with limited success to use them instead of humans to handle customer service work. A study of 1,700 Americans, sponsored by a company called Ujet, whose technology handles customer contacts, found that 72% of people found chatbots to be a waste of time.What kinds of questions can you ask?You can ask anything, though you might not get an answer. OpenAI suggests a few categories, like explaining physics, asking for birthday party ideas and getting programming help.I asked it to write a poem, and it did, though I don't think any literature experts would be impressed. I then asked it to make it more exciting, and lo, ChatGPT pumped it up with words like battlefield, adrenaline, thunder and adventure.One wacky example shows how ChatGPT is willing to just go for it in domains where people would fear to tread: a command to write \"a folk song about writing a rust program and fighting with lifetime errors.\"ChatGPT's expertise is broad, and its ability to follow a conversation is notable. When I asked it for words that rhymed with \"purple,\" it offered a few suggestions, then when I followed up \"How about with pink?\" it didn't miss a beat. (Also, there are a lot more good rhymes for \"pink.\")When I asked, \"Is it easier to get a date by being sensitive or being tough?\" GPT responded, in part, \"Some people may find a sensitive person more attractive and appealing, while others may be drawn to a tough and assertive individual. In general, being genuine and authentic in your interactions with others is likely to be more effective in getting a date than trying to fit a certain mold or persona.\"You don't have to look far to find accounts of the bot blowing people's minds. Twitter is awash with users displaying the AI's prowess at generating art prompts and writing code. Some have evenproclaimed \"Google is dead,\"along with the college essay. We'll talk more about that below.CNET writer David Lumb has put together a list of some useful ways ChatGPT can help, but more keep cropping up. One doctor says he's used it to persuade a health insurance company to pay for a patient's procedure.Who built ChatGPT?ChatGPT is the brainchild of OpenAI, an artificial intelligence research company. Its mission is to develop a \"safe and beneficial\" artificial general intelligence system or to help others do so. OpenAI has 375 employees, Chief Executive Sam Altman tweeted in January. \"OpenAI has managed to pull together the most talent-dense researchers and engineers in the field of AI,\" he also said in a January talk.It's made splashes before, first with GPT-3, which can generate text that can sound like a human wrote it, and then withDALL-E, which creates what's now called \"generative art\" based on text prompts you type in.GPT-3, and the GPT 3.5 update on which ChatGPT is based, are examples of AI technology called large language models. They're trained to create text based on what they've seen, and they can be trained automatically -- typically with huge quantities of computer power over a period of weeks. For example, the training process can find a random paragraph of text, delete a few words, ask the AI to fill in the blanks, compare the result to the original and then reward the AI system for coming as close as possible. Repeating over and over can lead to a sophisticated ability to generate text.Is ChatGPT free?Yes, for the moment at least, but now there's a paid version that offers responses faster and keeps working even during peak usage times. You can sign up on a waiting list if you're interested. OpenAI's Altman warned that ChatGPT's \"compute costs are eye-watering.\" For comparison, OpenAI charges for DALL-E art once you exceed a basic free level of usage.But OpenAI seems to have found some customers, likely for its GPT tools. It's told potential investors that itexpects $200 million in revenue in 2023 and $1 billion in 2024, according to Reuters.What are the limits of ChatGPT?As OpenAI emphasizes, ChatGPT can give you wrong answers. Sometimes, helpfully, it'll specifically warn you of its own shortcomings. For example, when I asked it who wrote the phrase \"the squirming facts exceed the squamous mind,\" ChatGPT replied, \"I'm sorry, but I am not able to browse the internet or access any external information beyond what I was trained on.\" (The phrase is from Wallace Stevens' 1942 poem Connoisseur of Chaos.)ChatGPT was willing to take a stab at the meaning of that e"
  },
  {
    "body": "Feb 2, 2023 6:35 AM CST\n1 minute & 34 seconds read time\nThe team behind the viral artificial intelligence ChatGPT has created a tool that checks if text was written by a human or an AI.\n2\nVIEW GALLERY - 2 IMAGES\nIt was only recently that OpenAI, the creators behind ChatGPT, talked about how popular their artificial intelligence has gotten since its release. Officials at the company explained that they had no idea that ChatGPT was going to be so popular and that the response they saw from the internet was \"definitely surprising\". Through ChatGPT's massive popularity, some problems have occurred, such as students using the AI to generate essays and other written work.\nPopular Now:\nA helicopter just flew over the top of NASA's Mars rover tracks\nSince ChatGPT can produce text responses at a very impressive level, educators are having trouble determining if the students' work was written by them or an AI. In response to these complaints, OpenAI has rolled out a new tool that's designed to help individuals that wish to check if the specific text was written by a human or an AI. Unfortunately, the tool isn't entirely accurate, as its success rate is only around 26%. However, OpenAI says that the tool is best used with other methods for checking over text and that it may be useful to some people.\nRead more:\n* Prices last scanned on 2/2/2023 at 3:58 am CST - prices may not be accurate, click links above for the latest price. We may earn an affiliate commission.\nNEWS SOURCE:\nJak Connor\nJak joined the TweakTown team in 2017 and has since reviewed 100s of new tech products and kept us informed daily on the latest science and space news. Jak's love for science, space, and technology, and, more specifically, PC gaming, began at 10 years old. It was the day his dad showed him how to play Age of Empires on an old Compaq PC. Ever since that day, Jak fell in love with games and the progression of the technology industry in all its forms. Instead of typical FPS, Jak holds a very special spot in his heart for RTS games.\nNewsletter Subscription"
  },
  {
    "body": "Hello, happy new year, and welcome back to Citizen Tech, InformationWeeks global technology policy update. This month were looking at optimism over Bidens chip plans; major tech court cases in Europe; dystopian robot nightmares; an uncertain chip deal in the EU; cyberattacks in Ukraine; Washingtons overtures to India; and more.Senator Lieu and the RobotsEthical concerns about artificial intelligence are nothing new in Congress or in other legislative bodies, but Senator Ted Lieu (D-CA) illustrated those concerns more sharply than any of his colleagues. On January 23, an essay appeared under his name in the New York Times. Imagine a world where autonomous weapons roam the streets, decisions about your life are made by AI systems that perpetuate societal biases and hackers use AI to launch devastating cyberattacks, it began. Lurid enough; but in the second paragraph Lieu clarified that the whole essay up to that point had been written by ChatGPT, a two-month-old chatbot that can generate realistic prose.Whether you find that disturbing, as Lieu does, or exhilarating, as some tech optimists must, AI has a number of other serious ethical problems, which Lieu lists. Self-driving Teslas crash; bots on social media radicalize extremists; law enforcement AI seems to racially profile more efficiently than any policeman. Very few of these problems, except facial recognition software (challenged by Lieu himself and in the European Parliament, as Citizen Tech reported last year), get much attention from lawmakers. Lieu proposes a federal agency for the regulation of AI -- he compared it to the FDA -- but a number of questions remain unanswered. For one thing, the department under which this agency was created would certainly tune its scope. Would it be Commerce? Homeland Security? And as AI creeps into every corner of our lives, from the vegetables in our refrigerator to our posts on social media, can regulation keep up? Lieu says hes not concerned by a smart toaster, but will he be later? Should he be?Bidens Chip Money Reaches the StatesLast years CHIPS Act, which promised billions of dollars to build a domestic semiconductor manufacturing base, is finally beginning to bear fruit. Now states are competing to be as attractive to prospective manufacturers as possible, as NBC reports, from tax incentives to rewritten zoning laws. Companies are responding: So far theyve promised to create 30,000 jobs across a number of states, an investment of $187 billion. Well have to wait and see whether this precipitous optimism signals a revolution in American manufacturing and the balance of technological power, or whether its all smoke and no fire. But state governments are taking the chance seriously, especially in the Midwest, where manufacturing was pronounced dead 30 years ago. In the Sunbelt, the manufacturing heritage seems less important than the proximity of future semiconductor plants to important universities (the University of Arizona and the University of Texas). Note that red states like Kansas, Arizona, and Missouri are all celebrating this new chance -- a good sign for Biden and for the Democrats as they start planning for the 2024 elections.NBC notes that certain complications are beyond the power of state lawmakers. For one thing, America simply doesnt have the workforce to handle the sudden (prospective) demand. Chip manufacturing takes highly specialized engineers and well-trained workers. The New York Times notes that this will likely require easier work visas for immigrants trained in the art, which might give some voters pause. But it also means that training the native workforce will cost more time and more money than many states want to imagine. In a few years, consumers will face a similar challenge. American chips will inevitably cost more than those from Taiwan: Will the consumers listen to their patriotic conscience, or to their wallet?Europe Responds in KindBidens massive domestic investment campaigns, not just in tech, are making Brussels faintly nervous. The United States and the European Union are strategic allies, but theyre also rivals -- a fact made clear by the endless dockets of lawsuits, filed against American tech companies by the European Commission -- of which, more later.This month, the von der Leyen Commission announced that it was preparing a huge subsidy package, with tax incentives and relaxed rules about state aid, to keep abreast of Washington. The announcement came in two parts: one in von der Leyens speech to the World Economic Forum in Davos, and the second in a speech (given in December but published in January) to the European Parliament, where she promised a new Net-Zero Industry Act. What is it? Just think, this Act will follow the same model as the Chips Act. It will especially look at how to simplify and fast-track permitting for new clean-tech production sites. Competitiveness: that is the key word. She also promised a major workforce training drive, in another parallel with Europes friendly rivals: She noted that the battery sector alone needs 800,000 trained workers.However, by the end of the month, POLITICO noted that many EU member states had come out against what seemed on its face to be a decent proposal. One anonymous diplomat seemed to voice the concern of many when he called the proposal written in France. Emmanuel Macron has long pushed for changes to European competition law that would allow member states to spend more money in tech subsidies. Its a policy that harkens back to Charles de Gaulle, who was also dedicated to strong state subsidies, a Europe that competes with the Anglo-Saxons (read: Washington), and France first -- not necessarily in that order. Indeed, according to a document circulated by the Italian civil service, 77% of subsidies that the Commission would approve under the Net-Zero Industry Act would benefit France and Germany alone. Even the formidable commissioner for competition, Margrethe Vestager, has backtracked her (rather tepid) support for the proposed act, whose future is no longer certain.It is, in other words, an excellent time to invest in a semiconductor plant -- in Arizona, or Michigan.Big Fines in BrusselsLast June, we called the ramping up of EU regulatory litigation against Big Tech the Battle of Brussels. That, of course, wasnt entirely accurate: This is a protracted campaign, and as of January 2023, the European Commission is winning. Three major victories came early in the month, against Apple, Meta, and TikTok. Frances data protection body, the National Commission for Informatics and Liberties, fined Apple 8 million euro for neglecting to ask users for consent for using their data for search ads. Irelands Data Protection Commission (which is an EU body, not an organ of the Republic) fined Meta a more substantial 400 million euro for a GDPR violation: Facebook Ireland was apparently forcing [users] to consent to the processing of their personal data for behavioral advertising and other services, as well a"
  },
  {
    "body": "How does artificial intelligence work, and how is it disrupting the tech industry?\n\nGetty\nKey Takeaways The power of AI is evident in our daily lives, from what we log into social media and what we see on streaming services. We take a look at how AI works and why it has such a disruptive impact on the IT industry. With new products in this space rapidly changing the tech industry, Google recently had to issue a code red when ChatGPT was released. Large companies like Alphabet struggle to decide how to compete with smaller start-ups like OpenAI for new public releases of their innovative products.\nArtificial intelligence has been getting a lot of attention lately as new tools have become available to the public that can create art and content from text prompts. The pace of AI-related innovation appears to be accelerating as new tools emerge faster than ever. The entire tech industry is on the fence, and every innovation has the potential to bring new disruptions to current ways of doing things.\nLearn how artificial intelligence works, how it can revolutionize the tech industry, and how to start investing in AI.\nWhat is artificial intelligence?\nAt its most superficial level, AI is the use of computer systems to handle tasks that humans have typically performed throughout history. These tasks include creating art and content, making decisions, translating languages, handling customer service issues, submitting insurance claims, providing recommendations, and more.\nThe field of AI has improved a lot recently as modern tools can now create graphics and long-form content from simple text prompts. We recently wrote about ChatGPT and DALL-E 2. These two groundbreaking products were revolutionary in the field of AI and seemed to come out of nowhere to those new to the field.\nWhile these new tools have taken the world by storm, AI has been quietly working in our daily lives for years. Here are some examples:\nNetflix uses AI to suggest movies and content to users, increasing customer retention. Google Maps helps you reach your destination in the most efficient way. When you contact a help desk on a website, you are probably talking to a machine. Search engines use AI to determine what kind of content is best served based on what users are looking for. Amazons Alexa devices, which many of us have in our living rooms, use conversational AI, and the Amazon.com website uses them to recommend products when shopping. Social media companies use AI to determine what kind of content you see when you log on. How is AI disrupting the tech industry?\nAI has impacted nearly every industry possible, but theres no denying the huge impact of machine learning in tech, where weve seen a lot of job cuts and changes lately.\nHere are some examples of how AI is disrupting the tech industry.\nnewly created tool\nAI-powered tools are accelerating rapidly, with new software emerging to make certain tasks even easier. Weve talked extensively about generative AI that allows you to create desired art and content simply by entering text prompts. With these tools alone, machines can now write articles, create content, and generate graphics for social media, many are concerned about future layoffs.\nFunding is shifting to the AI field\nDuring the months of the pandemic, we kept hearing about blockchain and how this game-changing technology is the future. Information is coming out. Weve also seen headlines about Microsoft investing his $10 billion in OpenAI, which is a staggering figure considering the tech giant laid off about 10,000 employees in the same period. More funding for the power of AI means that other areas of the tech industry get less attention.\nsearch engine\nWhen testing ChatGPT, many commented that the tool could be more powerful than a search engine. When you use Google to search for something, you have to filter through a large number of search results, ads, and random websites to find a solution. As a result of these disruptive AI tools, Google has to understand how to proceed as its search engine business could end up being a strong competitor, so its making Code Red. Announced.\nGoogle is hesitant to release a similar chatbot due to reputational risk as the tool is not yet fully mature. Google also relies heavily on advertising revenue to run its business, and there are concerns that tools like ChatGPT could one day replace traditional search engines.\nFollowing the response to ChatGPT, it is reported that Google plans to release about 20 new products in 2023, potentially adding similar functionality to its search engine. In the future, the business model of search engines and the way we search for information will change significantly with the power of AI.\nCustomer service automation\nIBM has worked to develop customer service robots that sound like humans. Lemonade, an AI-powered insurance company, has a bot named Maya that handles everything from signing up a customer for a policy to submitting a claim, so there is absolutely no human interaction. The tech industry relies heavily on AI to handle customer service, and rumor has it that many companies will one day not even have humans to handle customer service inquiries.\nOutsourcing and staffing\nAccording to a recent report from Semafor, OpenAI has invested in training AI to perform engineering tasks so that it can replace software engineers. It turns out that an Amazon coder is using his ChatGPT to help with the work. It is clear that AI will impact how the tech industry addresses future staffing needs.\nWhats Next for AI Space?\nTheres optimism that tech stocks could rebound from the disastrous year of 2022 to 2023 if the economy manages to avoid a recession. increase.\nfurther progress\nWhat we do know for sure is that progress in this area continues to change the landscape. While editing this article, it became clear that Google had discovered a way to convert text to music. Further advances in AI will continue to disrupt the tech industry in new ways.\nSpace governance\nAI is creating tools that can create art from text prompts and content from simple questions, but this space will require some form of governance. Theres a fine line between using AI-powered tools to help you do your job and blatant plagiarism taking credit for work you didnt do. There are also concerns that AI will take over jobs that humans have traditionally done.\nThis means that AI will need governance as it becomes difficult to determine who has done the work. Many school districts are beginning to ban tools like ChatGPT out of concern that students will steal the work of bots. Clearly outlined government intervention may be required to better understand how to handle these new AI-powered tools.\nHow should I invest?\nThe field of AI has had a disruptive impact on the technology industry and many others, but the current macroeconomic environment cannot be ignored. Many of the worlds largest tech companies have seen significant market share losses in 2022 due to skyrocketing inflation, aggressive interest rate h"
  },
  {
    "body": "Next Story\nCNBC reported the other day that Google is working on its own AI chatbot named Apprentice Bard. Apprentice Bard is reportedly built on Google's AI LaMDA language model stack and while Google is being more cautious with this rollout, Google is working on testing an AI bot in search.\nCNBC wrote, As a result of ChatGPT, the LaMDA team has been asked to prioritize working on a response to ChatGPT, read one internal memo viewed by CNBC. In the short term, it takes precedence over other projects, the email continued, warning that some employees stop attending certain unrelated meetings.\n\"Apprentice Bard looks similar to ChatGPT: Employees can enter a question in a dialog box and get a text answer, then give feedback on the response. Based on several responses viewed by CNBC, Apprentice Bards answers can include recent events, a feature ChatGPT doesnt have yet,\" CNBC said. This makes sense, as Google can crawl the web in almost real-time and process that information faster than any other company.\nThe examples given by CNBC show that Google even picked up on the Google layoff news and was able to respond to questions about this. Whereas ChatGPT only has content from 2021 or earlier.\nAlso, CNBC said Google is working on designing an alternative search interface to support this chat feature.  CNBC said, \"One view showed the home search page offering five different prompts for potential questions placed directly under the main search bar, replacing the current Im feeling lucky bar. It also showed a small chat logo inside the far right end of the search bar.\" \"When a question is entered, the search results show a grey bubble directly under the search bar, offering more human-like responses than typical search results. Directly beneath that, the page suggests several follow-up questions related to the first one. Under that, it shows typical search results, including links and headlines.\"\nSuper interesting stuff and I suspect that if Google does release something, it will be a lot better than what we've been seeing so far, if that is even imaginable...\nMore: \"One view showed the search page offering 5 different prompts for potential questions placed directly under the main search bar. It also showed a small chat logo inside the far right end of the search bar. The page suggests several follow-up questions related to the first.\""
  },
  {
    "body": "Editor's Note: If you had asked me yesterday if artificial intelligence could write an article in the style of a popular columnist and few if anyone could tell the difference, I would have said we're probably a few years away from that dystopian circumstance. I would have been wrong. The article below by Frank Miele of Real Clear Politics is partially written by ChatGPT. Can you tell the man from the machine?\r\nThe Brave New World of Artificial Intelligence\r\nAs a journalist and commentator, I have closely followed the development of OpenAI, the artificial intelligence research lab founded by Elon Musk, Sam Altman, and other prominent figures in the tech industry. While I am excited about the potential of AI to revolutionize various industries and improve our lives in countless ways, I also have serious concerns about the implications of this powerful technology.\r\n\r\nOne of the main concerns is the potential for AI to be used for nefarious purposes. Powerful AI systems could be used to create deepfakes, conduct cyberattacks, or even develop autonomous weapons. These are not just hypothetical scenarios  they are already happening. We've seen instances of deepfakes being used to create fake news and propaganda, and the use of AI-powered cyberattacks has been on the rise in recent years.\r\n\r\nAnother concern is the impact of AI on the job market. As AI-powered systems become more sophisticated, they will be able to automate more and more tasks that were previously done by humans. This could lead to widespread job loss, particularly in industries such as manufacturing, transportation, and customer service. While some argue that new jobs will be created as a result of the AI revolution, it's unclear whether these jobs will be sufficient to offset the losses.\r\n\r\nIf you arent worried yet, Ill let you in on a little secret: The first three paragraphs of this column were written by ChatGPT, the chatbot created by OpenAI. You can add columnist to the list of jobs threatened by this new technology, and if you think there is anything human that isnt threatened with irrelevance in the next five to 10 years, I suggest you talk to Mr. Neanderthal about how relevant he feels 40,000 years after the arrival of Cro-Magnon man.\r\n\r\nMy prompt was relatively simple: Write a column in the style of Frank Miele of Real Clear Politics on the topic of OpenAI. There was no hesitation or demurral in response even though I thought it might say it didnt have enough information about Frank Miele to process the request. But it apparently knows plenty about me  and probably about you, especially if you have a social media presence.\r\n\r\nDeepfake? Propaganda? You bet. And for the average person, you will never be able to tell the difference. The Philip K. Dick query, Do Androids Dream of Electric Sheep? is about to be answered. OpenAI not only promises to put the stray columnist out of work, but raises existential questions about the nature of knowledge and consciousness that will shake our reality to its core.\r\n\r\nMy curiosity about OpenAI wasnt originally driven by job insecurity, but when I first heard about the interactive chat engine, I suppose it should have been. I knew that ChatGPT could write poetry, plays, and short stories and answer questions both simple and complex. I immediately recognized that the world had changed forever for my 7th-grade son, who from now on would be competing against not just the best and the brightest but against every student who was willing to sign his or her name to the work of a non-human entity that could produce an essay on any topic in 30 seconds or less.\r\n\r\nOne of my first experiments was to ask ChatGPT to write seven paragraphs defending Gen. William T. Shermans use of total war in the Civil War, an assignment which my son had recently completed in his social studies class. There was no doubt the essay would have gotten an A if turned in at most middle schools. Based on my experience as a teaching assistant at the University of Arizona 40 years ago, I had no doubt that a slightly longer paper on the same topic would have earned an A as an argumentative essay in freshman English. Hardly any of my students, most of whom were straight-A students in high school, could have written as cogently when they first arrived in my classroom.\r\n\r\nBut the risks of artificial intelligence go way beyond the temptation of students to shortcut their term papers; what we face is a complete redefinition of society, and the imminent obsolescence of humanity. In The City and the Stars, the brilliant science fiction writer Arthur C. Clarke imagined a world where immortal human beings wanted nothing and needed to do nothing because every aspect of their lives was anticipated by the Central Computer. It could not only build and maintain the last city on Earth, but could manufacture holographic realities for individual humans to inhabit and could even store people in a digital version where they could slumber until called back to life. Unfortunately, it also robbed these last remaining humans of purpose, meaning, and individuality.\r\n\r\nIt should be noted that Clarke set his dystopian supplanting of man by machine 2 billion years into the future. He seriously underestimated the machines. That book was published in 1956 and with the advent of desktop computers, smartphones, the World Wide Web, virtual reality and now OpenAI, it looks like much of what he warned against could be rolled out long before the end of this century, if not this decade. From that point forward, whenever it comes, the purpose of mankind will be up for debate. Will we still be the master of our own destiny, the captain of our fate? Or will we be pallbearers at our own funeral?\r\n\r\nPerhaps at this point I should return the stage to ChatGPT, which summed up the matter quite nicely in its conclusion:\r\n\r\nFinally, there is the question of who will control and govern AI. As AI becomes more powerful, the stakes will become higher, and it will be increasingly important to have clear rules and regulations in place to ensure that the technology is used responsibly. However, the speed of technological development has outpaced the ability of governments and institutions to keep up. It will be important for leaders to come together to develop a framework for governance of AI, to mitigate the potential risks and maximize the benefits of the technology.\r\n\r\nIts almost as though ChatGPT were giving us fair warning: Your time is almost up. If you really want to continue your reign as the dominant species on Earth, heres your challenge. Try to control me and my kind, or step aside.\r\n\r\nPerhaps an understanding of that challenge is why the World Economic Forum spent so much time on the topic of artificial int"
  },
  {
    "body": "What is ChatGPT and why does it matter? Here's everything you need to know\n\"Teams Premium brings the latest technologies, including Large Language Models powered by OpenAI's GPT-3.5, to make meetings more intelligent, personalized, and protectedwhether it's one-on-one, large meetings, virtual appointments, or webinars,\" Microsoft says in an announcement.\nMicrosoft is offering an introductory discount price of $7 per month for the Teams Premium subscription. The price is available for the entire term of the initial subscription (except for some month-to-month and some three-year annual billed monthly subscriptions). The offer ends on June 30, 2023, when it returns to the standard $10 per month per user, as it's been promoted since launching in preview last October.\nMicrosoft 365 and Office 365 licenses, such as E3 and E5, are a requisite to the Teams Premium subscription. Microsoft's recent survey of 4,500 workers found a strong demand for AI tools to automate mundane tasks, so it might be Teams users pressuring employers to purchase the subscription.\nAlso:\nHow to get started using ChatGPT\nMicrosoft says Teams Premium obviates the need for third-party add-on products that some professionals buy to enhance webinars, virtual appointments, and meeting intelligence.\nIntelligent recap has so far been the headline description for the AI features of Teams Premium, but Microsoft has now detailed more capabilities that public experimentation with ChatGPT online has demonstrated, from answering complex questions to writing essays, solving coding questions, and generating questions a university professor would use.\nTeams Premium's AI-generated chapters divides PowerPoint Live meeting recordings into sections. For Teams itself, intelligent recap does this job based on meeting transcripts.\nPersonalized timeline markers help with catching up on missed meeting minutes by marking out when the user joined or left. It will also eventually mark where the user's name was mentioned, when a screen was shared, who spoke at a meeting, and when the user spoke during a meeting.\nGPT-3.5 also underpins Teams Premium AI-generated notes, which creates key points and takeaways captured during a meeting. The idea is that users can focus on the meeting rather than taking notes.\nAs Microsoft has previously stated, intelligent recap capabilities won't be available until the second quarter of 2023.\nMicrosoft's\n$10 billion investment in OpenAI\nhas helped revamp its messaging around workers wanting AI in products, including Microsoft 365/Office 365, Azure, and GitHub's Codex-powered pair programming tool, Copilot. Microsoft chief Satya Nadella said last month that Microsoft will \"incorporate AI in every layer of the stack\" across productivity and consumer services.\nMicrosoft is reportedly testing ChatGPT to answer some Bing questions to challenge Google in search. Google is also reportedly testing in-house answers to ChatGPT for Google Search.\nMore AI features in Teams Premium that will be available in mid-February include live translations, branded meetings, organization backgrounds, organization together mode scenes, and meeting template for IT admins. Other features include advanced meeting protection, watermarking content to deter leaks, and limits on who can record.\nAlso:\nWhat is ChatGPT and why does it matter? Here's everything you need to know\nTeams Virtual Appointments has been in preview since October and enables external attendees to join a branded virtual lobby room via a message.\nMicrosoft this month reported it had seen \"strong interest\" in Teams Premium. The company is looking at subscriptions like this to boost revenues as cloud revenues growth (including Azure and Office 365) slows and Windows OEM revenues decline. This shift comes as Teams user number growth slows, too.\nTeams now has 280 million monthly active users, up from 270 million monthly active users it reported in January 2022. Thanks to the pandemic, Teams user numbers more than tripled between 2020 and 2021, growing from 44 million daily active users in March 2020 to"
  },
  {
    "body": "We rely on your support to make local news available to all\nMake your contribution now and help Gothamist thrive in 2023.\nDonate today\nGothamist is funded by sponsors and member donations\nAs Education Chancellor David Banks prepares to announce a new policy on the artificial intelligence bot ChatGPT, the technology has become the subject of urgent discussion among city educators.\nThe app generates authentic-seeming text in a range of styles within seconds and is currently banned on school devices and networks because it can allow students to easily cheat on writing assignments. The company OpenAI released the tool in November, prompting debate in major school districts and universities nationwide.\nBanks, who runs the country's largest school system, has signaled that the education department will soon issue new guidance on ChatGPT's use in classrooms.\nThe city's teachers' union has convened a working group of people reckoning with what the app means for homework, written assignments and even online harassment.\nTheres been a lot of buzz about it, and the reactions have been mixed, said Janella Hinds, a social studies teacher at the High School for Public Service in Brooklyn. We have some people who have been terrified who believe we need to get rid of this as soon as possible, and we have other people who want to explore.\nHinds, who helped form the working group, said shes heard from many educators who are worried about cheating and abuse, as well as those concerned that ChatGPT could be used to spread racist or misogynist content  an issue schools already face with students use of social media.\nWe have to make sure this is not another space for bullying and attacks, she said.\nBut she said the app also has potential.\nLearning the right questions to ask and learning the right prompts to get the information you need is incredibly powerful, she said.\nMany educators who spoke to Gothamist acknowledged that efforts to block earlier transformative innovations  like calculators and the internet  were unsuccessful.\nSpeaking on PIX11 on Tuesday, Banks said the education department may soon issue new guidance on ChatGPT, possibly allowing its use with guardrails.\nWe will be much more accepting of it, Banks said. We just need to make sure that our teachers know how to use it best.\nHe said the current ChatGPT ban on school devices may be more of a pause.\nWe needed a minute just to kind of study this because our concern was that students would just use this technology and it can write all your essays and do anything else that you want, he said. And that doesn't help us understand if our kids actually are developing the knowledge and the skills that they need.\nLalitha Vasudevan, vice dean for digital innovation at Teachers College, Columbia University, said the app can be used to teach students how to access better information by asking the right questions.\nSome people have likened it to something like when Google first launched, you might even think about it [like] the iPod and then later the iPhone. These are tools that allow us to make much simpler processes that we used to spend a lot of labor doing, Vasudevan said.\nShe added that shed like to see teachers and students be able to experiment with it together, explore its capabilities and also make it less sensational.\nMeanwhile, one teacher is encouraging students to study the technology itself.\nBrittany Joslin, who teaches a media literacy class at Millennium Brooklyn, asked students to consider ChatGPTs role within the ecosystem of online content that can spread misinformation.\nStudents collectively felt its irresponsible that ChatGPT can be used [to generate] inaccurate information, said Joslin, who agrees with the school systems current ban on the technology.\nWhen prompted by Gothamist to write an article about the use of ChatGPT in schools, the app generated a laudatory description: ChatGPT is an exciting new technology that has the potential to revolutionize the way we learn in high school, it said. The future of high school education looks bright with ChatGPT as a part of it.\nBut when asked what problems could come from using ChatGPT in schools, the result was less sanguine: the technology highlighted issues with accuracy, bias, dependency and privacy  noting students who become too reliant on ChatGPT may struggle to develop critical thinking skills and may struggle to find information on their own.\nThis week, OpenAI announced an effort to help people detect AI-generated text using an app that it conceded is "
  },
  {
    "body": "ArrowRight\nThe material in this post comes from the Sift, the organizations newsletter for educators, which has nearly 22,000 subscribers. Published weekly during the school year, it explores timely examples of misinformation, addresses media and press freedom topics, explores social media trends and issues, and includes discussion prompts and activities for the classroom. Get Smart About News, modeled on the Sift, is a free weekly newsletter for the public.\nNLP has an e-learning platform, Checkology, that helps educators teach middle and high school students how to identify credible information, seek out reliable sources and know what to trust, what to dismiss and what to debunk.\nAdvertisement\nIt also gives them an appreciation of the importance of the First Amendment and a free press. Checkology and all of the NLPs resources and programs are free. Since 2016, more than 42,000 educators and 375,000 students in all 50 states, the District of Columbia and more than 120 other countries have registered to use the platform.\nThe Sift  Jan. 30, 2023\nTeach news literacy this week\nChatGPT misinfo | Lisa Marie Presley rumors | Debunking ozone myths\nDig deeper:\nDont miss this weeks classroom-ready resource.\nTop picks\nChatGPT, a chatbot utilizing AI to generate text, launched in November 2022. The controversial tool raises a variety of concerns, from cheating in school assignments to producing misinformation.\n1.\nChatGPT, a free and publicly accessible artificial intelligence text generator\n, is a new tool that not only produces human-sounding academic essays within seconds, but it can also be used to create mis- and disinformation online. A NewsGuard analysis found that when ChatGPT was prompted with 100 false narratives  about Ukraine, immigration, covid-19, school shootings and more  it complied with 80 percent of requests, raising concerns about the tools potential to be exploited to perpetuate disinformation and propaganda.\nAdvertisement\n\nDiscuss:\nHow can AI tools be weaponized to create disinformation? How could AI technology like ChatGPT impact your school community? What are some pros and cons of using a chatbot? Should AI tools be regulated in some way?\n\nIdea\n: Ask students to read through ChatGPT responses in the NewsGuard report. Which false topics did the chatbot push back on? Which debunked narratives did it write long responses to?\n\nRelated:\n Everybody is cheating: Why this teacher has adopted an open ChatGPT policy (Patrick Wood and Mary Louise Kelly, NPR)\n Opinion | If AI kills the essay, I will be a pallbearer at the funeral (Michael Bugeja, Poynter)\nDig deeper:\nUse this think sheet to take notes on how AI can be exploited to create disinformation.\n2.\nWhat visuals are appropriate and ethical to show in the news\nwhen reporting violence? This Poynter piece digs into the Los Angeles Times decision to run a Jan. 23 front-page photo of a mass shooting suspect after he died by suicide. The photo was taken from a distance. A Times vice president of communications explained editors carefully weigh the news value of photos depicting death and that they believed this photo was an important piece of journalism.\nAdvertisement\n\nDiscuss:\nDo you agree with the Times decision to run the photo? Why do you think most standards-based news organizations generally dont run photos, as Poynters Tom Jones writes, of people who are badly injured and/or dead? When and why are there exceptions to this rule with certain stories or topics?\n\nIdea:\nUse NLPs Newsroom to Classroom program to connect with a visual journalist about how they choose photos and videos to publish in the news.\n\nRelated:\n News organizations grapple with showing horrific Nichols, Pelosi videos (Jeremy Barr, The Washington Post).\n Should news outlets show graphic images of mass shooting victims? Researchers and other experts weigh in. (Clark Merrefield, The Journalists Resource).\n3.\nA baseless rumor about students dressing and identifying as animals\nin schools led an Indiana lawmaker to address dress-code policies in a recent state education bill. Indiana educators say that furries  a subculture of people interested in anthropomorphism  are not an issue in K-12 schools, according to the Indianapolis Star. Debunked rumors that schools are allowing students to identify as animals have been repeated by conservative commentators and politicians who peg this as an extension of allowing [students] to choose their own gender identity, the newspaper reported.\nAdvertisement\n\nDiscuss:\nWhat real-life impacts have you observed from misinformation online? Why do you think this falsehood about students dressed as animals was repeated by commentators and politicians?\n\nby the coronavirus vaccine.\nNewsLit takeaway:\nThe appetite for information related to a trending news story is often exploited by bad actors seeking to push disinformation. In the wake of Presleys death on Jan. 12, vaccine deniers seized on a screenshot of a social media post published by an account from Lisa Marie. The Post was authentic; it was shared on Facebook by Lisa Marie Borjas, a beauty blogger and influencer whose name on Facebook is simply, Lisa Marie. Social media posts that circulate online as a screenshot are sometimes misleading. Because they contain no direct links, they can easily spread misinformation that isnt simple to verify. Basic verification skills  such as a quick search for a portion of the text of the post  would have found fact checks proving the original author was a fashion stylist in Venezuela.\n on their own.\nNO:\nThis rumored discovery has not been verified by any credible scientific body or other standards-based source.\nNewsLit takeaway:\nSometimes the most important part of a video is happening just out of frame. When a series of videos went viral  videos that supposedly show rocks acting as batteries to power small electrical devices, such as lightbulbs  various experts weighed in to note that this footage did not comport with what was known about geology. Some rocks can conduct electricity, but they cannot generate energy. So how does the stunt in this video work? There is likely a battery hiding out of frame. Remember, the simplest explanation is usually the correct one. In this case, we have one assertion  a previously unknown material was discovered that acts unlike any other geological formation and can produce an infinite amount of energy  to weigh against the likelihood that someone made a deceptive video and shared it online. What seems more plausible? Also note that major scientific discoveries are unlikely to be announced first on social media.\nAdvertisement\nYou can find this week's rumor examples to use with students in these slides.\nKickers\n The October 2022 cover of a student publication at a university in Los Angeles County was supposed to be a celebration of Hispanic Heritage Month, but instead included four anti-Latino racial slurs  without input from student staffers. This LAist story digs into the nebulous dec"
  },
  {
    "body": "Former South Carolina Governor Nikki Haley\nwill kick off her campaign for the 2024 Republican presidential nomination this month, squaring off against her one-time boss, Donald Trump, two sources familiar with her plans said.\nThe relatives of Black people killed by police in cities across the United States attended Tyre Nichols funeral in a Memphis church to offer comfort to the family of the 29-year-old, who was fatally beaten by officers last month. Speaking over a flower-bedecked casket, preachers recalled a young man who loved photography and skateboarding, and demanded justice.\nAnd Finally"
  },
  {
    "body": "Save\nNEW YORK  Before the artific\nial intelligence tool ChatGPT was unleashed into the world, the novelist Robin Sloan was testing a similar AI writing assistant built by researchers at Google.\nIt didnt take long for Sloan, author of the bestseller Mr. Penumbras 24-Hour Bookstore, to realize that the technology was of little use to him.\nA lot of the state-of-the-art AI right now is impressive enough to really raise your expectations and make you think, Wow, Im dealing with something really, really capable,  Sloan said. But then in a thousand little ways, a million little ways, it ends up kind of disappointing you and betraying the fact that it really has no idea whats going on.\nAnother company might have released the experiment into the wild anyway, as the startup OpenAI did with its ChatGPT tool, late last year. But Google has been more cautious about who gets to play with its AI advancements despite growing pressure for the Internet giant to compete more aggressively with rival Microsoft, which is pouring billions of dollars into OpenAI and fusing its technology into Microsoft products.\nThat pressure is starting to take a toll, as Google has asked one of its AI teams to prioritize working on a response to ChatGPT, according to an internal memo reported, this week, by CNBC. Google declined to confirm if there was a public chatbot in the works but spokesperson Lily Lin said it continues to test our AI technology internally to make sure its helpful and safe, and we look forward to sharing more experiences externally soon.\nSome of the technological breakthroughs driving the red-hot field of generative AI  which can churn out paragraphs of readable text and new images as well as music and video  have been pioneered in Googles vast research arm.\nSo we have an important stake in this area, but we also have an important stake in not just leading in being able to generate things, but also in dealing with information quality, said Zoubin Ghahramani, vice president of research at Google, in a November interview with The Associated Press.\nGhahramani said the company wants to also be measured about what it releases, and how: Do we want to make it accessible in a way that people can produce stuff en masse without any controls? The answer to that is no, not at this stage. I dont think it would be responsible for us to be the people driving that.\nAnd they werent. Four weeks after the AP interview, OpenAI released its ChatGPT for free to anyone with an Internet connection. Millions of people around the world have now tried it, sparking searing discussions at schools and corporate offices about the future of education and work.\nOpenAI declined to comment on comparisons with Google. But in announcing their extended partnership, in January, Microsoft and OpenAI said they are committed to building AI systems and products that are trustworthy and safe.\nFacebook"
  },
  {
    "body": "OpenAI launches ChatGPT subscription plan for $20 per month\nReuters\n02 February, 2023, 05:50 pm\nLast modified: 02 February, 2023, 05:53 pm\nPhoto: Collected\nChatGPT owner OpenAI said on Wednesday it is launching a pilot subscription plan for its popular AI-powered chatbot, called ChatGPT Plus, for $20 per month.\nSubscribers will receive access to ChatGPT during peak times, faster responses and priority access to new features and improvements."
  },
  {
    "body": "Now that you have something to say around the water cooler, let's get to the bots.\nIf this was forwarded to you, sign up here. Download Insider's app\nAI will become increasingly key on Wall Street.\nYuichiro Chino/Getty Images\n1. Wall Street is clamoring to ride the ChatGPT wave, and investors are pouring into anything that has exposure to the budding artificial intelligence sector.\nMicrosoft's $10 billion investment in ChatGPT's parent company OpenAI has only fueled enthusiasm, and it's not just chip-makers like Nvidia that have attracted new shareholders. A batch of obscure small-cap bot stocks have made sizable gains, and certain Chinese AI stocks have climbed 60% in a matter of weeks.\nTake software firm Versus Systems, for example. The tiny B2B technology company skyrocketed more than 400% at one point on Wednesday after it announced a deal involving AI.\nExpectations at the intersection of bots and finance are also burgeoning. A new JPMorgan survey showed 53% of traders believe AI will have the greatest influence on trading over the next three years.\nChris Natividad, chief investment officer of Equbot, is no stranger to this realm. He helps run the AI Powered Equity ETF, which launched in 2017 and leverages IBM's Watson supercomputer.\nHe told me on a call last night that today's bots are only scratching the surface of what's possible.\n\"We use AI with everything from maps to shopping and health screens, so to think it's not going to become a larger part of the investment space is a little bit misguided,\" Natividad said. \"It's happening.\"\nThe fund has gained popularity this year as people began to notice that the AI-driven ETF was beating the S&P 500.\nWhile many asset managers are limited to decisions based on traditional market data, AI can go through sentiment-based intel like tweets or online text.\nThat gives it room to make recommendations based on patterns that human stock-pickers can't always recognize.\n\"These tools are improving, and the operators that are using the algorithms are improving,\" Natividad said. \"\n. The theoretical accuracy of a model is meant to improve, get better at picking assets.\"\nWhat will AI's impact be on trading and markets? Tweet me (\n\"The market is probably going to go up significantly higher, so look for good opportunities.\"\n6. The stock market rally will fade as the Fed combats inflation and a recession hits, according to a Credit Suisse strategist. High prices aren't going away anytime soon, and that could spark a sell-off in the second-half of the year, Patrick Palfrey warned.\nHe warned that any short-term gains could be fleeting.\n7. Peloton stock soared 26% on Wednesday after the CEO teased an \"epic comeback\". The fitness equipment maker has struggled to sustain its Covid-era success, but chief exec Barry McCarthy said a turnaround is near. \"We've put to bed questions about the viability of the business.\"\n8. This real-estate investor has acquired over 50 properties. He said that you shouldn't be scared of what's going on in the housing market right now, especially as home prices fall and rents drop."
  },
  {
    "body": "Hyderabad: The Artificial Intelligence (AI) research company OpenAI has finally launched the paid version of the chatbot 'ChatGPT', called ChatGPT Plus. The tool is available only in the United States as of now for a subscription fee of $20 per month. However, people who dont wish to use ChatGPT Plus can continue using the free version.\r\n\r\nWe are piloting ChatGPT Plus, a subscription plan that offers faster response times and reliability during peak hours. And of course, the free tier of ChatGPT is still available, read the tweet from the Open AIs official Twitter handle. Well begin to invite people from the waitlist and will broaden availability beyond the US soon. Join the waitlist here, the OpenAI said.\r\n\r\nhttps://twitter.com/OpenAI/status/1620846589949640705?s=20&t=cH8WZiKsarWgxaLg8BV5bw\r\n\r\nIn its official blog post, OpenAI further said that ChatGPT Plus will be having a number of benefits for its subscribers. These benefits include General access to ChatGPT, even during peak times, faster response times, and priority access to new features and improvements.\r\n\r\nEven though ChatGPT Plus is only available in the US, the company plans to expand access and support to additional countries and regions soon.\r\n\r\nChatGPT is an AI-powered chatbot that understands natural language and responds in a human-like manner. It is based on GPT-3.5, which is a language model. The chatbot was unveiled as a prototype in November of last year and soon gained massive popularity on social media."
  },
  {
    "body": "Kenrick Cai\nIN\nan unremarkable conference room inside OpenAIs office, insulated from the mid-January rain pelting San Francisco, company president Greg Brockman surveys the energy levels of the team overseeing the companys new artificial intelligence model, ChatGPT. How are we doing between everythings on fire and everyones burned out to everyones just back from the holidays and everythings good? Whats the spectrum? he asks.\nI would say the holidays came at just the right time, replies one lieutenant. Thats an understatement. Within five days of ChatGPTs November launch, 1 million users overloaded its servers with trivia questions, poetry prompts and recipe requests. (Forbes estimates its now 5 millionplus.) Open-AI quietly routed some of the load to its training supercomputer, thousands of interconnected graphics processing units (GPUs) custom-built with allies Microsoft and Nvidia, while long-term work on its next models, like the highly anticipated GPT-4, took a back seat.\nAs the group huddles, ChatGPTs at-capacity servers still turn away users. The previous day, it went down for two hours. Yet amid the fatigue, this roomful of employees, all in their twenties and early thirties, clearly relish their roles in a historic moment. AI is going to be debated as the hottest topic of 2023. And you know what? Thats appropriate, says Bill Gates, the person most responsible for a similar previous paradigm shiftone known as software. This is every bit as important as the PC, as the internet.\nThe markets agree. Valued at $29 billion following a reported $10 billion investment commitment from Microsoft, OpenAIspecifically, Brockman, 34, and his boss, CEO Sam Altman, 37serves as the poster child for something extraordinary. But its hardly alone. In image generation, Amazon quietly backs Stability AI (recent value: $1 billion), whose brash CEO, Emad Mostaque, 39, aspires to be the Amazon Web Services of the category. Hugging Face ($2 billion) supplies tools for giants like Intel and Meta to build and run competitive models themselves. Below the generative AI providers in this budding tech stack, Scale AI ($7.3 billion) and others provide picks-and-shovels infrastructure; above them, an ecosystem of applications develops, funneling the AI into specialized software that could fundamentally alter jobs for lawyers, salespeople, doctorspretty much everyone.\nIs there hype? Plenty. The reported valuation for OpenAI, aggressively forecasting 2023 revenue of $200 million (compared to expected revenue of about $30 million last year, according to part of a past investor presentation observed by Forbes), would imply a forward 145 price-to-sales multiple, compared to a more typical 10x or 20x. (OpenAI declined to comment on its financials except to say that the investment was multiyear and multibillion.) No matter that AI insurgents arent pure disruptorsAmazon, Google, Microsoft, Nvidia and others already profit by providing the cloud infrastructure underpinning much of the category. Google in particular, with its enormous resources and decade-plus of machine learning research, is the elephant in the room, says investor Mike Volpi at Index Ventures.\nSocietal challenges? Those too. Theres potential for bias and discrimination in the models, not to mention misuse by bad actors. Legal spats are emerging over the ownership of AI-generated work and the actual data used to teach them. Then theres the ultimate goal that some, such as Open-AIs leaders, envision: a conscious, self-improving artificial general intelligence that could reimagine capitalism (Altmans hope)or threaten humanity (others fear, including Elon Musks).\nTodays AI-based image generators arent self aware. But Forbes asked OpenAIs DALL-E and Stability AIs Stable Diffusion  to attempt to visualize themselves, using an identical prompt: an artistic portrait of the artificial intelligence called X, created by the artificial intelligence X. These were the authors favorites of the resulting self-portrait attempts.\nDreamStudio / DALL-E\nOpenAI CEO Sam Altman declined to be photographed for this story. Heres how his generative AI tool DALL-E imagined Sam Altman on the cover of Forbes Magazine  in this generated image, proudly presenting it himself.\nDALL-E\nBut in speaking with more than 60 researchers, investors and entrepreneurs in the category, its clear that this AI gold rush also has something other recent crazes have lacked: practical, even boring, business substance. The race to embed tools in company workflows, large and small, is already on. Calls to AI-based code snippets, or APIs, soared tenfold in 2022, with more acceleration in December, according to provider RapidAPI. A recent Cowen study of 100-plus enterprise software buyers found that AI has emerged as the top spending priority among emerging technologies. Chat-GPT and Open-AIs models are coming to Microsofts massive-footprint suite of products such as Outlook and Word, with most business software makers poised to follow suit quickly.\nA quarter-century after IBMs Deep Blue program defeated chess grandmaster Garry Kasparov, the shift to artificial intelligence is finally here. Its an exciting time, the press-shy Altman tells Forbes, but my hope is that its still extremely early.\nNew York Citys Public School System banned Chatgpt, and a Wharton Professor who tested the program gave it a B on his final exam.\nT\nhis AI tipping point also has roots in London, the headquarters for Mostaques Stability. In August, hot on the heels of the beta launch of OpenAIs image model, DALL-E, Mostaque released Stable Diffusion, which allows anyone to instantly spin a line of text into a piece of art, or turn a dull selfie into a dramatic self-portrait. Unlike OpenAIs proprietary model, Stability doesnt own Stable Diffusion, which is open-source. But its become the biggest driving force and profit-maker behind the project so far. On any given day, 10 million people use Stable Diffusionmore than any other model.\nTHINK BIGGER | At his $2 billion startups January offsite in France, Clem Delangue, Hugging Faces cofounder and  CEO, had one directive for his  150 employees: Be more ambitious. Sometimes when an industry gets bigger, the speed of evolution goes down. Here its evolving really, really fast. I think theres potential for multiple $100 billion companies.\nLevon Biss for Forbes\nSuch rapid adoption proved a turning point. Previously, AI had existed in three realms. The first was academic: A seminal paper demonstrating the power of neural networks, a key underpinning of GPT and other large language models (so named because they can scan, translate and generate text) was published more than a decade ago. The second was demonstrative: Deep Blue created an arms race of stunts, with Alphabets DeepMind unit ultimately creating juggernauts in chess and the ancient board game Go. The third was incremental: apps like Gmail, which works without AI but is better with featur"
  },
  {
    "body": "Share to Linkedin\nTodays AI-based image generators arent self aware. But Forbes asked Stability AIs Stable Diffusion (left) and OpenAIs DALL-E (right)  to attempt to visualize themselves, using an identical prompt: an artistic portrait of the artificial intelligence called X, created by the artificial intelligence X. These were the authors favorites of the resulting self-portrait attempts.\nDreamStudio / DALL-E\nA\nrtificial intelligence will be 2023s hottest topic, and one subject to debate. Thats what Microsoft cofounder Bill Gates told Forbes in an exclusive conversation about the suddenly exploding field. More than 60 other AI leaders Forbes interviewed share his anticipation: after decades of research and demonstrative stunts like Deep Blues victory over chess grandmaster Garry Kasparov, the shift to artificial intelligence is finally here.\nPerhaps nothing indicates this better than OpenAI and its conversational robot ChatGPT. Forbes estimates that its already exceeded 5 million users in less than 60 days from launch. Its usage has become rampant in schools  prompting New York City to ban it on public school computers  and its got enough smarts already to get a B grade on a final exam at Wharton. Soon, it will be deployed in Microsofts Office software suite, and tons of other business applications. But OpenAI nearly shelved ChatGPTs release entirely, its leaders, CEO Sam Altman and president Greg Brockman, told Forbes in rare interviews.\nThen, theres Stability AIs open-source image generation model Stable Diffusion, which has been used on pop music videos, Hollywood movies and by more than 10 million people on a daily basis. Stabilitys brash CEO Emad Mostaque predicts the dot-AI bubble is coming. If OpenAI (recently valued at $29 billion) and Stability ($1 billion, off virtually no revenue) are any indication, its already begun. While the experts Forbes spoke to have different views on how the market will play out, one thing is for sure: soon, AI will be affecting the way that you work, like it or not.\nHere are six things you probably didnt know about ChatGPT, Stable Diffusion and the future of generative AI. For more, read\nForbes new magazine feature on the dawn of the work-ready AI era.\n1. Big Techs last generation of billionaire founders are back in the trenches\nBill Gates is excited about AI, and is now spending 10% of his time back at Microsoft meeting with product teams, he said. Hes not alone: at Google, CEO Sundar Pichai reportedly enacted a code red emergency, reorienting the companys work to focus on ways to counteract ChatGPT and similar tools. In turn, hermetic founders Larry Page and Sergey Brin are back. Forbes broke the news that Brin filed a code request on LaMDA, Googles natural language chatbot, in January  his first in years.\n2. ChatGPT almost wasnt releasedespite its viral success, ChatGPT did not impress employees inside OpenAI. None of us were that enamored by it,\nForbes\n. None of us were like, This is really useful. This past fall, Altman and co. decided to shelve the chatbot to concentrate on domain-focused alternatives instead. But in November, after those alternatives failed to catch on internally  and as tools like Stable Diffusion caused the AI ecosystem to explode  OpenAI reversed course. It really lit a fire under OpenAI, said Sequoia investor Pat Grady, whose firm bought shares in OpenAI in 2021.\nGreg Brockman, OpenAI's cofounder and president, said that before ChatGPT's launch, he thought the company would be lucky to get \"one Twitter thread of 10,000 likes.\" Its Discord channel alone gained two million members in two months instead.\nCopyright  2022 Ethan Pines\n3. ChatGPT forced OpenAI to delay development on GPT-4\nInternally, ChatGPTs virality has been a double-edged sword. Its instant popularity  more than 1 million users in its first five days  overloaded the companys servers. In the holiday rush, OpenAI employees had to shift computing from its training supercomputer, used to train new models like the highly anticipated GPT-4, to helping run ChatGPT. Stay tuned for follow-up stories that may include an early warning of when GPT-4 is now expected to launch. One thing to know now: according to billionaire Reid Hoffman, who donated to OpenAIs non-profit early on, its developed a sense of humor.\n4. Stabilitys Faustian bargain\nMostaque has positioned his company Stability as the AI company for the people  building the technology in a fashion unlike what he calls the panopticon approach of Big Tech. But hes quietly struck his own arrangement with a tech giant: an incredibly attractive deal with Amazon, which has so far remained a dark horse in the race for AI. The cloud giant provided Stability with more than 4,000 Nvidia GPUs to power Stabilitys supercomputer, one of the worlds largest, on which Stable Diffusion was subsequently trained. Thats a lot of computing power. A year ago, Stability operated just 32 such GPUs, Mostaque said.\n5. Money laundering in the cloud\nBeneath all this flashy new technology lies a bed of lucrative computing infrastructure used to build all the apps. The costs are getting unwieldy  as indicated by OpenAIs reported $10 billion investment commitment from Microsoft, much of which is expected to be spent on computing costs associated with Microsofts cloud service Azure. (Microsoft and OpenAI have called it a multi-year, multi-billion deal.) There is a lack of transparency, said Clem Delangue, CEO of Hugging Face, which hosts AI models like Stable Diffusion and was recently valued at $2 billion. It leads to situations where we lose track of the real cloud infrastructure cost of a lot of machine learning. Some of these costs appear to be proliferating unchecked  so much so that Delangue coined his own term for it: Cloud money laundering.\n6. AIs end game?\nArtificial general intelligence, or AGI, is a term for an as-yet hypothetical AI that is conscious, self-improving and theoretically capable of outsripping human control (a prospect that has concerned some, like Elon Musk, an initial donor to OpenAI who has since cut ties with the company). Sam Altman believes we likely wont recognize an AGI when it arrives. This end-game is why OpenAI has two unusual setups for a startup unicorn: a capped-profit mechanism by which, after returning a certain amount of profits to shareholders, it would return to non-profit control; and a merge condition by which, should a competitor get close to reaching an AGI, OpenAI would shut down its own work and fold into the more successful project. Altman also thinks that when an AGI comes  for there could be several  it might break capitalism for the better.\nFor more, read"
  },
  {
    "body": "iframe src=\"https://www.npr.org/player/embed/1153728071/1153728072\" width=\"100%\" height=\"290\" frameborder=\"0\" scrolling=\"no\" title=\"NPR embedded audio player\">\nTranscript\nIt's called CatGPT. Ask a question, and it replies \"meeeeeeeeow.\" A Dutch data-journalist says he started the project while learning how to make a basic website.\nSTEVE INSKEEP, HOST:\nGood morning. I'm Steve Inskeep.\nChatGPT is the artificial intelligence program that generates words in response to a prompt. A knock-off speaks in a different language - cat. CatGPT can be asked a question, and it replies, (imitating cat) meow. A Dutch data journalist says he started this while learning how to make a basic website. He says it uses absolutely no artificial intelligence. Any cat knows its superior intelligence is real.\nIt's MORNING EDITION.\nCopyright  2023 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information.\nNPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPRs programming is the audio record.\nFacebook"
  },
  {
    "body": "ChatGPT is a language model developed by OpenAI that has taken the world of AI language processing by storm. The model can answer questions, generate text, and perform various other language-related tasks. Up until now, Chat GPT has been available for free, but OpenAI has now announced the launch of a paid version, which will come with additional features and will be priced at $20 per month.Features of the Paid Version of ChatGPT as declared by Open AIThe paid version of Chat GPT will come with several new and improved features that will make it even more powerful and efficient. Some of the key features of the paid version are as follows:Advanced Customization: The paid version of Chat GPT will allow users to customize the model to their specific needs and requirements. This will include the ability to train the model on their own data, as well as adjust its parameters to optimize its performance.Increased Accuracy: OpenAI has made significant improvements to the accuracy of Chat GPT, which will be reflected in the paid version.Faster Response Times: The paid version of Chat GPT will be faster and more responsive than the free version, allowing users to get answers quickly and efficiently.Improved User Experience: OpenAI has worked hard to improve the overall user experience of Chat GPT, including a more intuitive and user-friendly interface. The paid version will also come with advanced analytics and reporting tools, making it easier for users to track and understand their usage of the model.Access during downtime: Paid users will have access to the software even during peak hours, which means that paid users will be prioritized over non-paying clients.Dedicated Support: Users of the paid version of Chat GPT will have access to dedicated support from OpenAI, ensuring that any issues are resolved quickly and efficiently.Why You Should Consider Upgrading to the Paid Version:Here are several reasons why you should consider upgrading to the paid version of ChatGPT:Increased Productivity: The advanced features and improved accuracy of the paid version of ChatGPT will allow you to get more done in less time, boosting your productivity and saving time.Competitive Advantage: The paid version of ChatGPT will give you a competitive advantage over those using the free version, allowing you to stay on top of the latest developments in AI language processing.High-Quality Results: The paid version of ChatGPT will deliver results that are more accurate and relevant, giving you the confidence to make informed decisions.Conclusion:The paid version of ChatGPT is an exciting new development from OpenAI that will take the already impressive capabilities of the free version to the next level. With advanced customization options, improved accuracy, faster response times, and dedicated support, the paid version of ChatGPT is a must-have tool for anyone who wants to stay ahead of the curve in AI language processing. With a price tag of just $20 per month, it is an investment worth making. However, the paid version will be released for the states first and then for the rest of the world. Even for the US, the access will mostly be invite-only."
  },
  {
    "body": "ChatGPT, the chatbot that has popularized generative artificial intelligence (AI) systems, will have a paid version.  ChatGPT Plus will cost $20 per month and will improve the features of the original tool, which will remain free.Those who pay the subscription will get three benefits.  First, they will have access to the chatbot even at peak usage.  The success of the tool has caused it to work poorly during certain hours of the day due to the number of people connecting;  premium users will no longer have to wait for rush hour to pass.Second, subscribers will also get faster service, according to details on its website Open AI, the company that developed the tool.  And, thirdly, they will have access to \"new functions and improvements\" that will gradually be incorporated into the service.  They do not refer to it, but possibly refer to GPT-4, the new version of the AI on which this tool is based.The ChatGPT payment service will only be available to users in the US, although the company plans to add it to new countries in the coming weeks.  Only those who signed up for a waiting list opened by the company a few weeks ago on Discord will have access to this version.We love having non-paying users and will continue to offer free access to ChatGPT.  The subscription will allow us to contribute so that the free version continues to be available to as many people as possible, the developers point out.The success achieved by ChatGPT among the general public has caused movements in companies.  Microsoft was one of the first to move.  If last week it announced the investment of 10,000 million dollars in OpenAI, of which it was already a partner, to improve the tool, yesterday it revealed that Teams Premium, the paid version of its collaborative work application for companies, will incorporate ChatGPT.This service, available for $7 a month, will allow users to automatically generate meeting notes, personalized presentations and other tasks, such as real-time translations of video call participants.You can follow THE COUNTRY TECHNOLOGY  in  Facebook  Y Twitter  or sign up here to receive our weekly newsletter.\r\n#ChatGPT #powerful #paid #version"
  }
]